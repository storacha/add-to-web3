{"version":3,"file":"index.js","sources":["../webpack://add-to-web3/./node_modules/@actions/core/lib/command.js","../webpack://add-to-web3/./node_modules/@actions/core/lib/core.js","../webpack://add-to-web3/./node_modules/@actions/core/lib/file-command.js","../webpack://add-to-web3/./node_modules/@actions/core/lib/utils.js","../webpack://add-to-web3/./node_modules/@assemblyscript/loader/index.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/car.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/decoder.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/encoder.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/indexed-reader.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/indexer.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/iterator-channel.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/iterator.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/reader-browser.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/reader.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/writer-browser.js","../webpack://add-to-web3/./node_modules/@ipld/car/cjs/lib/writer.js","../webpack://add-to-web3/./node_modules/@ipld/dag-cbor/cjs/index.js","../webpack://add-to-web3/./node_modules/@ipld/dag-pb/cjs/src/index.js","../webpack://add-to-web3/./node_modules/@ipld/dag-pb/cjs/src/pb-decode.js","../webpack://add-to-web3/./node_modules/@ipld/dag-pb/cjs/src/pb-encode.js","../webpack://add-to-web3/./node_modules/@ipld/dag-pb/cjs/src/util.js","../webpack://add-to-web3/./node_modules/@protobufjs/aspromise/index.js","../webpack://add-to-web3/./node_modules/@protobufjs/base64/index.js","../webpack://add-to-web3/./node_modules/@protobufjs/eventemitter/index.js","../webpack://add-to-web3/./node_modules/@protobufjs/float/index.js","../webpack://add-to-web3/./node_modules/@protobufjs/inquire/index.js","../webpack://add-to-web3/./node_modules/@protobufjs/pool/index.js","../webpack://add-to-web3/./node_modules/@protobufjs/utf8/index.js","../webpack://add-to-web3/./node_modules/balanced-match/index.js","../webpack://add-to-web3/./node_modules/blob-to-it/index.js","../webpack://add-to-web3/./node_modules/brace-expansion/index.js","../webpack://add-to-web3/./node_modules/browser-readablestream-to-it/index.js","../webpack://add-to-web3/./node_modules/carbites/cjs/lib/treewalk/index.js","../webpack://add-to-web3/./node_modules/carbites/cjs/lib/treewalk/joiner.js","../webpack://add-to-web3/./node_modules/carbites/cjs/lib/treewalk/splitter.js","../webpack://add-to-web3/./node_modules/cborg/cjs/cborg.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/0uint.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/1negint.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/2bytes.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/3string.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/4array.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/5map.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/6tag.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/7float.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/bl.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/byte-utils.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/common.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/decode.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/encode.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/is.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/jump.js","../webpack://add-to-web3/./node_modules/cborg/cjs/lib/token.js","../webpack://add-to-web3/./node_modules/concat-map/index.js","../webpack://add-to-web3/./node_modules/data-uri-to-buffer/dist/src/index.js","../webpack://add-to-web3/./node_modules/err-code/index.js","../webpack://add-to-web3/./node_modules/files-from-path/cjs/src/index.js","../webpack://add-to-web3/./node_modules/hamt-sharding/src/bucket.js","../webpack://add-to-web3/./node_modules/hamt-sharding/src/consumable-buffer.js","../webpack://add-to-web3/./node_modules/hamt-sharding/src/consumable-hash.js","../webpack://add-to-web3/./node_modules/hamt-sharding/src/index.js","../webpack://add-to-web3/./node_modules/interface-blockstore/src/adapter.js","../webpack://add-to-web3/./node_modules/interface-blockstore/src/errors.js","../webpack://add-to-web3/./node_modules/interface-blockstore/src/index.js","../webpack://add-to-web3/./node_modules/interface-blockstore/src/memory.js","../webpack://add-to-web3/./node_modules/ipfs-car/dist/cjs/blockstore/fs.js","../webpack://add-to-web3/./node_modules/ipfs-car/dist/cjs/blockstore/memory.js","../webpack://add-to-web3/./node_modules/ipfs-car/dist/cjs/pack/constants.js","../webpack://add-to-web3/./node_modules/ipfs-car/dist/cjs/pack/index.js","../webpack://add-to-web3/./node_modules/ipfs-car/dist/cjs/unpack/index.js","../webpack://add-to-web3/./node_modules/ipfs-car/dist/cjs/unpack/utils/verifying-get-only-blockstore.js","../webpack://add-to-web3/./node_modules/ipfs-core-utils/src/files/normalise-input/index.js","../webpack://add-to-web3/./node_modules/ipfs-core-utils/src/files/normalise-input/normalise-content.js","../webpack://add-to-web3/./node_modules/ipfs-core-utils/src/files/normalise-input/normalise-input.js","../webpack://add-to-web3/./node_modules/ipfs-core-utils/src/files/normalise-input/utils.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/node_modules/ipfs-unixfs/src/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/node_modules/ipfs-unixfs/src/unixfs.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/dag-cbor.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/identity.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/raw.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/unixfs-v1/content/directory.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/unixfs-v1/content/file.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/resolvers/unixfs-v1/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/utils/extract-data-from-block.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/utils/find-cid-in-shard.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-exporter/src/utils/validate-offset-and-length.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/node_modules/bl/BufferList.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/node_modules/ipfs-unixfs/src/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/node_modules/ipfs-unixfs/src/unixfs.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/chunker/fixed-size.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/chunker/rabin.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/dir.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/file/balanced.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/file/buffer-importer.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/file/flat.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/file/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/file/trickle.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dag-builder/validate-chunks.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dir-flat.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dir-sharded.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/dir.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/flat-to-shard.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/options.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/tree-builder.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/utils/persist.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs-importer/src/utils/to-path-components.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs/src/index.js","../webpack://add-to-web3/./node_modules/ipfs-unixfs/src/unixfs.js","../webpack://add-to-web3/./node_modules/is-plain-obj/index.js","../webpack://add-to-web3/./node_modules/it-all/index.js","../webpack://add-to-web3/./node_modules/it-batch/index.js","../webpack://add-to-web3/./node_modules/it-drain/index.js","../webpack://add-to-web3/./node_modules/it-filter/index.js","../webpack://add-to-web3/./node_modules/it-glob/index.js","../webpack://add-to-web3/./node_modules/it-last/index.js","../webpack://add-to-web3/./node_modules/it-map/index.js","../webpack://add-to-web3/./node_modules/it-parallel-batch/index.js","../webpack://add-to-web3/./node_modules/it-peekable/index.js","../webpack://add-to-web3/./node_modules/it-pipe/index.js","../webpack://add-to-web3/./node_modules/it-take/index.js","../webpack://add-to-web3/./node_modules/merge-options/index.js","../webpack://add-to-web3/./node_modules/minimatch/minimatch.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base10.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base16.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base2.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base32.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base36.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base58.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base64.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/base8.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bases/identity.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/basics.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/block.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/bytes.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/cid.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/codecs/json.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/codecs/raw.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/hashes/digest.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/hashes/hasher.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/hashes/identity.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/hashes/sha2.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/index.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/src/varint.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/vendor/base-x.js","../webpack://add-to-web3/./node_modules/multiformats/cjs/vendor/varint.js","../webpack://add-to-web3/./node_modules/murmurhash3js-revisited/index.js","../webpack://add-to-web3/./node_modules/murmurhash3js-revisited/lib/murmurHash3js.js","../webpack://add-to-web3/./node_modules/p-retry/index.js","../webpack://add-to-web3/./node_modules/protobufjs/minimal.js","../webpack://add-to-web3/./node_modules/protobufjs/src/index-minimal.js","../webpack://add-to-web3/./node_modules/protobufjs/src/reader.js","../webpack://add-to-web3/./node_modules/protobufjs/src/reader_buffer.js","../webpack://add-to-web3/./node_modules/protobufjs/src/roots.js","../webpack://add-to-web3/./node_modules/protobufjs/src/rpc.js","../webpack://add-to-web3/./node_modules/protobufjs/src/rpc/service.js","../webpack://add-to-web3/./node_modules/protobufjs/src/util/longbits.js","../webpack://add-to-web3/./node_modules/protobufjs/src/util/minimal.js","../webpack://add-to-web3/./node_modules/protobufjs/src/writer.js","../webpack://add-to-web3/./node_modules/protobufjs/src/writer_buffer.js","../webpack://add-to-web3/./node_modules/rabin-wasm/dist/rabin-wasm.node.js","../webpack://add-to-web3/./node_modules/rabin-wasm/src/index.js","../webpack://add-to-web3/./node_modules/rabin-wasm/src/rabin.js","../webpack://add-to-web3/./node_modules/retry/index.js","../webpack://add-to-web3/./node_modules/retry/lib/retry.js","../webpack://add-to-web3/./node_modules/retry/lib/retry_operation.js","../webpack://add-to-web3/./node_modules/sparse-array/index.js","../webpack://add-to-web3/./node_modules/streaming-iterables/dist/index.js","../webpack://add-to-web3/./node_modules/uint8arrays/compare.js","../webpack://add-to-web3/./node_modules/uint8arrays/concat.js","../webpack://add-to-web3/./node_modules/uint8arrays/equals.js","../webpack://add-to-web3/./node_modules/uint8arrays/from-string.js","../webpack://add-to-web3/./node_modules/uint8arrays/index.js","../webpack://add-to-web3/./node_modules/uint8arrays/to-string.js","../webpack://add-to-web3/./node_modules/uint8arrays/util/bases.js","../webpack://add-to-web3/./node_modules/uint8arrays/xor.js","../webpack://add-to-web3/./node_modules/varint/decode.js","../webpack://add-to-web3/./node_modules/varint/encode.js","../webpack://add-to-web3/./node_modules/varint/index.js","../webpack://add-to-web3/./node_modules/varint/length.js","../webpack://add-to-web3/./node_modules/web-encoding/src/lib.js","../webpack://add-to-web3/./node_modules/web-streams-polyfill/dist/polyfill.js","../webpack://add-to-web3/./node_modules/web3.storage/node_modules/files-from-path/cjs/src/index.js","../webpack://add-to-web3/./web3.js","../webpack://add-to-web3/./node_modules/@web-std/blob/dist/src/lib.node.cjs","../webpack://add-to-web3/./node_modules/@web-std/blob/dist/src/package.cjs","../webpack://add-to-web3/./node_modules/@web-std/fetch/dist/index.cjs","../webpack://add-to-web3/./node_modules/@web-std/file/dist/src/lib.node.cjs","../webpack://add-to-web3/./node_modules/web3.storage/dist/src/lib.cjs","../webpack://add-to-web3/external \"buffer\"","../webpack://add-to-web3/external \"crypto\"","../webpack://add-to-web3/external \"fs\"","../webpack://add-to-web3/external \"http\"","../webpack://add-to-web3/external \"https\"","../webpack://add-to-web3/external \"os\"","../webpack://add-to-web3/external \"path\"","../webpack://add-to-web3/external \"stream\"","../webpack://add-to-web3/external \"url\"","../webpack://add-to-web3/external \"util\"","../webpack://add-to-web3/external \"zlib\"","../webpack://add-to-web3/webpack/bootstrap","../webpack://add-to-web3/webpack/runtime/compat","../webpack://add-to-web3/./index.js"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        const delimiter = '_GitHubActionsFileCommandDelimeter_';\n        const commandValue = `${name}<<${delimiter}${os.EOL}${convertedVal}${os.EOL}${delimiter}`;\n        file_command_1.issueCommand('ENV', commandValue);\n    }\n    else {\n        command_1.issueCommand('set-env', { name }, convertedVal);\n    }\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    return inputs;\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    process.stdout.write(os.EOL);\n    command_1.issueCommand('set-output', { name }, value);\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n */\nfunction error(message) {\n    command_1.issue('error', message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds an warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n */\nfunction warning(message) {\n    command_1.issue('warning', message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    command_1.issueCommand('save-state', { name }, value);\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issueCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueCommand = issueCommand;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n//# sourceMappingURL=utils.js.map","\"use strict\";\n\n// Runtime header offsets\nconst ID_OFFSET = -8;\nconst SIZE_OFFSET = -4;\n\n// Runtime ids\nconst ARRAYBUFFER_ID = 0;\nconst STRING_ID = 1;\nconst ARRAYBUFFERVIEW_ID = 2;\n\n// Runtime type information\nconst ARRAYBUFFERVIEW = 1 << 0;\nconst ARRAY = 1 << 1;\nconst SET = 1 << 2;\nconst MAP = 1 << 3;\nconst VAL_ALIGN_OFFSET = 5;\nconst VAL_ALIGN = 1 << VAL_ALIGN_OFFSET;\nconst VAL_SIGNED = 1 << 10;\nconst VAL_FLOAT = 1 << 11;\nconst VAL_NULLABLE = 1 << 12;\nconst VAL_MANAGED = 1 << 13;\nconst KEY_ALIGN_OFFSET = 14;\nconst KEY_ALIGN = 1 << KEY_ALIGN_OFFSET;\nconst KEY_SIGNED = 1 << 19;\nconst KEY_FLOAT = 1 << 20;\nconst KEY_NULLABLE = 1 << 21;\nconst KEY_MANAGED = 1 << 22;\n\n// Array(BufferView) layout\nconst ARRAYBUFFERVIEW_BUFFER_OFFSET = 0;\nconst ARRAYBUFFERVIEW_DATASTART_OFFSET = 4;\nconst ARRAYBUFFERVIEW_DATALENGTH_OFFSET = 8;\nconst ARRAYBUFFERVIEW_SIZE = 12;\nconst ARRAY_LENGTH_OFFSET = 12;\nconst ARRAY_SIZE = 16;\n\nconst BIGINT = typeof BigUint64Array !== \"undefined\";\nconst THIS = Symbol();\nconst CHUNKSIZE = 1024;\n\n/** Gets a string from an U32 and an U16 view on a memory. */\nfunction getStringImpl(buffer, ptr) {\n  const U32 = new Uint32Array(buffer);\n  const U16 = new Uint16Array(buffer);\n  var length = U32[(ptr + SIZE_OFFSET) >>> 2] >>> 1;\n  var offset = ptr >>> 1;\n  if (length <= CHUNKSIZE) return String.fromCharCode.apply(String, U16.subarray(offset, offset + length));\n  const parts = [];\n  do {\n    const last = U16[offset + CHUNKSIZE - 1];\n    const size = last >= 0xD800 && last < 0xDC00 ? CHUNKSIZE - 1 : CHUNKSIZE;\n    parts.push(String.fromCharCode.apply(String, U16.subarray(offset, offset += size)));\n    length -= size;\n  } while (length > CHUNKSIZE);\n  return parts.join(\"\") + String.fromCharCode.apply(String, U16.subarray(offset, offset + length));\n}\n\n/** Prepares the base module prior to instantiation. */\nfunction preInstantiate(imports) {\n  const baseModule = {};\n\n  function getString(memory, ptr) {\n    if (!memory) return \"<yet unknown>\";\n    return getStringImpl(memory.buffer, ptr);\n  }\n\n  // add common imports used by stdlib for convenience\n  const env = (imports.env = imports.env || {});\n  env.abort = env.abort || function abort(mesg, file, line, colm) {\n    const memory = baseModule.memory || env.memory; // prefer exported, otherwise try imported\n    throw Error(\"abort: \" + getString(memory, mesg) + \" at \" + getString(memory, file) + \":\" + line + \":\" + colm);\n  }\n  env.trace = env.trace || function trace(mesg, n) {\n    const memory = baseModule.memory || env.memory;\n    console.log(\"trace: \" + getString(memory, mesg) + (n ? \" \" : \"\") + Array.prototype.slice.call(arguments, 2, 2 + n).join(\", \"));\n  }\n  imports.Math = imports.Math || Math;\n  imports.Date = imports.Date || Date;\n\n  return baseModule;\n}\n\n/** Prepares the final module once instantiation is complete. */\nfunction postInstantiate(baseModule, instance) {\n  const rawExports = instance.exports;\n  const memory = rawExports.memory;\n  const table = rawExports.table;\n  const alloc = rawExports[\"__alloc\"];\n  const retain = rawExports[\"__retain\"];\n  const rttiBase = rawExports[\"__rtti_base\"] || ~0; // oob if not present\n\n  /** Gets the runtime type info for the given id. */\n  function getInfo(id) {\n    const U32 = new Uint32Array(memory.buffer);\n    const count = U32[rttiBase >>> 2];\n    if ((id >>>= 0) >= count) throw Error(\"invalid id: \" + id);\n    return U32[(rttiBase + 4 >>> 2) + id * 2];\n  }\n\n  /** Gets the runtime base id for the given id. */\n  function getBase(id) {\n    const U32 = new Uint32Array(memory.buffer);\n    const count = U32[rttiBase >>> 2];\n    if ((id >>>= 0) >= count) throw Error(\"invalid id: \" + id);\n    return U32[(rttiBase + 4 >>> 2) + id * 2 + 1];\n  }\n\n  /** Gets the runtime alignment of a collection's values. */\n  function getValueAlign(info) {\n    return 31 - Math.clz32((info >>> VAL_ALIGN_OFFSET) & 31); // -1 if none\n  }\n\n  /** Gets the runtime alignment of a collection's keys. */\n  function getKeyAlign(info) {\n    return 31 - Math.clz32((info >>> KEY_ALIGN_OFFSET) & 31); // -1 if none\n  }\n\n  /** Allocates a new string in the module's memory and returns its retained pointer. */\n  function __allocString(str) {\n    const length = str.length;\n    const ptr = alloc(length << 1, STRING_ID);\n    const U16 = new Uint16Array(memory.buffer);\n    for (var i = 0, p = ptr >>> 1; i < length; ++i) U16[p + i] = str.charCodeAt(i);\n    return ptr;\n  }\n\n  baseModule.__allocString = __allocString;\n\n  /** Reads a string from the module's memory by its pointer. */\n  function __getString(ptr) {\n    const buffer = memory.buffer;\n    const id = new Uint32Array(buffer)[ptr + ID_OFFSET >>> 2];\n    if (id !== STRING_ID) throw Error(\"not a string: \" + ptr);\n    return getStringImpl(buffer, ptr);\n  }\n\n  baseModule.__getString = __getString;\n\n  /** Gets the view matching the specified alignment, signedness and floatness. */\n  function getView(alignLog2, signed, float) {\n    const buffer = memory.buffer;\n    if (float) {\n      switch (alignLog2) {\n        case 2: return new Float32Array(buffer);\n        case 3: return new Float64Array(buffer);\n      }\n    } else {\n      switch (alignLog2) {\n        case 0: return new (signed ? Int8Array : Uint8Array)(buffer);\n        case 1: return new (signed ? Int16Array : Uint16Array)(buffer);\n        case 2: return new (signed ? Int32Array : Uint32Array)(buffer);\n        case 3: return new (signed ? BigInt64Array : BigUint64Array)(buffer);\n      }\n    }\n    throw Error(\"unsupported align: \" + alignLog2);\n  }\n\n  /** Allocates a new array in the module's memory and returns its retained pointer. */\n  function __allocArray(id, values) {\n    const info = getInfo(id);\n    if (!(info & (ARRAYBUFFERVIEW | ARRAY))) throw Error(\"not an array: \" + id + \" @ \" + info);\n    const align = getValueAlign(info);\n    const length = values.length;\n    const buf = alloc(length << align, ARRAYBUFFER_ID);\n    const arr = alloc(info & ARRAY ? ARRAY_SIZE : ARRAYBUFFERVIEW_SIZE, id);\n    const U32 = new Uint32Array(memory.buffer);\n    U32[arr + ARRAYBUFFERVIEW_BUFFER_OFFSET >>> 2] = retain(buf);\n    U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2] = buf;\n    U32[arr + ARRAYBUFFERVIEW_DATALENGTH_OFFSET >>> 2] = length << align;\n    if (info & ARRAY) U32[arr + ARRAY_LENGTH_OFFSET >>> 2] = length;\n    const view = getView(align, info & VAL_SIGNED, info & VAL_FLOAT);\n    if (info & VAL_MANAGED) {\n      for (let i = 0; i < length; ++i) view[(buf >>> align) + i] = retain(values[i]);\n    } else {\n      view.set(values, buf >>> align);\n    }\n    return arr;\n  }\n\n  baseModule.__allocArray = __allocArray;\n\n  /** Gets a live view on an array's values in the module's memory. Infers the array type from RTTI. */\n  function __getArrayView(arr) {\n    const U32 = new Uint32Array(memory.buffer);\n    const id = U32[arr + ID_OFFSET >>> 2];\n    const info = getInfo(id);\n    if (!(info & ARRAYBUFFERVIEW)) throw Error(\"not an array: \" + id);\n    const align = getValueAlign(info);\n    var buf = U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];\n    const length = info & ARRAY\n      ? U32[arr + ARRAY_LENGTH_OFFSET >>> 2]\n      : U32[buf + SIZE_OFFSET >>> 2] >>> align;\n    return getView(align, info & VAL_SIGNED, info & VAL_FLOAT)\n          .subarray(buf >>>= align, buf + length);\n  }\n\n  baseModule.__getArrayView = __getArrayView;\n\n  /** Copies an array's values from the module's memory. Infers the array type from RTTI. */\n  function __getArray(arr) {\n    const input = __getArrayView(arr);\n    const len = input.length;\n    const out = new Array(len);\n    for (let i = 0; i < len; i++) out[i] = input[i];\n    return out;\n  }\n\n  baseModule.__getArray = __getArray;\n\n  /** Copies an ArrayBuffer's value from the module's memory. */\n  function __getArrayBuffer(ptr) {\n    const buffer = memory.buffer;\n    const length = new Uint32Array(buffer)[ptr + SIZE_OFFSET >>> 2];\n    return buffer.slice(ptr, ptr + length);\n  }\n\n  baseModule.__getArrayBuffer = __getArrayBuffer;\n\n  /** Copies a typed array's values from the module's memory. */\n  function getTypedArray(Type, alignLog2, ptr) {\n    return new Type(getTypedArrayView(Type, alignLog2, ptr));\n  }\n\n  /** Gets a live view on a typed array's values in the module's memory. */\n  function getTypedArrayView(Type, alignLog2, ptr) {\n    const buffer = memory.buffer;\n    const U32 = new Uint32Array(buffer);\n    const bufPtr = U32[ptr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];\n    return new Type(buffer, bufPtr, U32[bufPtr + SIZE_OFFSET >>> 2] >>> alignLog2);\n  }\n\n  baseModule.__getInt8Array = getTypedArray.bind(null, Int8Array, 0);\n  baseModule.__getInt8ArrayView = getTypedArrayView.bind(null, Int8Array, 0);\n  baseModule.__getUint8Array = getTypedArray.bind(null, Uint8Array, 0);\n  baseModule.__getUint8ArrayView = getTypedArrayView.bind(null, Uint8Array, 0);\n  baseModule.__getUint8ClampedArray = getTypedArray.bind(null, Uint8ClampedArray, 0);\n  baseModule.__getUint8ClampedArrayView = getTypedArrayView.bind(null, Uint8ClampedArray, 0);\n  baseModule.__getInt16Array = getTypedArray.bind(null, Int16Array, 1);\n  baseModule.__getInt16ArrayView = getTypedArrayView.bind(null, Int16Array, 1);\n  baseModule.__getUint16Array = getTypedArray.bind(null, Uint16Array, 1);\n  baseModule.__getUint16ArrayView = getTypedArrayView.bind(null, Uint16Array, 1);\n  baseModule.__getInt32Array = getTypedArray.bind(null, Int32Array, 2);\n  baseModule.__getInt32ArrayView = getTypedArrayView.bind(null, Int32Array, 2);\n  baseModule.__getUint32Array = getTypedArray.bind(null, Uint32Array, 2);\n  baseModule.__getUint32ArrayView = getTypedArrayView.bind(null, Uint32Array, 2);\n  if (BIGINT) {\n    baseModule.__getInt64Array = getTypedArray.bind(null, BigInt64Array, 3);\n    baseModule.__getInt64ArrayView = getTypedArrayView.bind(null, BigInt64Array, 3);\n    baseModule.__getUint64Array = getTypedArray.bind(null, BigUint64Array, 3);\n    baseModule.__getUint64ArrayView = getTypedArrayView.bind(null, BigUint64Array, 3);\n  }\n  baseModule.__getFloat32Array = getTypedArray.bind(null, Float32Array, 2);\n  baseModule.__getFloat32ArrayView = getTypedArrayView.bind(null, Float32Array, 2);\n  baseModule.__getFloat64Array = getTypedArray.bind(null, Float64Array, 3);\n  baseModule.__getFloat64ArrayView = getTypedArrayView.bind(null, Float64Array, 3);\n\n  /** Tests whether an object is an instance of the class represented by the specified base id. */\n  function __instanceof(ptr, baseId) {\n    const U32 = new Uint32Array(memory.buffer);\n    var id = U32[(ptr + ID_OFFSET) >>> 2];\n    if (id <= U32[rttiBase >>> 2]) {\n      do if (id == baseId) return true;\n      while (id = getBase(id));\n    }\n    return false;\n  }\n\n  baseModule.__instanceof = __instanceof;\n\n  // Pull basic exports to baseModule so code in preInstantiate can use them\n  baseModule.memory = baseModule.memory || memory;\n  baseModule.table  = baseModule.table  || table;\n\n  // Demangle exports and provide the usual utility on the prototype\n  return demangle(rawExports, baseModule);\n}\n\nfunction isResponse(o) {\n  return typeof Response !== \"undefined\" && o instanceof Response;\n}\n\n/** Asynchronously instantiates an AssemblyScript module from anything that can be instantiated. */\nasync function instantiate(source, imports) {\n  if (isResponse(source = await source)) return instantiateStreaming(source, imports);\n  return postInstantiate(\n    preInstantiate(imports || (imports = {})),\n    await WebAssembly.instantiate(\n      source instanceof WebAssembly.Module\n        ? source\n        : await WebAssembly.compile(source),\n      imports\n    )\n  );\n}\n\nexports.instantiate = instantiate;\n\n/** Synchronously instantiates an AssemblyScript module from a WebAssembly.Module or binary buffer. */\nfunction instantiateSync(source, imports) {\n  return postInstantiate(\n    preInstantiate(imports || (imports = {})),\n    new WebAssembly.Instance(\n      source instanceof WebAssembly.Module\n        ? source\n        : new WebAssembly.Module(source),\n      imports\n    )\n  )\n}\n\nexports.instantiateSync = instantiateSync;\n\n/** Asynchronously instantiates an AssemblyScript module from a response, i.e. as obtained by `fetch`. */\nasync function instantiateStreaming(source, imports) {\n  if (!WebAssembly.instantiateStreaming) {\n    return instantiate(\n      isResponse(source = await source)\n        ? source.arrayBuffer()\n        : source,\n      imports\n    );\n  }\n  return postInstantiate(\n    preInstantiate(imports || (imports = {})),\n    (await WebAssembly.instantiateStreaming(source, imports)).instance\n  );\n}\n\nexports.instantiateStreaming = instantiateStreaming;\n\n/** Demangles an AssemblyScript module's exports to a friendly object structure. */\nfunction demangle(exports, baseModule) {\n  var module = baseModule ? Object.create(baseModule) : {};\n  var setArgumentsLength = exports[\"__argumentsLength\"]\n    ? function(length) { exports[\"__argumentsLength\"].value = length; }\n    : exports[\"__setArgumentsLength\"] || exports[\"__setargc\"] || function() {};\n  for (let internalName in exports) {\n    if (!Object.prototype.hasOwnProperty.call(exports, internalName)) continue;\n    const elem = exports[internalName];\n    let parts = internalName.split(\".\");\n    let curr = module;\n    while (parts.length > 1) {\n      let part = parts.shift();\n      if (!Object.prototype.hasOwnProperty.call(curr, part)) curr[part] = {};\n      curr = curr[part];\n    }\n    let name = parts[0];\n    let hash = name.indexOf(\"#\");\n    if (hash >= 0) {\n      let className = name.substring(0, hash);\n      let classElem = curr[className];\n      if (typeof classElem === \"undefined\" || !classElem.prototype) {\n        let ctor = function(...args) {\n          return ctor.wrap(ctor.prototype.constructor(0, ...args));\n        };\n        ctor.prototype = {\n          valueOf: function valueOf() {\n            return this[THIS];\n          }\n        };\n        ctor.wrap = function(thisValue) {\n          return Object.create(ctor.prototype, { [THIS]: { value: thisValue, writable: false } });\n        };\n        if (classElem) Object.getOwnPropertyNames(classElem).forEach(name =>\n          Object.defineProperty(ctor, name, Object.getOwnPropertyDescriptor(classElem, name))\n        );\n        curr[className] = ctor;\n      }\n      name = name.substring(hash + 1);\n      curr = curr[className].prototype;\n      if (/^(get|set):/.test(name)) {\n        if (!Object.prototype.hasOwnProperty.call(curr, name = name.substring(4))) {\n          let getter = exports[internalName.replace(\"set:\", \"get:\")];\n          let setter = exports[internalName.replace(\"get:\", \"set:\")];\n          Object.defineProperty(curr, name, {\n            get: function() { return getter(this[THIS]); },\n            set: function(value) { setter(this[THIS], value); },\n            enumerable: true\n          });\n        }\n      } else {\n        if (name === 'constructor') {\n          (curr[name] = (...args) => {\n            setArgumentsLength(args.length);\n            return elem(...args);\n          }).original = elem;\n        } else { // instance method\n          (curr[name] = function(...args) { // !\n            setArgumentsLength(args.length);\n            return elem(this[THIS], ...args);\n          }).original = elem;\n        }\n      }\n    } else {\n      if (/^(get|set):/.test(name)) {\n        if (!Object.prototype.hasOwnProperty.call(curr, name = name.substring(4))) {\n          Object.defineProperty(curr, name, {\n            get: exports[internalName.replace(\"set:\", \"get:\")],\n            set: exports[internalName.replace(\"get:\", \"set:\")],\n            enumerable: true\n          });\n        }\n      } else if (typeof elem === \"function\" && elem !== setArgumentsLength) {\n        (curr[name] = (...args) => {\n          setArgumentsLength(args.length);\n          return elem(...args);\n        }).original = elem;\n      } else {\n        curr[name] = elem;\n      }\n    }\n  }\n  return module;\n}\n\nexports.demangle = demangle;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar reader = require('./lib/reader.js');\nvar indexer = require('./lib/indexer.js');\nvar iterator = require('./lib/iterator.js');\nvar writer = require('./lib/writer.js');\nvar indexedReader = require('./lib/indexed-reader.js');\n\n\n\nexports.CarReader = reader.CarReader;\nexports.CarIndexer = indexer.CarIndexer;\nexports.CarBlockIterator = iterator.CarBlockIterator;\nexports.CarCIDIterator = iterator.CarCIDIterator;\nexports.CarWriter = writer.CarWriter;\nexports.CarIndexedReader = indexedReader.CarIndexedReader;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar varint = require('varint');\nvar cid = require('multiformats/cid');\nvar Digest = require('multiformats/hashes/digest');\nvar dagCbor = require('@ipld/dag-cbor');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n  n['default'] = e;\n  return Object.freeze(n);\n}\n\nvar varint__default = /*#__PURE__*/_interopDefaultLegacy(varint);\nvar Digest__namespace = /*#__PURE__*/_interopNamespace(Digest);\n\nconst CIDV0_BYTES = {\n  SHA2_256: 18,\n  LENGTH: 32,\n  DAG_PB: 112\n};\nasync function readVarint(reader) {\n  const bytes = await reader.upTo(8);\n  const i = varint__default['default'].decode(bytes);\n  reader.seek(varint__default['default'].decode.bytes);\n  return i;\n}\nasync function readHeader(reader) {\n  const length = await readVarint(reader);\n  const header = await reader.exactly(length);\n  reader.seek(length);\n  const block = dagCbor.decode(header);\n  if (block == null || Array.isArray(block) || typeof block !== 'object') {\n    throw new Error('Invalid CAR header format');\n  }\n  if (block.version !== 1) {\n    if (typeof block.version === 'string') {\n      throw new Error(`Invalid CAR version: \"${ block.version }\"`);\n    }\n    throw new Error(`Invalid CAR version: ${ block.version }`);\n  }\n  if (!Array.isArray(block.roots)) {\n    throw new Error('Invalid CAR header format');\n  }\n  if (Object.keys(block).filter(p => p !== 'roots' && p !== 'version').length) {\n    throw new Error('Invalid CAR header format');\n  }\n  return block;\n}\nasync function readMultihash(reader) {\n  const bytes = await reader.upTo(8);\n  varint__default['default'].decode(bytes);\n  const codeLength = varint__default['default'].decode.bytes;\n  const length = varint__default['default'].decode(bytes.subarray(varint__default['default'].decode.bytes));\n  const lengthLength = varint__default['default'].decode.bytes;\n  const mhLength = codeLength + lengthLength + length;\n  const multihash = await reader.exactly(mhLength);\n  reader.seek(mhLength);\n  return multihash;\n}\nasync function readCid(reader) {\n  const first = await reader.exactly(2);\n  if (first[0] === CIDV0_BYTES.SHA2_256 && first[1] === CIDV0_BYTES.LENGTH) {\n    const bytes = await reader.exactly(34);\n    reader.seek(34);\n    const multihash = Digest__namespace.decode(bytes);\n    return cid.CID.create(0, CIDV0_BYTES.DAG_PB, multihash);\n  }\n  const version = await readVarint(reader);\n  if (version !== 1) {\n    throw new Error(`Unexpected CID version (${ version })`);\n  }\n  const codec = await readVarint(reader);\n  const bytes = await readMultihash(reader);\n  const multihash = Digest__namespace.decode(bytes);\n  return cid.CID.create(version, codec, multihash);\n}\nasync function readBlockHead(reader) {\n  const start = reader.pos;\n  const length = await readVarint(reader) + (reader.pos - start);\n  const cid = await readCid(reader);\n  const blockLength = length - (reader.pos - start);\n  return {\n    cid,\n    length,\n    blockLength\n  };\n}\nasync function readBlock(reader) {\n  const {cid, blockLength} = await readBlockHead(reader);\n  const bytes = await reader.exactly(blockLength);\n  reader.seek(blockLength);\n  return {\n    bytes,\n    cid\n  };\n}\nasync function readBlockIndex(reader) {\n  const offset = reader.pos;\n  const {cid, length, blockLength} = await readBlockHead(reader);\n  const index = {\n    cid,\n    length,\n    blockLength,\n    offset,\n    blockOffset: reader.pos\n  };\n  reader.seek(index.blockLength);\n  return index;\n}\nfunction createDecoder(reader) {\n  const headerPromise = readHeader(reader);\n  return {\n    header: () => headerPromise,\n    async *blocks() {\n      await headerPromise;\n      while ((await reader.upTo(8)).length > 0) {\n        yield await readBlock(reader);\n      }\n    },\n    async *blocksIndex() {\n      await headerPromise;\n      while ((await reader.upTo(8)).length > 0) {\n        yield await readBlockIndex(reader);\n      }\n    }\n  };\n}\nfunction bytesReader(bytes) {\n  let pos = 0;\n  return {\n    async upTo(length) {\n      return bytes.subarray(pos, pos + Math.min(length, bytes.length - pos));\n    },\n    async exactly(length) {\n      if (length > bytes.length - pos) {\n        throw new Error('Unexpected end of data');\n      }\n      return bytes.subarray(pos, pos + length);\n    },\n    seek(length) {\n      pos += length;\n    },\n    get pos() {\n      return pos;\n    }\n  };\n}\nfunction chunkReader(readChunk) {\n  let pos = 0;\n  let have = 0;\n  let offset = 0;\n  let currentChunk = new Uint8Array(0);\n  const read = async length => {\n    have = currentChunk.length - offset;\n    const bufa = [currentChunk.subarray(offset)];\n    while (have < length) {\n      const chunk = await readChunk();\n      if (chunk.length === 0) {\n        break;\n      }\n      if (have < 0) {\n        if (chunk.length > have) {\n          bufa.push(chunk.subarray(-have));\n        }\n      } else {\n        bufa.push(chunk);\n      }\n      have += chunk.length;\n    }\n    currentChunk = new Uint8Array(bufa.reduce((p, c) => p + c.length, 0));\n    let off = 0;\n    for (const b of bufa) {\n      currentChunk.set(b, off);\n      off += b.length;\n    }\n    offset = 0;\n  };\n  return {\n    async upTo(length) {\n      if (currentChunk.length - offset < length) {\n        await read(length);\n      }\n      return currentChunk.subarray(offset, offset + Math.min(currentChunk.length - offset, length));\n    },\n    async exactly(length) {\n      if (currentChunk.length - offset < length) {\n        await read(length);\n      }\n      if (currentChunk.length - offset < length) {\n        throw new Error('Unexpected end of data');\n      }\n      return currentChunk.subarray(offset, offset + length);\n    },\n    seek(length) {\n      pos += length;\n      offset += length;\n    },\n    get pos() {\n      return pos;\n    }\n  };\n}\nfunction asyncIterableReader(asyncIterable) {\n  const iterator = asyncIterable[Symbol.asyncIterator]();\n  async function readChunk() {\n    const next = await iterator.next();\n    if (next.done) {\n      return new Uint8Array(0);\n    }\n    return next.value;\n  }\n  return chunkReader(readChunk);\n}\n\nexports.asyncIterableReader = asyncIterableReader;\nexports.bytesReader = bytesReader;\nexports.chunkReader = chunkReader;\nexports.createDecoder = createDecoder;\nexports.readHeader = readHeader;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar varint = require('varint');\nvar dagCbor = require('@ipld/dag-cbor');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar varint__default = /*#__PURE__*/_interopDefaultLegacy(varint);\n\nfunction createHeader(roots) {\n  const headerBytes = dagCbor.encode({\n    version: 1,\n    roots\n  });\n  const varintBytes = varint__default['default'].encode(headerBytes.length);\n  const header = new Uint8Array(varintBytes.length + headerBytes.length);\n  header.set(varintBytes, 0);\n  header.set(headerBytes, varintBytes.length);\n  return header;\n}\nfunction createEncoder(writer) {\n  return {\n    async setRoots(roots) {\n      const bytes = createHeader(roots);\n      await writer.write(bytes);\n    },\n    async writeBlock(block) {\n      const {cid, bytes} = block;\n      await writer.write(new Uint8Array(varint__default['default'].encode(cid.bytes.length + bytes.length)));\n      await writer.write(cid.bytes);\n      await writer.write(bytes);\n    },\n    async close() {\n      return writer.end();\n    }\n  };\n}\n\nexports.createEncoder = createEncoder;\nexports.createHeader = createHeader;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar fs = require('fs');\nvar stream = require('stream');\nvar cid = require('multiformats/cid');\nvar indexer = require('./indexer.js');\nvar reader = require('./reader.js');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nclass CarIndexedReader {\n  constructor(version, path, roots, index, order) {\n    this._version = version;\n    this._path = path;\n    this._roots = roots;\n    this._index = index;\n    this._order = order;\n    this._fd = null;\n  }\n  get version() {\n    return this._version;\n  }\n  async getRoots() {\n    return this._roots;\n  }\n  async has(key) {\n    return this._index.has(key.toString());\n  }\n  async get(key) {\n    const blockIndex = this._index.get(key.toString());\n    if (!blockIndex) {\n      return undefined;\n    }\n    if (!this._fd) {\n      this._fd = await fs__default['default'].promises.open(this._path, 'r');\n    }\n    const readIndex = {\n      cid: key,\n      length: 0,\n      offset: 0,\n      blockLength: blockIndex.blockLength,\n      blockOffset: blockIndex.blockOffset\n    };\n    return reader.CarReader.readRaw(this._fd, readIndex);\n  }\n  async *blocks() {\n    for (const cidStr of this._order) {\n      const block = await this.get(cid.CID.parse(cidStr));\n      if (!block) {\n        throw new Error('Unexpected internal error');\n      }\n      yield block;\n    }\n  }\n  async *cids() {\n    for (const cidStr of this._order) {\n      yield cid.CID.parse(cidStr);\n    }\n  }\n  async close() {\n    if (this._fd) {\n      return this._fd.close();\n    }\n  }\n  static async fromFile(path) {\n    if (typeof path !== 'string') {\n      throw new TypeError('fromFile() requires a file path string');\n    }\n    const iterable = await indexer.CarIndexer.fromIterable(stream.Readable.from(fs__default['default'].createReadStream(path)));\n    const index = new Map();\n    const order = [];\n    for await (const {cid, blockLength, blockOffset} of iterable) {\n      const cidStr = cid.toString();\n      index.set(cidStr, {\n        blockLength,\n        blockOffset\n      });\n      order.push(cidStr);\n    }\n    return new CarIndexedReader(iterable.version, path, await iterable.getRoots(), index, order);\n  }\n}\nconst __browser = false;\n\nexports.CarIndexedReader = CarIndexedReader;\nexports.__browser = __browser;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar decoder = require('./decoder.js');\n\nclass CarIndexer {\n  constructor(version, roots, iterator) {\n    this._version = version;\n    this._roots = roots;\n    this._iterator = iterator;\n  }\n  get version() {\n    return this._version;\n  }\n  async getRoots() {\n    return this._roots;\n  }\n  [Symbol.asyncIterator]() {\n    return this._iterator;\n  }\n  static async fromBytes(bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array');\n    }\n    return decodeIndexerComplete(decoder.bytesReader(bytes));\n  }\n  static async fromIterable(asyncIterable) {\n    if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n      throw new TypeError('fromIterable() requires an async iterable');\n    }\n    return decodeIndexerComplete(decoder.asyncIterableReader(asyncIterable));\n  }\n}\nasync function decodeIndexerComplete(reader) {\n  const decoder$1 = decoder.createDecoder(reader);\n  const {version, roots} = await decoder$1.header();\n  return new CarIndexer(version, roots, decoder$1.blocksIndex());\n}\n\nexports.CarIndexer = CarIndexer;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction noop() {\n}\nfunction create() {\n  const chunkQueue = [];\n  let drainer = null;\n  let drainerResolver = noop;\n  let ended = false;\n  let outWait = null;\n  let outWaitResolver = noop;\n  const makeDrainer = () => {\n    if (!drainer) {\n      drainer = new Promise(resolve => {\n        drainerResolver = () => {\n          drainer = null;\n          drainerResolver = noop;\n          resolve();\n        };\n      });\n    }\n    return drainer;\n  };\n  const writer = {\n    write(chunk) {\n      chunkQueue.push(chunk);\n      const drainer = makeDrainer();\n      outWaitResolver();\n      return drainer;\n    },\n    async end() {\n      ended = true;\n      const drainer = makeDrainer();\n      outWaitResolver();\n      return drainer;\n    }\n  };\n  const iterator = {\n    async next() {\n      const chunk = chunkQueue.shift();\n      if (chunk) {\n        if (chunkQueue.length === 0) {\n          drainerResolver();\n        }\n        return {\n          done: false,\n          value: chunk\n        };\n      }\n      if (ended) {\n        drainerResolver();\n        return {\n          done: true,\n          value: undefined\n        };\n      }\n      if (!outWait) {\n        outWait = new Promise(resolve => {\n          outWaitResolver = () => {\n            outWait = null;\n            outWaitResolver = noop;\n            return resolve(iterator.next());\n          };\n        });\n      }\n      return outWait;\n    }\n  };\n  return {\n    writer,\n    iterator\n  };\n}\n\nexports.create = create;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar decoder = require('./decoder.js');\n\nclass CarIteratorBase {\n  constructor(version, roots, iterable) {\n    this._version = version;\n    this._roots = roots;\n    this._iterable = iterable;\n    this._decoded = false;\n  }\n  get version() {\n    return this._version;\n  }\n  async getRoots() {\n    return this._roots;\n  }\n}\nclass CarBlockIterator extends CarIteratorBase {\n  [Symbol.asyncIterator]() {\n    if (this._decoded) {\n      throw new Error('Cannot decode more than once');\n    }\n    if (!this._iterable) {\n      throw new Error('Block iterable not found');\n    }\n    this._decoded = true;\n    return this._iterable[Symbol.asyncIterator]();\n  }\n  static async fromBytes(bytes) {\n    const {version, roots, iterator} = await fromBytes(bytes);\n    return new CarBlockIterator(version, roots, iterator);\n  }\n  static async fromIterable(asyncIterable) {\n    const {version, roots, iterator} = await fromIterable(asyncIterable);\n    return new CarBlockIterator(version, roots, iterator);\n  }\n}\nclass CarCIDIterator extends CarIteratorBase {\n  [Symbol.asyncIterator]() {\n    if (this._decoded) {\n      throw new Error('Cannot decode more than once');\n    }\n    if (!this._iterable) {\n      throw new Error('Block iterable not found');\n    }\n    this._decoded = true;\n    const iterable = this._iterable[Symbol.asyncIterator]();\n    return {\n      async next() {\n        const next = await iterable.next();\n        if (next.done) {\n          return next;\n        }\n        return {\n          done: false,\n          value: next.value.cid\n        };\n      }\n    };\n  }\n  static async fromBytes(bytes) {\n    const {version, roots, iterator} = await fromBytes(bytes);\n    return new CarCIDIterator(version, roots, iterator);\n  }\n  static async fromIterable(asyncIterable) {\n    const {version, roots, iterator} = await fromIterable(asyncIterable);\n    return new CarCIDIterator(version, roots, iterator);\n  }\n}\nasync function fromBytes(bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new TypeError('fromBytes() requires a Uint8Array');\n  }\n  return decodeIterator(decoder.bytesReader(bytes));\n}\nasync function fromIterable(asyncIterable) {\n  if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n    throw new TypeError('fromIterable() requires an async iterable');\n  }\n  return decodeIterator(decoder.asyncIterableReader(asyncIterable));\n}\nasync function decodeIterator(reader) {\n  const decoder$1 = decoder.createDecoder(reader);\n  const {version, roots} = await decoder$1.header();\n  return {\n    version,\n    roots,\n    iterator: decoder$1.blocks()\n  };\n}\n\nexports.CarBlockIterator = CarBlockIterator;\nexports.CarCIDIterator = CarCIDIterator;\nexports.CarIteratorBase = CarIteratorBase;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar decoder = require('./decoder.js');\n\nclass CarReader {\n  constructor(version, roots, blocks) {\n    this._version = version;\n    this._roots = roots;\n    this._blocks = blocks;\n    this._keys = blocks.map(b => b.cid.toString());\n  }\n  get version() {\n    return this._version;\n  }\n  async getRoots() {\n    return this._roots;\n  }\n  async has(key) {\n    return this._keys.indexOf(key.toString()) > -1;\n  }\n  async get(key) {\n    const index = this._keys.indexOf(key.toString());\n    return index > -1 ? this._blocks[index] : undefined;\n  }\n  async *blocks() {\n    for (const block of this._blocks) {\n      yield block;\n    }\n  }\n  async *cids() {\n    for (const block of this._blocks) {\n      yield block.cid;\n    }\n  }\n  static async fromBytes(bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array');\n    }\n    return decodeReaderComplete(decoder.bytesReader(bytes));\n  }\n  static async fromIterable(asyncIterable) {\n    if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n      throw new TypeError('fromIterable() requires an async iterable');\n    }\n    return decodeReaderComplete(decoder.asyncIterableReader(asyncIterable));\n  }\n}\nasync function decodeReaderComplete(reader) {\n  const decoder$1 = decoder.createDecoder(reader);\n  const {version, roots} = await decoder$1.header();\n  const blocks = [];\n  for await (const block of decoder$1.blocks()) {\n    blocks.push(block);\n  }\n  return new CarReader(version, roots, blocks);\n}\nconst __browser = true;\n\nexports.CarReader = CarReader;\nexports.__browser = __browser;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar fs = require('fs');\nvar util = require('util');\nvar readerBrowser = require('./reader-browser.js');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nconst fsread = util.promisify(fs__default['default'].read);\nclass CarReader extends readerBrowser.CarReader {\n  static async readRaw(fd, blockIndex) {\n    const {cid, blockLength, blockOffset} = blockIndex;\n    const bytes = new Uint8Array(blockLength);\n    let read;\n    if (typeof fd === 'number') {\n      read = (await fsread(fd, bytes, 0, blockLength, blockOffset)).bytesRead;\n    } else if (typeof fd === 'object' && typeof fd.read === 'function') {\n      read = (await fd.read(bytes, 0, blockLength, blockOffset)).bytesRead;\n    } else {\n      throw new TypeError('Bad fd');\n    }\n    if (read !== blockLength) {\n      throw new Error(`Failed to read entire block (${ read } instead of ${ blockLength })`);\n    }\n    return {\n      cid,\n      bytes\n    };\n  }\n}\nconst __browser = false;\n\nexports.CarReader = CarReader;\nexports.__browser = __browser;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar cid = require('multiformats/cid');\nvar encoder = require('./encoder.js');\nvar iteratorChannel = require('./iterator-channel.js');\nvar decoder = require('./decoder.js');\n\nclass CarWriter {\n  constructor(roots, encoder) {\n    this._encoder = encoder;\n    this._mutex = encoder.setRoots(roots);\n    this._ended = false;\n  }\n  async put(block) {\n    if (!(block.bytes instanceof Uint8Array) || !block.cid) {\n      throw new TypeError('Can only write {cid, bytes} objects');\n    }\n    if (this._ended) {\n      throw new Error('Already closed');\n    }\n    const cid$1 = cid.CID.asCID(block.cid);\n    if (!cid$1) {\n      throw new TypeError('Can only write {cid, bytes} objects');\n    }\n    this._mutex = this._mutex.then(() => this._encoder.writeBlock({\n      cid: cid$1,\n      bytes: block.bytes\n    }));\n    return this._mutex;\n  }\n  async close() {\n    if (this._ended) {\n      throw new Error('Already closed');\n    }\n    await this._mutex;\n    this._ended = true;\n    return this._encoder.close();\n  }\n  static create(roots) {\n    roots = toRoots(roots);\n    const {encoder, iterator} = encodeWriter();\n    const writer = new CarWriter(roots, encoder);\n    const out = new CarWriterOut(iterator);\n    return {\n      writer,\n      out\n    };\n  }\n  static createAppender() {\n    const {encoder, iterator} = encodeWriter();\n    encoder.setRoots = () => Promise.resolve();\n    const writer = new CarWriter([], encoder);\n    const out = new CarWriterOut(iterator);\n    return {\n      writer,\n      out\n    };\n  }\n  static async updateRootsInBytes(bytes, roots) {\n    const reader = decoder.bytesReader(bytes);\n    await decoder.readHeader(reader);\n    const newHeader = encoder.createHeader(roots);\n    if (reader.pos !== newHeader.length) {\n      throw new Error(`updateRoots() can only overwrite a header of the same length (old header is ${ reader.pos } bytes, new header is ${ newHeader.length } bytes)`);\n    }\n    bytes.set(newHeader, 0);\n    return bytes;\n  }\n}\nclass CarWriterOut {\n  constructor(iterator) {\n    this._iterator = iterator;\n  }\n  [Symbol.asyncIterator]() {\n    if (this._iterating) {\n      throw new Error('Multiple iterator not supported');\n    }\n    this._iterating = true;\n    return this._iterator;\n  }\n}\nfunction encodeWriter() {\n  const iw = iteratorChannel.create();\n  const {writer, iterator} = iw;\n  const encoder$1 = encoder.createEncoder(writer);\n  return {\n    encoder: encoder$1,\n    iterator\n  };\n}\nfunction toRoots(roots) {\n  if (roots === undefined) {\n    return [];\n  }\n  if (!Array.isArray(roots)) {\n    const cid$1 = cid.CID.asCID(roots);\n    if (!cid$1) {\n      throw new TypeError('roots must be a single CID or an array of CIDs');\n    }\n    return [cid$1];\n  }\n  const _roots = [];\n  for (const root of roots) {\n    const _root = cid.CID.asCID(root);\n    if (!_root) {\n      throw new TypeError('roots must be a single CID or an array of CIDs');\n    }\n    _roots.push(_root);\n  }\n  return _roots;\n}\nconst __browser = true;\n\nexports.CarWriter = CarWriter;\nexports.CarWriterOut = CarWriterOut;\nexports.__browser = __browser;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar fs = require('fs');\nvar util = require('util');\nvar writerBrowser = require('./writer-browser.js');\nvar decoder = require('./decoder.js');\nvar encoder = require('./encoder.js');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\n\nconst fsread = util.promisify(fs__default['default'].read);\nconst fswrite = util.promisify(fs__default['default'].write);\nclass CarWriter extends writerBrowser.CarWriter {\n  static async updateRootsInFile(fd, roots) {\n    const chunkSize = 256;\n    let bytes;\n    let offset = 0;\n    let readChunk;\n    if (typeof fd === 'number') {\n      readChunk = async () => (await fsread(fd, bytes, 0, chunkSize, offset)).bytesRead;\n    } else if (typeof fd === 'object' && typeof fd.read === 'function') {\n      readChunk = async () => (await fd.read(bytes, 0, chunkSize, offset)).bytesRead;\n    } else {\n      throw new TypeError('Bad fd');\n    }\n    const fdReader = decoder.chunkReader(async () => {\n      bytes = new Uint8Array(chunkSize);\n      const read = await readChunk();\n      offset += read;\n      return read < chunkSize ? bytes.subarray(0, read) : bytes;\n    });\n    await decoder.readHeader(fdReader);\n    const newHeader = encoder.createHeader(roots);\n    if (fdReader.pos !== newHeader.length) {\n      throw new Error(`updateRoots() can only overwrite a header of the same length (old header is ${ fdReader.pos } bytes, new header is ${ newHeader.length } bytes)`);\n    }\n    if (typeof fd === 'number') {\n      await fswrite(fd, newHeader, 0, newHeader.length, 0);\n    } else if (typeof fd === 'object' && typeof fd.read === 'function') {\n      await fd.write(newHeader, 0, newHeader.length, 0);\n    }\n  }\n}\nconst __browser = false;\n\nexports.CarWriter = CarWriter;\nexports.__browser = __browser;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar cborg = require('cborg');\nvar cid = require('multiformats/cid');\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n  n['default'] = e;\n  return Object.freeze(n);\n}\n\nvar cborg__namespace = /*#__PURE__*/_interopNamespace(cborg);\n\nconst CID_CBOR_TAG = 42;\nfunction cidEncoder(obj) {\n  if (obj.asCID !== obj) {\n    return null;\n  }\n  const cid$1 = cid.CID.asCID(obj);\n  if (!cid$1) {\n    return null;\n  }\n  const bytes = new Uint8Array(cid$1.bytes.byteLength + 1);\n  bytes.set(cid$1.bytes, 1);\n  return [\n    new cborg__namespace.Token(cborg__namespace.Type.tag, CID_CBOR_TAG),\n    new cborg__namespace.Token(cborg__namespace.Type.bytes, bytes)\n  ];\n}\nfunction undefinedEncoder() {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded');\n}\nfunction numberEncoder(num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n  return null;\n}\nconst encodeOptions = {\n  float64: true,\n  typeEncoders: {\n    Object: cidEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n};\nfunction cidDecoder(bytes) {\n  if (bytes[0] !== 0) {\n    throw new Error('Invalid CID for CBOR tag 42; expected leading 0x00');\n  }\n  return cid.CID.decode(bytes.subarray(1));\n}\nconst decodeOptions = {\n  allowIndefinite: false,\n  allowUndefined: false,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true,\n  strict: true,\n  useMaps: false,\n  tags: []\n};\ndecodeOptions.tags[CID_CBOR_TAG] = cidDecoder;\nconst name = 'dag-cbor';\nconst code = 113;\nconst encode = node => cborg__namespace.encode(node, encodeOptions);\nconst decode = data => cborg__namespace.decode(data, decodeOptions);\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar cid = require('multiformats/cid');\nvar pbDecode = require('./pb-decode.js');\nvar pbEncode = require('./pb-encode.js');\nvar util = require('./util.js');\n\nconst name = 'dag-pb';\nconst code = 112;\nfunction encode(node) {\n  util.validate(node);\n  const pbn = {};\n  if (node.Links) {\n    pbn.Links = node.Links.map(l => {\n      const link = {};\n      if (l.Hash) {\n        link.Hash = l.Hash.bytes;\n      }\n      if (l.Name !== undefined) {\n        link.Name = l.Name;\n      }\n      if (l.Tsize !== undefined) {\n        link.Tsize = l.Tsize;\n      }\n      return link;\n    });\n  }\n  if (node.Data) {\n    pbn.Data = node.Data;\n  }\n  return pbEncode.encodeNode(pbn);\n}\nfunction decode(bytes) {\n  const pbn = pbDecode.decodeNode(bytes);\n  const node = {};\n  if (pbn.Data) {\n    node.Data = pbn.Data;\n  }\n  if (pbn.Links) {\n    node.Links = pbn.Links.map(l => {\n      const link = {};\n      try {\n        link.Hash = cid.CID.decode(l.Hash);\n      } catch (e) {\n      }\n      if (!link.Hash) {\n        throw new Error('Invalid Hash field found in link, expected CID');\n      }\n      if (l.Name !== undefined) {\n        link.Name = l.Name;\n      }\n      if (l.Tsize !== undefined) {\n        link.Tsize = l.Tsize;\n      }\n      return link;\n    });\n  }\n  return node;\n}\n\nexports.createLink = util.createLink;\nexports.createNode = util.createNode;\nexports.prepare = util.prepare;\nexports.validate = util.validate;\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst textDecoder = new TextDecoder();\nfunction decodeVarint(bytes, offset) {\n  let v = 0;\n  for (let shift = 0;; shift += 7) {\n    if (shift >= 64) {\n      throw new Error('protobuf: varint overflow');\n    }\n    if (offset >= bytes.length) {\n      throw new Error('protobuf: unexpected end of data');\n    }\n    const b = bytes[offset++];\n    v += shift < 28 ? (b & 127) << shift : (b & 127) * 2 ** shift;\n    if (b < 128) {\n      break;\n    }\n  }\n  return [\n    v,\n    offset\n  ];\n}\nfunction decodeBytes(bytes, offset) {\n  let byteLen;\n  [byteLen, offset] = decodeVarint(bytes, offset);\n  const postOffset = offset + byteLen;\n  if (byteLen < 0 || postOffset < 0) {\n    throw new Error('protobuf: invalid length');\n  }\n  if (postOffset > bytes.length) {\n    throw new Error('protobuf: unexpected end of data');\n  }\n  return [\n    bytes.subarray(offset, postOffset),\n    postOffset\n  ];\n}\nfunction decodeKey(bytes, index) {\n  let wire;\n  [wire, index] = decodeVarint(bytes, index);\n  return [\n    wire & 7,\n    wire >> 3,\n    index\n  ];\n}\nfunction decodeLink(bytes) {\n  const link = {};\n  const l = bytes.length;\n  let index = 0;\n  while (index < l) {\n    let wireType, fieldNum;\n    [wireType, fieldNum, index] = decodeKey(bytes, index);\n    if (fieldNum === 1) {\n      if (link.Hash) {\n        throw new Error('protobuf: (PBLink) duplicate Hash section');\n      }\n      if (wireType !== 2) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${ wireType }) for Hash`);\n      }\n      if (link.Name !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Name before Hash');\n      }\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Tsize before Hash');\n      }\n      ;\n      [link.Hash, index] = decodeBytes(bytes, index);\n    } else if (fieldNum === 2) {\n      if (link.Name !== undefined) {\n        throw new Error('protobuf: (PBLink) duplicate Name section');\n      }\n      if (wireType !== 2) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${ wireType }) for Name`);\n      }\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Tsize before Name');\n      }\n      let byts;\n      [byts, index] = decodeBytes(bytes, index);\n      link.Name = textDecoder.decode(byts);\n    } else if (fieldNum === 3) {\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) duplicate Tsize section');\n      }\n      if (wireType !== 0) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${ wireType }) for Tsize`);\n      }\n      ;\n      [link.Tsize, index] = decodeVarint(bytes, index);\n    } else {\n      throw new Error(`protobuf: (PBLink) invalid fieldNumber, expected 1, 2 or 3, got ${ fieldNum }`);\n    }\n  }\n  if (index > l) {\n    throw new Error('protobuf: (PBLink) unexpected end of data');\n  }\n  return link;\n}\nfunction decodeNode(bytes) {\n  const l = bytes.length;\n  let index = 0;\n  let links;\n  let linksBeforeData = false;\n  let data;\n  while (index < l) {\n    let wireType, fieldNum;\n    [wireType, fieldNum, index] = decodeKey(bytes, index);\n    if (wireType !== 2) {\n      throw new Error(`protobuf: (PBNode) invalid wireType, expected 2, got ${ wireType }`);\n    }\n    if (fieldNum === 1) {\n      if (data) {\n        throw new Error('protobuf: (PBNode) duplicate Data section');\n      }\n      ;\n      [data, index] = decodeBytes(bytes, index);\n      if (links) {\n        linksBeforeData = true;\n      }\n    } else if (fieldNum === 2) {\n      if (linksBeforeData) {\n        throw new Error('protobuf: (PBNode) duplicate Links section');\n      } else if (!links) {\n        links = [];\n      }\n      let byts;\n      [byts, index] = decodeBytes(bytes, index);\n      links.push(decodeLink(byts));\n    } else {\n      throw new Error(`protobuf: (PBNode) invalid fieldNumber, expected 1 or 2, got ${ fieldNum }`);\n    }\n  }\n  if (index > l) {\n    throw new Error('protobuf: (PBNode) unexpected end of data');\n  }\n  const node = {};\n  if (data) {\n    node.Data = data;\n  }\n  node.Links = links || [];\n  return node;\n}\n\nexports.decodeNode = decodeNode;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst textEncoder = new TextEncoder();\nconst maxInt32 = 2 ** 32;\nconst maxUInt32 = 2 ** 31;\nfunction encodeLink(link, bytes) {\n  let i = bytes.length;\n  if (typeof link.Tsize === 'number') {\n    if (link.Tsize < 0) {\n      throw new Error('Tsize cannot be negative');\n    }\n    if (!Number.isSafeInteger(link.Tsize)) {\n      throw new Error('Tsize too large for encoding');\n    }\n    i = encodeVarint(bytes, i, link.Tsize) - 1;\n    bytes[i] = 24;\n  }\n  if (typeof link.Name === 'string') {\n    const nameBytes = textEncoder.encode(link.Name);\n    i -= nameBytes.length;\n    bytes.set(nameBytes, i);\n    i = encodeVarint(bytes, i, nameBytes.length) - 1;\n    bytes[i] = 18;\n  }\n  if (link.Hash) {\n    i -= link.Hash.length;\n    bytes.set(link.Hash, i);\n    i = encodeVarint(bytes, i, link.Hash.length) - 1;\n    bytes[i] = 10;\n  }\n  return bytes.length - i;\n}\nfunction encodeNode(node) {\n  const size = sizeNode(node);\n  const bytes = new Uint8Array(size);\n  let i = size;\n  if (node.Data) {\n    i -= node.Data.length;\n    bytes.set(node.Data, i);\n    i = encodeVarint(bytes, i, node.Data.length) - 1;\n    bytes[i] = 10;\n  }\n  if (node.Links) {\n    for (let index = node.Links.length - 1; index >= 0; index--) {\n      const size = encodeLink(node.Links[index], bytes.subarray(0, i));\n      i -= size;\n      i = encodeVarint(bytes, i, size) - 1;\n      bytes[i] = 18;\n    }\n  }\n  return bytes;\n}\nfunction sizeLink(link) {\n  let n = 0;\n  if (link.Hash) {\n    const l = link.Hash.length;\n    n += 1 + l + sov(l);\n  }\n  if (typeof link.Name === 'string') {\n    const l = textEncoder.encode(link.Name).length;\n    n += 1 + l + sov(l);\n  }\n  if (typeof link.Tsize === 'number') {\n    n += 1 + sov(link.Tsize);\n  }\n  return n;\n}\nfunction sizeNode(node) {\n  let n = 0;\n  if (node.Data) {\n    const l = node.Data.length;\n    n += 1 + l + sov(l);\n  }\n  if (node.Links) {\n    for (const link of node.Links) {\n      const l = sizeLink(link);\n      n += 1 + l + sov(l);\n    }\n  }\n  return n;\n}\nfunction encodeVarint(bytes, offset, v) {\n  offset -= sov(v);\n  const base = offset;\n  while (v >= maxUInt32) {\n    bytes[offset++] = v & 127 | 128;\n    v /= 128;\n  }\n  while (v >= 128) {\n    bytes[offset++] = v & 127 | 128;\n    v >>>= 7;\n  }\n  bytes[offset] = v;\n  return base;\n}\nfunction sov(x) {\n  if (x % 2 === 0) {\n    x++;\n  }\n  return Math.floor((len64(x) + 6) / 7);\n}\nfunction len64(x) {\n  let n = 0;\n  if (x >= maxInt32) {\n    x = Math.floor(x / maxInt32);\n    n = 32;\n  }\n  if (x >= 1 << 16) {\n    x >>>= 16;\n    n += 16;\n  }\n  if (x >= 1 << 8) {\n    x >>>= 8;\n    n += 8;\n  }\n  return n + len8tab[x];\n}\nconst len8tab = [\n  0,\n  1,\n  2,\n  2,\n  3,\n  3,\n  3,\n  3,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8\n];\n\nexports.encodeNode = encodeNode;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar cid = require('multiformats/cid');\n\nconst pbNodeProperties = [\n  'Data',\n  'Links'\n];\nconst pbLinkProperties = [\n  'Hash',\n  'Name',\n  'Tsize'\n];\nconst textEncoder = new TextEncoder();\nfunction linkComparator(a, b) {\n  if (a === b) {\n    return 0;\n  }\n  const abuf = a.Name ? textEncoder.encode(a.Name) : [];\n  const bbuf = b.Name ? textEncoder.encode(b.Name) : [];\n  let x = abuf.length;\n  let y = bbuf.length;\n  for (let i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (abuf[i] !== bbuf[i]) {\n      x = abuf[i];\n      y = bbuf[i];\n      break;\n    }\n  }\n  return x < y ? -1 : y < x ? 1 : 0;\n}\nfunction hasOnlyProperties(node, properties) {\n  return !Object.keys(node).some(p => !properties.includes(p));\n}\nfunction asLink(link) {\n  if (typeof link.asCID === 'object') {\n    const Hash = cid.CID.asCID(link);\n    if (!Hash) {\n      throw new TypeError('Invalid DAG-PB form');\n    }\n    return { Hash };\n  }\n  if (typeof link !== 'object' || Array.isArray(link)) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n  const pbl = {};\n  if (link.Hash) {\n    let cid$1 = cid.CID.asCID(link.Hash);\n    try {\n      if (!cid$1) {\n        if (typeof link.Hash === 'string') {\n          cid$1 = cid.CID.parse(link.Hash);\n        } else if (link.Hash instanceof Uint8Array) {\n          cid$1 = cid.CID.decode(link.Hash);\n        }\n      }\n    } catch (e) {\n      throw new TypeError(`Invalid DAG-PB form: ${ e.message }`);\n    }\n    if (cid$1) {\n      pbl.Hash = cid$1;\n    }\n  }\n  if (!pbl.Hash) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n  if (typeof link.Name === 'string') {\n    pbl.Name = link.Name;\n  }\n  if (typeof link.Tsize === 'number') {\n    pbl.Tsize = link.Tsize;\n  }\n  return pbl;\n}\nfunction prepare(node) {\n  if (node instanceof Uint8Array || typeof node === 'string') {\n    node = { Data: node };\n  }\n  if (typeof node !== 'object' || Array.isArray(node)) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n  const pbn = {};\n  if (node.Data !== undefined) {\n    if (typeof node.Data === 'string') {\n      pbn.Data = textEncoder.encode(node.Data);\n    } else if (node.Data instanceof Uint8Array) {\n      pbn.Data = node.Data;\n    } else {\n      throw new TypeError('Invalid DAG-PB form');\n    }\n  }\n  if (node.Links !== undefined) {\n    if (Array.isArray(node.Links)) {\n      pbn.Links = node.Links.map(asLink);\n      pbn.Links.sort(linkComparator);\n    } else {\n      throw new TypeError('Invalid DAG-PB form');\n    }\n  } else {\n    pbn.Links = [];\n  }\n  return pbn;\n}\nfunction validate(node) {\n  if (!node || typeof node !== 'object' || Array.isArray(node)) {\n    throw new TypeError('Invalid DAG-PB form');\n  }\n  if (!hasOnlyProperties(node, pbNodeProperties)) {\n    throw new TypeError('Invalid DAG-PB form (extraneous properties)');\n  }\n  if (node.Data !== undefined && !(node.Data instanceof Uint8Array)) {\n    throw new TypeError('Invalid DAG-PB form (Data must be a Uint8Array)');\n  }\n  if (!Array.isArray(node.Links)) {\n    throw new TypeError('Invalid DAG-PB form (Links must be an array)');\n  }\n  for (let i = 0; i < node.Links.length; i++) {\n    const link = node.Links[i];\n    if (!link || typeof link !== 'object' || Array.isArray(link)) {\n      throw new TypeError('Invalid DAG-PB form (bad link object)');\n    }\n    if (!hasOnlyProperties(link, pbLinkProperties)) {\n      throw new TypeError('Invalid DAG-PB form (extraneous properties on link object)');\n    }\n    if (!link.Hash) {\n      throw new TypeError('Invalid DAG-PB form (link must have a Hash)');\n    }\n    if (link.Hash.asCID !== link.Hash) {\n      throw new TypeError('Invalid DAG-PB form (link Hash must be a CID)');\n    }\n    if (link.Name !== undefined && typeof link.Name !== 'string') {\n      throw new TypeError('Invalid DAG-PB form (link Name must be a string)');\n    }\n    if (link.Tsize !== undefined && (typeof link.Tsize !== 'number' || link.Tsize % 1 !== 0)) {\n      throw new TypeError('Invalid DAG-PB form (link Tsize must be an integer)');\n    }\n    if (i > 0 && linkComparator(link, node.Links[i - 1]) === -1) {\n      throw new TypeError('Invalid DAG-PB form (links must be sorted by Name bytes)');\n    }\n  }\n}\nfunction createNode(data, links = []) {\n  return prepare({\n    Data: data,\n    Links: links\n  });\n}\nfunction createLink(name, size, cid) {\n  return asLink({\n    Hash: cid,\n    Name: name,\n    Tsize: size\n  });\n}\n\nexports.createLink = createLink;\nexports.createNode = createNode;\nexports.prepare = prepare;\nexports.validate = validate;\n","\"use strict\";\r\nmodule.exports = asPromise;\r\n\r\n/**\r\n * Callback as used by {@link util.asPromise}.\r\n * @typedef asPromiseCallback\r\n * @type {function}\r\n * @param {Error|null} error Error, if any\r\n * @param {...*} params Additional arguments\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Returns a promise from a node-style callback function.\r\n * @memberof util\r\n * @param {asPromiseCallback} fn Function to call\r\n * @param {*} ctx Function context\r\n * @param {...*} params Function arguments\r\n * @returns {Promise<*>} Promisified function\r\n */\r\nfunction asPromise(fn, ctx/*, varargs */) {\r\n    var params  = new Array(arguments.length - 1),\r\n        offset  = 0,\r\n        index   = 2,\r\n        pending = true;\r\n    while (index < arguments.length)\r\n        params[offset++] = arguments[index++];\r\n    return new Promise(function executor(resolve, reject) {\r\n        params[offset] = function callback(err/*, varargs */) {\r\n            if (pending) {\r\n                pending = false;\r\n                if (err)\r\n                    reject(err);\r\n                else {\r\n                    var params = new Array(arguments.length - 1),\r\n                        offset = 0;\r\n                    while (offset < params.length)\r\n                        params[offset++] = arguments[offset];\r\n                    resolve.apply(null, params);\r\n                }\r\n            }\r\n        };\r\n        try {\r\n            fn.apply(ctx || null, params);\r\n        } catch (err) {\r\n            if (pending) {\r\n                pending = false;\r\n                reject(err);\r\n            }\r\n        }\r\n    });\r\n}\r\n","\"use strict\";\r\n\r\n/**\r\n * A minimal base64 implementation for number arrays.\r\n * @memberof util\r\n * @namespace\r\n */\r\nvar base64 = exports;\r\n\r\n/**\r\n * Calculates the byte length of a base64 encoded string.\r\n * @param {string} string Base64 encoded string\r\n * @returns {number} Byte length\r\n */\r\nbase64.length = function length(string) {\r\n    var p = string.length;\r\n    if (!p)\r\n        return 0;\r\n    var n = 0;\r\n    while (--p % 4 > 1 && string.charAt(p) === \"=\")\r\n        ++n;\r\n    return Math.ceil(string.length * 3) / 4 - n;\r\n};\r\n\r\n// Base64 encoding table\r\nvar b64 = new Array(64);\r\n\r\n// Base64 decoding table\r\nvar s64 = new Array(123);\r\n\r\n// 65..90, 97..122, 48..57, 43, 47\r\nfor (var i = 0; i < 64;)\r\n    s64[b64[i] = i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i - 59 | 43] = i++;\r\n\r\n/**\r\n * Encodes a buffer to a base64 encoded string.\r\n * @param {Uint8Array} buffer Source buffer\r\n * @param {number} start Source start\r\n * @param {number} end Source end\r\n * @returns {string} Base64 encoded string\r\n */\r\nbase64.encode = function encode(buffer, start, end) {\r\n    var parts = null,\r\n        chunk = [];\r\n    var i = 0, // output index\r\n        j = 0, // goto index\r\n        t;     // temporary\r\n    while (start < end) {\r\n        var b = buffer[start++];\r\n        switch (j) {\r\n            case 0:\r\n                chunk[i++] = b64[b >> 2];\r\n                t = (b & 3) << 4;\r\n                j = 1;\r\n                break;\r\n            case 1:\r\n                chunk[i++] = b64[t | b >> 4];\r\n                t = (b & 15) << 2;\r\n                j = 2;\r\n                break;\r\n            case 2:\r\n                chunk[i++] = b64[t | b >> 6];\r\n                chunk[i++] = b64[b & 63];\r\n                j = 0;\r\n                break;\r\n        }\r\n        if (i > 8191) {\r\n            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));\r\n            i = 0;\r\n        }\r\n    }\r\n    if (j) {\r\n        chunk[i++] = b64[t];\r\n        chunk[i++] = 61;\r\n        if (j === 1)\r\n            chunk[i++] = 61;\r\n    }\r\n    if (parts) {\r\n        if (i)\r\n            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\r\n        return parts.join(\"\");\r\n    }\r\n    return String.fromCharCode.apply(String, chunk.slice(0, i));\r\n};\r\n\r\nvar invalidEncoding = \"invalid encoding\";\r\n\r\n/**\r\n * Decodes a base64 encoded string to a buffer.\r\n * @param {string} string Source string\r\n * @param {Uint8Array} buffer Destination buffer\r\n * @param {number} offset Destination offset\r\n * @returns {number} Number of bytes written\r\n * @throws {Error} If encoding is invalid\r\n */\r\nbase64.decode = function decode(string, buffer, offset) {\r\n    var start = offset;\r\n    var j = 0, // goto index\r\n        t;     // temporary\r\n    for (var i = 0; i < string.length;) {\r\n        var c = string.charCodeAt(i++);\r\n        if (c === 61 && j > 1)\r\n            break;\r\n        if ((c = s64[c]) === undefined)\r\n            throw Error(invalidEncoding);\r\n        switch (j) {\r\n            case 0:\r\n                t = c;\r\n                j = 1;\r\n                break;\r\n            case 1:\r\n                buffer[offset++] = t << 2 | (c & 48) >> 4;\r\n                t = c;\r\n                j = 2;\r\n                break;\r\n            case 2:\r\n                buffer[offset++] = (t & 15) << 4 | (c & 60) >> 2;\r\n                t = c;\r\n                j = 3;\r\n                break;\r\n            case 3:\r\n                buffer[offset++] = (t & 3) << 6 | c;\r\n                j = 0;\r\n                break;\r\n        }\r\n    }\r\n    if (j === 1)\r\n        throw Error(invalidEncoding);\r\n    return offset - start;\r\n};\r\n\r\n/**\r\n * Tests if the specified string appears to be base64 encoded.\r\n * @param {string} string String to test\r\n * @returns {boolean} `true` if probably base64 encoded, otherwise false\r\n */\r\nbase64.test = function test(string) {\r\n    return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(string);\r\n};\r\n","\"use strict\";\r\nmodule.exports = EventEmitter;\r\n\r\n/**\r\n * Constructs a new event emitter instance.\r\n * @classdesc A minimal event emitter.\r\n * @memberof util\r\n * @constructor\r\n */\r\nfunction EventEmitter() {\r\n\r\n    /**\r\n     * Registered listeners.\r\n     * @type {Object.<string,*>}\r\n     * @private\r\n     */\r\n    this._listeners = {};\r\n}\r\n\r\n/**\r\n * Registers an event listener.\r\n * @param {string} evt Event name\r\n * @param {function} fn Listener\r\n * @param {*} [ctx] Listener context\r\n * @returns {util.EventEmitter} `this`\r\n */\r\nEventEmitter.prototype.on = function on(evt, fn, ctx) {\r\n    (this._listeners[evt] || (this._listeners[evt] = [])).push({\r\n        fn  : fn,\r\n        ctx : ctx || this\r\n    });\r\n    return this;\r\n};\r\n\r\n/**\r\n * Removes an event listener or any matching listeners if arguments are omitted.\r\n * @param {string} [evt] Event name. Removes all listeners if omitted.\r\n * @param {function} [fn] Listener to remove. Removes all listeners of `evt` if omitted.\r\n * @returns {util.EventEmitter} `this`\r\n */\r\nEventEmitter.prototype.off = function off(evt, fn) {\r\n    if (evt === undefined)\r\n        this._listeners = {};\r\n    else {\r\n        if (fn === undefined)\r\n            this._listeners[evt] = [];\r\n        else {\r\n            var listeners = this._listeners[evt];\r\n            for (var i = 0; i < listeners.length;)\r\n                if (listeners[i].fn === fn)\r\n                    listeners.splice(i, 1);\r\n                else\r\n                    ++i;\r\n        }\r\n    }\r\n    return this;\r\n};\r\n\r\n/**\r\n * Emits an event by calling its listeners with the specified arguments.\r\n * @param {string} evt Event name\r\n * @param {...*} args Arguments\r\n * @returns {util.EventEmitter} `this`\r\n */\r\nEventEmitter.prototype.emit = function emit(evt) {\r\n    var listeners = this._listeners[evt];\r\n    if (listeners) {\r\n        var args = [],\r\n            i = 1;\r\n        for (; i < arguments.length;)\r\n            args.push(arguments[i++]);\r\n        for (i = 0; i < listeners.length;)\r\n            listeners[i].fn.apply(listeners[i++].ctx, args);\r\n    }\r\n    return this;\r\n};\r\n","\"use strict\";\r\n\r\nmodule.exports = factory(factory);\r\n\r\n/**\r\n * Reads / writes floats / doubles from / to buffers.\r\n * @name util.float\r\n * @namespace\r\n */\r\n\r\n/**\r\n * Writes a 32 bit float to a buffer using little endian byte order.\r\n * @name util.float.writeFloatLE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Writes a 32 bit float to a buffer using big endian byte order.\r\n * @name util.float.writeFloatBE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Reads a 32 bit float from a buffer using little endian byte order.\r\n * @name util.float.readFloatLE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n/**\r\n * Reads a 32 bit float from a buffer using big endian byte order.\r\n * @name util.float.readFloatBE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n/**\r\n * Writes a 64 bit double to a buffer using little endian byte order.\r\n * @name util.float.writeDoubleLE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Writes a 64 bit double to a buffer using big endian byte order.\r\n * @name util.float.writeDoubleBE\r\n * @function\r\n * @param {number} val Value to write\r\n * @param {Uint8Array} buf Target buffer\r\n * @param {number} pos Target buffer offset\r\n * @returns {undefined}\r\n */\r\n\r\n/**\r\n * Reads a 64 bit double from a buffer using little endian byte order.\r\n * @name util.float.readDoubleLE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n/**\r\n * Reads a 64 bit double from a buffer using big endian byte order.\r\n * @name util.float.readDoubleBE\r\n * @function\r\n * @param {Uint8Array} buf Source buffer\r\n * @param {number} pos Source buffer offset\r\n * @returns {number} Value read\r\n */\r\n\r\n// Factory function for the purpose of node-based testing in modified global environments\r\nfunction factory(exports) {\r\n\r\n    // float: typed array\r\n    if (typeof Float32Array !== \"undefined\") (function() {\r\n\r\n        var f32 = new Float32Array([ -0 ]),\r\n            f8b = new Uint8Array(f32.buffer),\r\n            le  = f8b[3] === 128;\r\n\r\n        function writeFloat_f32_cpy(val, buf, pos) {\r\n            f32[0] = val;\r\n            buf[pos    ] = f8b[0];\r\n            buf[pos + 1] = f8b[1];\r\n            buf[pos + 2] = f8b[2];\r\n            buf[pos + 3] = f8b[3];\r\n        }\r\n\r\n        function writeFloat_f32_rev(val, buf, pos) {\r\n            f32[0] = val;\r\n            buf[pos    ] = f8b[3];\r\n            buf[pos + 1] = f8b[2];\r\n            buf[pos + 2] = f8b[1];\r\n            buf[pos + 3] = f8b[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.writeFloatLE = le ? writeFloat_f32_cpy : writeFloat_f32_rev;\r\n        /* istanbul ignore next */\r\n        exports.writeFloatBE = le ? writeFloat_f32_rev : writeFloat_f32_cpy;\r\n\r\n        function readFloat_f32_cpy(buf, pos) {\r\n            f8b[0] = buf[pos    ];\r\n            f8b[1] = buf[pos + 1];\r\n            f8b[2] = buf[pos + 2];\r\n            f8b[3] = buf[pos + 3];\r\n            return f32[0];\r\n        }\r\n\r\n        function readFloat_f32_rev(buf, pos) {\r\n            f8b[3] = buf[pos    ];\r\n            f8b[2] = buf[pos + 1];\r\n            f8b[1] = buf[pos + 2];\r\n            f8b[0] = buf[pos + 3];\r\n            return f32[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.readFloatLE = le ? readFloat_f32_cpy : readFloat_f32_rev;\r\n        /* istanbul ignore next */\r\n        exports.readFloatBE = le ? readFloat_f32_rev : readFloat_f32_cpy;\r\n\r\n    // float: ieee754\r\n    })(); else (function() {\r\n\r\n        function writeFloat_ieee754(writeUint, val, buf, pos) {\r\n            var sign = val < 0 ? 1 : 0;\r\n            if (sign)\r\n                val = -val;\r\n            if (val === 0)\r\n                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos);\r\n            else if (isNaN(val))\r\n                writeUint(2143289344, buf, pos);\r\n            else if (val > 3.4028234663852886e+38) // +-Infinity\r\n                writeUint((sign << 31 | 2139095040) >>> 0, buf, pos);\r\n            else if (val < 1.1754943508222875e-38) // denormal\r\n                writeUint((sign << 31 | Math.round(val / 1.401298464324817e-45)) >>> 0, buf, pos);\r\n            else {\r\n                var exponent = Math.floor(Math.log(val) / Math.LN2),\r\n                    mantissa = Math.round(val * Math.pow(2, -exponent) * 8388608) & 8388607;\r\n                writeUint((sign << 31 | exponent + 127 << 23 | mantissa) >>> 0, buf, pos);\r\n            }\r\n        }\r\n\r\n        exports.writeFloatLE = writeFloat_ieee754.bind(null, writeUintLE);\r\n        exports.writeFloatBE = writeFloat_ieee754.bind(null, writeUintBE);\r\n\r\n        function readFloat_ieee754(readUint, buf, pos) {\r\n            var uint = readUint(buf, pos),\r\n                sign = (uint >> 31) * 2 + 1,\r\n                exponent = uint >>> 23 & 255,\r\n                mantissa = uint & 8388607;\r\n            return exponent === 255\r\n                ? mantissa\r\n                ? NaN\r\n                : sign * Infinity\r\n                : exponent === 0 // denormal\r\n                ? sign * 1.401298464324817e-45 * mantissa\r\n                : sign * Math.pow(2, exponent - 150) * (mantissa + 8388608);\r\n        }\r\n\r\n        exports.readFloatLE = readFloat_ieee754.bind(null, readUintLE);\r\n        exports.readFloatBE = readFloat_ieee754.bind(null, readUintBE);\r\n\r\n    })();\r\n\r\n    // double: typed array\r\n    if (typeof Float64Array !== \"undefined\") (function() {\r\n\r\n        var f64 = new Float64Array([-0]),\r\n            f8b = new Uint8Array(f64.buffer),\r\n            le  = f8b[7] === 128;\r\n\r\n        function writeDouble_f64_cpy(val, buf, pos) {\r\n            f64[0] = val;\r\n            buf[pos    ] = f8b[0];\r\n            buf[pos + 1] = f8b[1];\r\n            buf[pos + 2] = f8b[2];\r\n            buf[pos + 3] = f8b[3];\r\n            buf[pos + 4] = f8b[4];\r\n            buf[pos + 5] = f8b[5];\r\n            buf[pos + 6] = f8b[6];\r\n            buf[pos + 7] = f8b[7];\r\n        }\r\n\r\n        function writeDouble_f64_rev(val, buf, pos) {\r\n            f64[0] = val;\r\n            buf[pos    ] = f8b[7];\r\n            buf[pos + 1] = f8b[6];\r\n            buf[pos + 2] = f8b[5];\r\n            buf[pos + 3] = f8b[4];\r\n            buf[pos + 4] = f8b[3];\r\n            buf[pos + 5] = f8b[2];\r\n            buf[pos + 6] = f8b[1];\r\n            buf[pos + 7] = f8b[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.writeDoubleLE = le ? writeDouble_f64_cpy : writeDouble_f64_rev;\r\n        /* istanbul ignore next */\r\n        exports.writeDoubleBE = le ? writeDouble_f64_rev : writeDouble_f64_cpy;\r\n\r\n        function readDouble_f64_cpy(buf, pos) {\r\n            f8b[0] = buf[pos    ];\r\n            f8b[1] = buf[pos + 1];\r\n            f8b[2] = buf[pos + 2];\r\n            f8b[3] = buf[pos + 3];\r\n            f8b[4] = buf[pos + 4];\r\n            f8b[5] = buf[pos + 5];\r\n            f8b[6] = buf[pos + 6];\r\n            f8b[7] = buf[pos + 7];\r\n            return f64[0];\r\n        }\r\n\r\n        function readDouble_f64_rev(buf, pos) {\r\n            f8b[7] = buf[pos    ];\r\n            f8b[6] = buf[pos + 1];\r\n            f8b[5] = buf[pos + 2];\r\n            f8b[4] = buf[pos + 3];\r\n            f8b[3] = buf[pos + 4];\r\n            f8b[2] = buf[pos + 5];\r\n            f8b[1] = buf[pos + 6];\r\n            f8b[0] = buf[pos + 7];\r\n            return f64[0];\r\n        }\r\n\r\n        /* istanbul ignore next */\r\n        exports.readDoubleLE = le ? readDouble_f64_cpy : readDouble_f64_rev;\r\n        /* istanbul ignore next */\r\n        exports.readDoubleBE = le ? readDouble_f64_rev : readDouble_f64_cpy;\r\n\r\n    // double: ieee754\r\n    })(); else (function() {\r\n\r\n        function writeDouble_ieee754(writeUint, off0, off1, val, buf, pos) {\r\n            var sign = val < 0 ? 1 : 0;\r\n            if (sign)\r\n                val = -val;\r\n            if (val === 0) {\r\n                writeUint(0, buf, pos + off0);\r\n                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos + off1);\r\n            } else if (isNaN(val)) {\r\n                writeUint(0, buf, pos + off0);\r\n                writeUint(2146959360, buf, pos + off1);\r\n            } else if (val > 1.7976931348623157e+308) { // +-Infinity\r\n                writeUint(0, buf, pos + off0);\r\n                writeUint((sign << 31 | 2146435072) >>> 0, buf, pos + off1);\r\n            } else {\r\n                var mantissa;\r\n                if (val < 2.2250738585072014e-308) { // denormal\r\n                    mantissa = val / 5e-324;\r\n                    writeUint(mantissa >>> 0, buf, pos + off0);\r\n                    writeUint((sign << 31 | mantissa / 4294967296) >>> 0, buf, pos + off1);\r\n                } else {\r\n                    var exponent = Math.floor(Math.log(val) / Math.LN2);\r\n                    if (exponent === 1024)\r\n                        exponent = 1023;\r\n                    mantissa = val * Math.pow(2, -exponent);\r\n                    writeUint(mantissa * 4503599627370496 >>> 0, buf, pos + off0);\r\n                    writeUint((sign << 31 | exponent + 1023 << 20 | mantissa * 1048576 & 1048575) >>> 0, buf, pos + off1);\r\n                }\r\n            }\r\n        }\r\n\r\n        exports.writeDoubleLE = writeDouble_ieee754.bind(null, writeUintLE, 0, 4);\r\n        exports.writeDoubleBE = writeDouble_ieee754.bind(null, writeUintBE, 4, 0);\r\n\r\n        function readDouble_ieee754(readUint, off0, off1, buf, pos) {\r\n            var lo = readUint(buf, pos + off0),\r\n                hi = readUint(buf, pos + off1);\r\n            var sign = (hi >> 31) * 2 + 1,\r\n                exponent = hi >>> 20 & 2047,\r\n                mantissa = 4294967296 * (hi & 1048575) + lo;\r\n            return exponent === 2047\r\n                ? mantissa\r\n                ? NaN\r\n                : sign * Infinity\r\n                : exponent === 0 // denormal\r\n                ? sign * 5e-324 * mantissa\r\n                : sign * Math.pow(2, exponent - 1075) * (mantissa + 4503599627370496);\r\n        }\r\n\r\n        exports.readDoubleLE = readDouble_ieee754.bind(null, readUintLE, 0, 4);\r\n        exports.readDoubleBE = readDouble_ieee754.bind(null, readUintBE, 4, 0);\r\n\r\n    })();\r\n\r\n    return exports;\r\n}\r\n\r\n// uint helpers\r\n\r\nfunction writeUintLE(val, buf, pos) {\r\n    buf[pos    ] =  val        & 255;\r\n    buf[pos + 1] =  val >>> 8  & 255;\r\n    buf[pos + 2] =  val >>> 16 & 255;\r\n    buf[pos + 3] =  val >>> 24;\r\n}\r\n\r\nfunction writeUintBE(val, buf, pos) {\r\n    buf[pos    ] =  val >>> 24;\r\n    buf[pos + 1] =  val >>> 16 & 255;\r\n    buf[pos + 2] =  val >>> 8  & 255;\r\n    buf[pos + 3] =  val        & 255;\r\n}\r\n\r\nfunction readUintLE(buf, pos) {\r\n    return (buf[pos    ]\r\n          | buf[pos + 1] << 8\r\n          | buf[pos + 2] << 16\r\n          | buf[pos + 3] << 24) >>> 0;\r\n}\r\n\r\nfunction readUintBE(buf, pos) {\r\n    return (buf[pos    ] << 24\r\n          | buf[pos + 1] << 16\r\n          | buf[pos + 2] << 8\r\n          | buf[pos + 3]) >>> 0;\r\n}\r\n","\"use strict\";\r\nmodule.exports = inquire;\r\n\r\n/**\r\n * Requires a module only if available.\r\n * @memberof util\r\n * @param {string} moduleName Module to require\r\n * @returns {?Object} Required module if available and not empty, otherwise `null`\r\n */\r\nfunction inquire(moduleName) {\r\n    try {\r\n        var mod = eval(\"quire\".replace(/^/,\"re\"))(moduleName); // eslint-disable-line no-eval\r\n        if (mod && (mod.length || Object.keys(mod).length))\r\n            return mod;\r\n    } catch (e) {} // eslint-disable-line no-empty\r\n    return null;\r\n}\r\n","\"use strict\";\r\nmodule.exports = pool;\r\n\r\n/**\r\n * An allocator as used by {@link util.pool}.\r\n * @typedef PoolAllocator\r\n * @type {function}\r\n * @param {number} size Buffer size\r\n * @returns {Uint8Array} Buffer\r\n */\r\n\r\n/**\r\n * A slicer as used by {@link util.pool}.\r\n * @typedef PoolSlicer\r\n * @type {function}\r\n * @param {number} start Start offset\r\n * @param {number} end End offset\r\n * @returns {Uint8Array} Buffer slice\r\n * @this {Uint8Array}\r\n */\r\n\r\n/**\r\n * A general purpose buffer pool.\r\n * @memberof util\r\n * @function\r\n * @param {PoolAllocator} alloc Allocator\r\n * @param {PoolSlicer} slice Slicer\r\n * @param {number} [size=8192] Slab size\r\n * @returns {PoolAllocator} Pooled allocator\r\n */\r\nfunction pool(alloc, slice, size) {\r\n    var SIZE   = size || 8192;\r\n    var MAX    = SIZE >>> 1;\r\n    var slab   = null;\r\n    var offset = SIZE;\r\n    return function pool_alloc(size) {\r\n        if (size < 1 || size > MAX)\r\n            return alloc(size);\r\n        if (offset + size > SIZE) {\r\n            slab = alloc(SIZE);\r\n            offset = 0;\r\n        }\r\n        var buf = slice.call(slab, offset, offset += size);\r\n        if (offset & 7) // align to 32 bit\r\n            offset = (offset | 7) + 1;\r\n        return buf;\r\n    };\r\n}\r\n","\"use strict\";\r\n\r\n/**\r\n * A minimal UTF8 implementation for number arrays.\r\n * @memberof util\r\n * @namespace\r\n */\r\nvar utf8 = exports;\r\n\r\n/**\r\n * Calculates the UTF8 byte length of a string.\r\n * @param {string} string String\r\n * @returns {number} Byte length\r\n */\r\nutf8.length = function utf8_length(string) {\r\n    var len = 0,\r\n        c = 0;\r\n    for (var i = 0; i < string.length; ++i) {\r\n        c = string.charCodeAt(i);\r\n        if (c < 128)\r\n            len += 1;\r\n        else if (c < 2048)\r\n            len += 2;\r\n        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {\r\n            ++i;\r\n            len += 4;\r\n        } else\r\n            len += 3;\r\n    }\r\n    return len;\r\n};\r\n\r\n/**\r\n * Reads UTF8 bytes as a string.\r\n * @param {Uint8Array} buffer Source buffer\r\n * @param {number} start Source start\r\n * @param {number} end Source end\r\n * @returns {string} String read\r\n */\r\nutf8.read = function utf8_read(buffer, start, end) {\r\n    var len = end - start;\r\n    if (len < 1)\r\n        return \"\";\r\n    var parts = null,\r\n        chunk = [],\r\n        i = 0, // char offset\r\n        t;     // temporary\r\n    while (start < end) {\r\n        t = buffer[start++];\r\n        if (t < 128)\r\n            chunk[i++] = t;\r\n        else if (t > 191 && t < 224)\r\n            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;\r\n        else if (t > 239 && t < 365) {\r\n            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;\r\n            chunk[i++] = 0xD800 + (t >> 10);\r\n            chunk[i++] = 0xDC00 + (t & 1023);\r\n        } else\r\n            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;\r\n        if (i > 8191) {\r\n            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));\r\n            i = 0;\r\n        }\r\n    }\r\n    if (parts) {\r\n        if (i)\r\n            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\r\n        return parts.join(\"\");\r\n    }\r\n    return String.fromCharCode.apply(String, chunk.slice(0, i));\r\n};\r\n\r\n/**\r\n * Writes a string as UTF8 bytes.\r\n * @param {string} string Source string\r\n * @param {Uint8Array} buffer Destination buffer\r\n * @param {number} offset Destination offset\r\n * @returns {number} Bytes written\r\n */\r\nutf8.write = function utf8_write(string, buffer, offset) {\r\n    var start = offset,\r\n        c1, // character 1\r\n        c2; // character 2\r\n    for (var i = 0; i < string.length; ++i) {\r\n        c1 = string.charCodeAt(i);\r\n        if (c1 < 128) {\r\n            buffer[offset++] = c1;\r\n        } else if (c1 < 2048) {\r\n            buffer[offset++] = c1 >> 6       | 192;\r\n            buffer[offset++] = c1       & 63 | 128;\r\n        } else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {\r\n            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);\r\n            ++i;\r\n            buffer[offset++] = c1 >> 18      | 240;\r\n            buffer[offset++] = c1 >> 12 & 63 | 128;\r\n            buffer[offset++] = c1 >> 6  & 63 | 128;\r\n            buffer[offset++] = c1       & 63 | 128;\r\n        } else {\r\n            buffer[offset++] = c1 >> 12      | 224;\r\n            buffer[offset++] = c1 >> 6  & 63 | 128;\r\n            buffer[offset++] = c1       & 63 | 128;\r\n        }\r\n    }\r\n    return offset - start;\r\n};\r\n","'use strict';\nmodule.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if(a===b) {\n      return [ai, bi];\n    }\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n","/* eslint-env browser */\n\n'use strict'\n\nconst browserReadableStreamToIt = require('browser-readablestream-to-it')\n\n/**\n * @param {Blob} blob\n * @returns {AsyncIterable<Uint8Array>}\n */\nfunction blobToIt (blob) {\n  if (typeof blob.stream === 'function') {\n    return browserReadableStreamToIt(blob.stream())\n  }\n\n  // firefox < 69 does not support blob.stream()\n  // @ts-ignore - response.body is optional, but in practice it's a stream.\n  return browserReadableStreamToIt(new Response(blob).body)\n}\n\nmodule.exports = blobToIt\n","var concatMap = require('concat-map');\nvar balanced = require('balanced-match');\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = m.body.indexOf(',') >= 0;\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n    return [str];\n  }\n\n  var n;\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n      if (n.length === 1) {\n        var post = m.post.length\n          ? expand(m.post, false)\n          : [''];\n        return post.map(function(p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  }\n\n  // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length)\n    var incr = n.length == 3\n      ? Math.abs(numeric(n[2]))\n      : 1;\n    var test = lte;\n    var reverse = y < x;\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n    var pad = n.some(isPadded);\n\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\')\n          c = '';\n      } else {\n        c = String(i);\n        if (pad) {\n          var need = width - c.length;\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0)\n              c = '-' + z + c.slice(1);\n            else\n              c = z + c;\n          }\n        }\n      }\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function(el) { return expand(el, false) });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion)\n        expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n","'use strict'\n\n/**\n * Turns a browser readable stream into an async iterable. Async iteration over\n * returned iterable will lock give stream, preventing any other consumer from\n * acquiring a reader. The lock will be released if iteration loop is broken. To\n * prevent stream cancelling optional `{ preventCancel: true }` could be passed\n * as a second argument.\n * @template T\n * @param {ReadableStream<T>} stream\n * @param {Object} [options]\n * @param {boolean} [options.preventCancel=boolean]\n * @returns {AsyncIterable<T>}\n */\nasync function * browserReadableStreamToIt (stream, options = {}) {\n  const reader = stream.getReader()\n\n  try {\n    while (true) {\n      const result = await reader.read()\n\n      if (result.done) {\n        return\n      }\n\n      yield result.value\n    }\n  } finally {\n    if (options.preventCancel !== true) {\n      reader.cancel()\n    }\n\n    reader.releaseLock()\n  }\n}\n\nmodule.exports = browserReadableStreamToIt\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar splitter = require('./splitter.js');\nvar joiner = require('./joiner.js');\n\n\n\nexports.TreewalkCarSplitter = splitter.TreewalkCarSplitter;\nexports.TreewalkCarJoiner = joiner.TreewalkCarJoiner;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar car = require('@ipld/car');\n\nclass TreewalkCarJoiner {\n  constructor(cars) {\n    this._cars = Array.from(cars);\n    if (!this._cars.length)\n      throw new Error('missing CARs');\n  }\n  async *car() {\n    const reader = this._cars[0];\n    const roots = await reader.getRoots();\n    const {writer, out} = car.CarWriter.create(roots);\n    const writeCar = async () => {\n      const written = new Set();\n      const writeBlocks = async reader => {\n        for await (const b of reader.blocks()) {\n          if (written.has(b.cid.toString()))\n            continue;\n          await writer.put(b);\n          written.add(b.cid.toString());\n        }\n      };\n      try {\n        await writeBlocks(reader);\n        for (const reader of this._cars.slice(1)) {\n          await writeBlocks(reader);\n        }\n      } catch (err) {\n        console.error(err);\n      } finally {\n        await writer.close();\n      }\n    };\n    writeCar();\n    yield* out;\n  }\n}\n\nexports.TreewalkCarJoiner = TreewalkCarJoiner;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar car = require('@ipld/car');\nvar block = require('multiformats/block');\nvar raw = require('multiformats/codecs/raw');\nvar dagCbor = require('@ipld/dag-cbor');\nvar pb = require('@ipld/dag-pb');\n\nfunction _interopNamespace(e) {\n  if (e && e.__esModule) return e;\n  var n = Object.create(null);\n  if (e) {\n    Object.keys(e).forEach(function (k) {\n      if (k !== 'default') {\n        var d = Object.getOwnPropertyDescriptor(e, k);\n        Object.defineProperty(n, k, d.get ? d : {\n          enumerable: true,\n          get: function () {\n            return e[k];\n          }\n        });\n      }\n    });\n  }\n  n['default'] = e;\n  return Object.freeze(n);\n}\n\nvar raw__namespace = /*#__PURE__*/_interopNamespace(raw);\nvar dagCbor__namespace = /*#__PURE__*/_interopNamespace(dagCbor);\nvar pb__namespace = /*#__PURE__*/_interopNamespace(pb);\n\nclass TreewalkCarSplitter {\n  constructor(reader, targetSize, options = {}) {\n    if (typeof targetSize !== 'number' || targetSize <= 0) {\n      throw new Error('invalid target chunk size');\n    }\n    this._reader = reader;\n    this._targetSize = targetSize;\n    this._decoders = [\n      pb__namespace,\n      raw__namespace,\n      dagCbor__namespace,\n      ...options.decoders || []\n    ];\n  }\n  async *cars() {\n    const roots = await this._reader.getRoots();\n    if (roots.length !== 1)\n      throw new Error(`unexpected number of roots: ${ roots.length }`);\n    let channel;\n    for await (const val of this._cars(roots[0])) {\n      channel = val.channel;\n      if (val.out)\n        yield val.out;\n    }\n    if (!channel) {\n      throw new Error('missing CAR writer channel');\n    }\n    channel.writer.close();\n    yield channel.out;\n  }\n  async _get(cid) {\n    const rawBlock = await this._reader.get(cid);\n    if (!rawBlock)\n      throw new Error(`missing block for ${ cid }`);\n    const {bytes} = rawBlock;\n    const decoder = this._decoders.find(d => d.code === cid.code);\n    if (!decoder)\n      throw new Error(`missing decoder for ${ cid.code }`);\n    return new block.Block({\n      cid,\n      bytes,\n      value: decoder.decode(bytes)\n    });\n  }\n  async *_cars(cid, parents = [], channel = undefined) {\n    const block = await this._get(cid);\n    channel = channel || Object.assign(car.CarWriter.create(cid), { size: 0 });\n    if (channel.size > 0 && channel.size + block.bytes.byteLength >= this._targetSize) {\n      channel.writer.close();\n      const {out} = channel;\n      channel = newCar(parents);\n      yield {\n        channel,\n        out\n      };\n    }\n    parents = parents.concat(block);\n    channel.size += block.bytes.byteLength;\n    channel.writer.put(block);\n    for (const [, cid] of block.links()) {\n      for await (const val of this._cars(cid, parents, channel)) {\n        channel = val.channel;\n        yield val;\n      }\n    }\n    if (!channel) {\n      throw new Error('missing CAR writer channel');\n    }\n    yield { channel };\n  }\n  static async fromIterable(iterable, targetSize, options) {\n    const reader = await car.CarReader.fromIterable(iterable);\n    return new TreewalkCarSplitter(reader, targetSize, options);\n  }\n  static async fromBlob(blob, targetSize, options) {\n    const buffer = await blob.arrayBuffer();\n    const reader = await car.CarReader.fromBytes(new Uint8Array(buffer));\n    return new TreewalkCarSplitter(reader, targetSize, options);\n  }\n}\nfunction newCar(parents) {\n  const ch = Object.assign(car.CarWriter.create(parents[0].cid), { size: parents.reduce((size, b) => size + b.bytes.byteLength, 0) });\n  for (const b of parents) {\n    ch.writer.put(b);\n  }\n  return ch;\n}\n\nexports.TreewalkCarSplitter = TreewalkCarSplitter;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar encode = require('./lib/encode.js');\nvar decode = require('./lib/decode.js');\nvar token = require('./lib/token.js');\n\n\n\nexports.encode = encode.encode;\nexports.decode = decode.decode;\nexports.Token = token.Token;\nexports.Type = token.Type;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar common = require('./common.js');\n\nconst uintBoundaries = [\n  24,\n  256,\n  65536,\n  4294967296,\n  BigInt('18446744073709551616')\n];\nfunction readUint8(data, offset, options) {\n  common.assertEnoughData(data, offset, 1);\n  const value = data[offset];\n  if (options.strict === true && value < uintBoundaries[0]) {\n    throw new Error(`${ common.decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  return value;\n}\nfunction readUint16(data, offset, options) {\n  common.assertEnoughData(data, offset, 2);\n  const value = data[offset] << 8 | data[offset + 1];\n  if (options.strict === true && value < uintBoundaries[1]) {\n    throw new Error(`${ common.decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  return value;\n}\nfunction readUint32(data, offset, options) {\n  common.assertEnoughData(data, offset, 4);\n  const value = data[offset] * 16777216 + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  if (options.strict === true && value < uintBoundaries[2]) {\n    throw new Error(`${ common.decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  return value;\n}\nfunction readUint64(data, offset, options) {\n  common.assertEnoughData(data, offset, 8);\n  const hi = data[offset] * 16777216 + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  const lo = data[offset + 4] * 16777216 + (data[offset + 5] << 16) + (data[offset + 6] << 8) + data[offset + 7];\n  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo);\n  if (options.strict === true && value < uintBoundaries[3]) {\n    throw new Error(`${ common.decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  if (value <= Number.MAX_SAFE_INTEGER) {\n    return Number(value);\n  }\n  if (options.allowBigInt === true) {\n    return value;\n  }\n  throw new Error(`${ common.decodeErrPrefix } integers outside of the safe integer range are not supported`);\n}\nfunction decodeUint8(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint8(data, pos + 1, options), 2);\n}\nfunction decodeUint16(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint16(data, pos + 1, options), 3);\n}\nfunction decodeUint32(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint32(data, pos + 1, options), 5);\n}\nfunction decodeUint64(data, pos, _minor, options) {\n  return new token.Token(token.Type.uint, readUint64(data, pos + 1, options), 9);\n}\nfunction encodeUint(buf, token) {\n  return encodeUintValue(buf, 0, token.value);\n}\nfunction encodeUintValue(buf, major, uint) {\n  if (uint < uintBoundaries[0]) {\n    const nuint = Number(uint);\n    buf.push([major | nuint]);\n  } else if (uint < uintBoundaries[1]) {\n    const nuint = Number(uint);\n    buf.push([\n      major | 24,\n      nuint\n    ]);\n  } else if (uint < uintBoundaries[2]) {\n    const nuint = Number(uint);\n    buf.push([\n      major | 25,\n      nuint >>> 8,\n      nuint & 255\n    ]);\n  } else if (uint < uintBoundaries[3]) {\n    const nuint = Number(uint);\n    buf.push([\n      major | 26,\n      nuint >>> 24 & 255,\n      nuint >>> 16 & 255,\n      nuint >>> 8 & 255,\n      nuint & 255\n    ]);\n  } else {\n    const buint = BigInt(uint);\n    if (buint < uintBoundaries[4]) {\n      const set = [\n        major | 27,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0\n      ];\n      let lo = Number(buint & BigInt(4294967295));\n      let hi = Number(buint >> BigInt(32) & BigInt(4294967295));\n      set[8] = lo & 255;\n      lo = lo >> 8;\n      set[7] = lo & 255;\n      lo = lo >> 8;\n      set[6] = lo & 255;\n      lo = lo >> 8;\n      set[5] = lo & 255;\n      set[4] = hi & 255;\n      hi = hi >> 8;\n      set[3] = hi & 255;\n      hi = hi >> 8;\n      set[2] = hi & 255;\n      hi = hi >> 8;\n      set[1] = hi & 255;\n      buf.push(set);\n    } else {\n      throw new Error(`${ common.decodeErrPrefix } encountered BigInt larger than allowable range`);\n    }\n  }\n}\nencodeUint.encodedSize = function encodedSize(token) {\n  return encodeUintValue.encodedSize(token.value);\n};\nencodeUintValue.encodedSize = function encodedSize(uint) {\n  if (uint < uintBoundaries[0]) {\n    return 1;\n  }\n  if (uint < uintBoundaries[1]) {\n    return 2;\n  }\n  if (uint < uintBoundaries[2]) {\n    return 3;\n  }\n  if (uint < uintBoundaries[3]) {\n    return 5;\n  }\n  return 9;\n};\nencodeUint.compareTokens = function compareTokens(tok1, tok2) {\n  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : 0;\n};\n\nexports.decodeUint16 = decodeUint16;\nexports.decodeUint32 = decodeUint32;\nexports.decodeUint64 = decodeUint64;\nexports.decodeUint8 = decodeUint8;\nexports.encodeUint = encodeUint;\nexports.encodeUintValue = encodeUintValue;\nexports.readUint16 = readUint16;\nexports.readUint32 = readUint32;\nexports.readUint64 = readUint64;\nexports.readUint8 = readUint8;\nexports.uintBoundaries = uintBoundaries;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar _0uint = require('./0uint.js');\nvar common = require('./common.js');\n\nfunction decodeNegint8(data, pos, _minor, options) {\n  return new token.Token(token.Type.negint, -1 - _0uint.readUint8(data, pos + 1, options), 2);\n}\nfunction decodeNegint16(data, pos, _minor, options) {\n  return new token.Token(token.Type.negint, -1 - _0uint.readUint16(data, pos + 1, options), 3);\n}\nfunction decodeNegint32(data, pos, _minor, options) {\n  return new token.Token(token.Type.negint, -1 - _0uint.readUint32(data, pos + 1, options), 5);\n}\nconst neg1b = BigInt(-1);\nconst pos1b = BigInt(1);\nfunction decodeNegint64(data, pos, _minor, options) {\n  const int = _0uint.readUint64(data, pos + 1, options);\n  if (typeof int !== 'bigint') {\n    const value = -1 - int;\n    if (value >= Number.MIN_SAFE_INTEGER) {\n      return new token.Token(token.Type.negint, value, 9);\n    }\n  }\n  if (options.allowBigInt !== true) {\n    throw new Error(`${ common.decodeErrPrefix } integers outside of the safe integer range are not supported`);\n  }\n  return new token.Token(token.Type.negint, neg1b - BigInt(int), 9);\n}\nfunction encodeNegint(buf, token) {\n  const negint = token.value;\n  const unsigned = typeof negint === 'bigint' ? negint * neg1b - pos1b : negint * -1 - 1;\n  _0uint.encodeUintValue(buf, token.type.majorEncoded, unsigned);\n}\nencodeNegint.encodedSize = function encodedSize(token) {\n  const negint = token.value;\n  const unsigned = typeof negint === 'bigint' ? negint * neg1b - pos1b : negint * -1 - 1;\n  if (unsigned < _0uint.uintBoundaries[0]) {\n    return 1;\n  }\n  if (unsigned < _0uint.uintBoundaries[1]) {\n    return 2;\n  }\n  if (unsigned < _0uint.uintBoundaries[2]) {\n    return 3;\n  }\n  if (unsigned < _0uint.uintBoundaries[3]) {\n    return 5;\n  }\n  return 9;\n};\nencodeNegint.compareTokens = function compareTokens(tok1, tok2) {\n  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : 0;\n};\n\nexports.decodeNegint16 = decodeNegint16;\nexports.decodeNegint32 = decodeNegint32;\nexports.decodeNegint64 = decodeNegint64;\nexports.decodeNegint8 = decodeNegint8;\nexports.encodeNegint = encodeNegint;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar common = require('./common.js');\nvar _0uint = require('./0uint.js');\nvar byteUtils = require('./byte-utils.js');\n\nfunction toToken(data, pos, prefix, length) {\n  common.assertEnoughData(data, pos, prefix + length);\n  const buf = byteUtils.slice(data, pos + prefix, pos + prefix + length);\n  return new token.Token(token.Type.bytes, buf, prefix + length);\n}\nfunction decodeBytesCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nfunction decodeBytes8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\nfunction decodeBytes16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\nfunction decodeBytes32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\nfunction decodeBytes64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ common.decodeErrPrefix } 64-bit integer bytes lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nfunction tokenBytes(token$1) {\n  if (token$1.encodedBytes === undefined) {\n    token$1.encodedBytes = token$1.type === token.Type.string ? byteUtils.fromString(token$1.value) : token$1.value;\n  }\n  return token$1.encodedBytes;\n}\nfunction encodeBytes(buf, token) {\n  const bytes = tokenBytes(token);\n  _0uint.encodeUintValue(buf, token.type.majorEncoded, bytes.length);\n  buf.push(bytes);\n}\nencodeBytes.encodedSize = function encodedSize(token) {\n  const bytes = tokenBytes(token);\n  return _0uint.encodeUintValue.encodedSize(bytes.length) + bytes.length;\n};\nencodeBytes.compareTokens = function compareTokens(tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2));\n};\nfunction compareBytes(b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : byteUtils.compare(b1, b2);\n}\n\nexports.compareBytes = compareBytes;\nexports.decodeBytes16 = decodeBytes16;\nexports.decodeBytes32 = decodeBytes32;\nexports.decodeBytes64 = decodeBytes64;\nexports.decodeBytes8 = decodeBytes8;\nexports.decodeBytesCompact = decodeBytesCompact;\nexports.encodeBytes = encodeBytes;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar common = require('./common.js');\nvar _0uint = require('./0uint.js');\nvar _2bytes = require('./2bytes.js');\nvar byteUtils = require('./byte-utils.js');\n\nfunction toToken(data, pos, prefix, length) {\n  const totLength = prefix + length;\n  common.assertEnoughData(data, pos, totLength);\n  return new token.Token(token.Type.string, byteUtils.toString(data, pos + prefix, pos + totLength), totLength);\n}\nfunction decodeStringCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nfunction decodeString8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\nfunction decodeString16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\nfunction decodeString32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\nfunction decodeString64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ common.decodeErrPrefix } 64-bit integer string lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nconst encodeString = _2bytes.encodeBytes;\n\nexports.decodeString16 = decodeString16;\nexports.decodeString32 = decodeString32;\nexports.decodeString64 = decodeString64;\nexports.decodeString8 = decodeString8;\nexports.decodeStringCompact = decodeStringCompact;\nexports.encodeString = encodeString;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar _0uint = require('./0uint.js');\nvar common = require('./common.js');\n\nfunction toToken(_data, _pos, prefix, length) {\n  return new token.Token(token.Type.array, length, prefix);\n}\nfunction decodeArrayCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nfunction decodeArray8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\nfunction decodeArray16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\nfunction decodeArray32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\nfunction decodeArray64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ common.decodeErrPrefix } 64-bit integer array lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nfunction decodeArrayIndefinite(data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${ common.decodeErrPrefix } indefinite length items not allowed`);\n  }\n  return toToken(data, pos, 1, Infinity);\n}\nfunction encodeArray(buf, token$1) {\n  _0uint.encodeUintValue(buf, token.Type.array.majorEncoded, token$1.value);\n}\nencodeArray.compareTokens = _0uint.encodeUint.compareTokens;\n\nexports.decodeArray16 = decodeArray16;\nexports.decodeArray32 = decodeArray32;\nexports.decodeArray64 = decodeArray64;\nexports.decodeArray8 = decodeArray8;\nexports.decodeArrayCompact = decodeArrayCompact;\nexports.decodeArrayIndefinite = decodeArrayIndefinite;\nexports.encodeArray = encodeArray;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar _0uint = require('./0uint.js');\nvar common = require('./common.js');\n\nfunction toToken(_data, _pos, prefix, length) {\n  return new token.Token(token.Type.map, length, prefix);\n}\nfunction decodeMapCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nfunction decodeMap8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, _0uint.readUint8(data, pos + 1, options));\n}\nfunction decodeMap16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, _0uint.readUint16(data, pos + 1, options));\n}\nfunction decodeMap32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, _0uint.readUint32(data, pos + 1, options));\n}\nfunction decodeMap64(data, pos, _minor, options) {\n  const l = _0uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ common.decodeErrPrefix } 64-bit integer map lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nfunction decodeMapIndefinite(data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${ common.decodeErrPrefix } indefinite length items not allowed`);\n  }\n  return toToken(data, pos, 1, Infinity);\n}\nfunction encodeMap(buf, token$1) {\n  _0uint.encodeUintValue(buf, token.Type.map.majorEncoded, token$1.value);\n}\nencodeMap.compareTokens = _0uint.encodeUint.compareTokens;\n\nexports.decodeMap16 = decodeMap16;\nexports.decodeMap32 = decodeMap32;\nexports.decodeMap64 = decodeMap64;\nexports.decodeMap8 = decodeMap8;\nexports.decodeMapCompact = decodeMapCompact;\nexports.decodeMapIndefinite = decodeMapIndefinite;\nexports.encodeMap = encodeMap;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar _0uint = require('./0uint.js');\n\nfunction decodeTagCompact(_data, _pos, minor, _options) {\n  return new token.Token(token.Type.tag, minor, 1);\n}\nfunction decodeTag8(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint8(data, pos + 1, options), 2);\n}\nfunction decodeTag16(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint16(data, pos + 1, options), 3);\n}\nfunction decodeTag32(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint32(data, pos + 1, options), 5);\n}\nfunction decodeTag64(data, pos, _minor, options) {\n  return new token.Token(token.Type.tag, _0uint.readUint64(data, pos + 1, options), 9);\n}\nfunction encodeTag(buf, token$1) {\n  _0uint.encodeUintValue(buf, token.Type.tag.majorEncoded, token$1.value);\n}\nencodeTag.compareTokens = _0uint.encodeUint.compareTokens;\n\nexports.decodeTag16 = decodeTag16;\nexports.decodeTag32 = decodeTag32;\nexports.decodeTag64 = decodeTag64;\nexports.decodeTag8 = decodeTag8;\nexports.decodeTagCompact = decodeTagCompact;\nexports.encodeTag = encodeTag;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar common = require('./common.js');\nvar _0uint = require('./0uint.js');\n\nconst MINOR_FALSE = 20;\nconst MINOR_TRUE = 21;\nconst MINOR_NULL = 22;\nconst MINOR_UNDEFINED = 23;\nfunction decodeUndefined(_data, _pos, _minor, options) {\n  if (options.allowUndefined === false) {\n    throw new Error(`${ common.decodeErrPrefix } undefined values are not supported`);\n  }\n  return new token.Token(token.Type.undefined, undefined, 1);\n}\nfunction decodeBreak(_data, _pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${ common.decodeErrPrefix } indefinite length items not allowed`);\n  }\n  return new token.Token(token.Type.break, undefined, 1);\n}\nfunction createToken(value, bytes, options) {\n  if (options) {\n    if (options.allowNaN === false && Number.isNaN(value)) {\n      throw new Error(`${ common.decodeErrPrefix } NaN values are not supported`);\n    }\n    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {\n      throw new Error(`${ common.decodeErrPrefix } Infinity values are not supported`);\n    }\n  }\n  return new token.Token(token.Type.float, value, bytes);\n}\nfunction decodeFloat16(data, pos, _minor, options) {\n  return createToken(readFloat16(data, pos + 1), 3, options);\n}\nfunction decodeFloat32(data, pos, _minor, options) {\n  return createToken(readFloat32(data, pos + 1), 5, options);\n}\nfunction decodeFloat64(data, pos, _minor, options) {\n  return createToken(readFloat64(data, pos + 1), 9, options);\n}\nfunction encodeFloat(buf, token$1, options) {\n  const float = token$1.value;\n  if (float === false) {\n    buf.push([token.Type.float.majorEncoded | MINOR_FALSE]);\n  } else if (float === true) {\n    buf.push([token.Type.float.majorEncoded | MINOR_TRUE]);\n  } else if (float === null) {\n    buf.push([token.Type.float.majorEncoded | MINOR_NULL]);\n  } else if (float === undefined) {\n    buf.push([token.Type.float.majorEncoded | MINOR_UNDEFINED]);\n  } else {\n    let decoded;\n    let success = false;\n    if (!options || options.float64 !== true) {\n      encodeFloat16(float);\n      decoded = readFloat16(ui8a, 1);\n      if (float === decoded || Number.isNaN(float)) {\n        ui8a[0] = 249;\n        buf.push(ui8a.slice(0, 3));\n        success = true;\n      } else {\n        encodeFloat32(float);\n        decoded = readFloat32(ui8a, 1);\n        if (float === decoded) {\n          ui8a[0] = 250;\n          buf.push(ui8a.slice(0, 5));\n          success = true;\n        }\n      }\n    }\n    if (!success) {\n      encodeFloat64(float);\n      decoded = readFloat64(ui8a, 1);\n      ui8a[0] = 251;\n      buf.push(ui8a.slice(0, 9));\n    }\n  }\n}\nencodeFloat.encodedSize = function encodedSize(token, options) {\n  const float = token.value;\n  if (float === false || float === true || float === null || float === undefined) {\n    return 1;\n  }\n  let decoded;\n  if (!options || options.float64 !== true) {\n    encodeFloat16(float);\n    decoded = readFloat16(ui8a, 1);\n    if (float === decoded || Number.isNaN(float)) {\n      return 3;\n    }\n    encodeFloat32(float);\n    decoded = readFloat32(ui8a, 1);\n    if (float === decoded) {\n      return 5;\n    }\n  }\n  return 9;\n};\nconst buffer = new ArrayBuffer(9);\nconst dataView = new DataView(buffer, 1);\nconst ui8a = new Uint8Array(buffer, 0);\nfunction encodeFloat16(inp) {\n  if (inp === Infinity) {\n    dataView.setUint16(0, 31744, false);\n  } else if (inp === -Infinity) {\n    dataView.setUint16(0, 64512, false);\n  } else if (Number.isNaN(inp)) {\n    dataView.setUint16(0, 32256, false);\n  } else {\n    dataView.setFloat32(0, inp);\n    const valu32 = dataView.getUint32(0);\n    const exponent = (valu32 & 2139095040) >> 23;\n    const mantissa = valu32 & 8388607;\n    if (exponent === 255) {\n      dataView.setUint16(0, 31744, false);\n    } else if (exponent === 0) {\n      dataView.setUint16(0, (inp & 2147483648) >> 16 | mantissa >> 13, false);\n    } else {\n      const logicalExponent = exponent - 127;\n      if (logicalExponent < -24) {\n        dataView.setUint16(0, 0);\n      } else if (logicalExponent < -14) {\n        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | 1 << 24 + logicalExponent, false);\n      } else {\n        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | logicalExponent + 15 << 10 | mantissa >> 13, false);\n      }\n    }\n  }\n}\nfunction readFloat16(ui8a, pos) {\n  if (ui8a.length - pos < 2) {\n    throw new Error(`${ common.decodeErrPrefix } not enough data for float16`);\n  }\n  const half = (ui8a[pos] << 8) + ui8a[pos + 1];\n  if (half === 31744) {\n    return Infinity;\n  }\n  if (half === 64512) {\n    return -Infinity;\n  }\n  if (half === 32256) {\n    return NaN;\n  }\n  const exp = half >> 10 & 31;\n  const mant = half & 1023;\n  let val;\n  if (exp === 0) {\n    val = mant * 2 ** -24;\n  } else if (exp !== 31) {\n    val = (mant + 1024) * 2 ** (exp - 25);\n  } else {\n    val = mant === 0 ? Infinity : NaN;\n  }\n  return half & 32768 ? -val : val;\n}\nfunction encodeFloat32(inp) {\n  dataView.setFloat32(0, inp, false);\n}\nfunction readFloat32(ui8a, pos) {\n  if (ui8a.length - pos < 4) {\n    throw new Error(`${ common.decodeErrPrefix } not enough data for float32`);\n  }\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 4).getFloat32(0, false);\n}\nfunction encodeFloat64(inp) {\n  dataView.setFloat64(0, inp, false);\n}\nfunction readFloat64(ui8a, pos) {\n  if (ui8a.length - pos < 8) {\n    throw new Error(`${ common.decodeErrPrefix } not enough data for float64`);\n  }\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 8).getFloat64(0, false);\n}\nencodeFloat.compareTokens = _0uint.encodeUint.compareTokens;\n\nexports.decodeBreak = decodeBreak;\nexports.decodeFloat16 = decodeFloat16;\nexports.decodeFloat32 = decodeFloat32;\nexports.decodeFloat64 = decodeFloat64;\nexports.decodeUndefined = decodeUndefined;\nexports.encodeFloat = encodeFloat;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar byteUtils = require('./byte-utils.js');\n\nconst defaultChunkSize = 256;\nclass Bl {\n  constructor(chunkSize = defaultChunkSize) {\n    this.chunkSize = chunkSize;\n    this.cursor = 0;\n    this.maxCursor = -1;\n    this.chunks = [];\n    this._initReuseChunk = null;\n  }\n  reset() {\n    this.chunks = [];\n    this.cursor = 0;\n    this.maxCursor = -1;\n    if (this._initReuseChunk !== null) {\n      this.chunks.push(this._initReuseChunk);\n      this.maxCursor = this._initReuseChunk.length - 1;\n    }\n  }\n  push(bytes) {\n    let topChunk = this.chunks[this.chunks.length - 1];\n    const newMax = this.cursor + bytes.length;\n    if (newMax <= this.maxCursor + 1) {\n      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n      topChunk.set(bytes, chunkPos);\n    } else {\n      if (topChunk) {\n        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n        if (chunkPos < topChunk.length) {\n          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos);\n          this.maxCursor = this.cursor - 1;\n        }\n      }\n      if (bytes.length < 64 && bytes.length < this.chunkSize) {\n        topChunk = byteUtils.alloc(this.chunkSize);\n        this.chunks.push(topChunk);\n        this.maxCursor += topChunk.length;\n        if (this._initReuseChunk === null) {\n          this._initReuseChunk = topChunk;\n        }\n        topChunk.set(bytes, 0);\n      } else {\n        this.chunks.push(bytes);\n        this.maxCursor += bytes.length;\n      }\n    }\n    this.cursor += bytes.length;\n  }\n  toBytes(reset = false) {\n    let byts;\n    if (this.chunks.length === 1) {\n      const chunk = this.chunks[0];\n      if (reset && this.cursor > chunk.length / 2) {\n        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor);\n        this._initReuseChunk = null;\n        this.chunks = [];\n      } else {\n        byts = byteUtils.slice(chunk, 0, this.cursor);\n      }\n    } else {\n      byts = byteUtils.concat(this.chunks, this.cursor);\n    }\n    if (reset) {\n      this.reset();\n    }\n    return byts;\n  }\n}\n\nexports.Bl = Bl;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst useBuffer = globalThis.process && !globalThis.process.browser && globalThis.Buffer && typeof globalThis.Buffer.isBuffer === 'function';\nconst textDecoder = new TextDecoder();\nconst textEncoder = new TextEncoder();\nfunction isBuffer(buf) {\n  return useBuffer && globalThis.Buffer.isBuffer(buf);\n}\nfunction asU8A(buf) {\n  if (!(buf instanceof Uint8Array)) {\n    return Uint8Array.from(buf);\n  }\n  return isBuffer(buf) ? new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength) : buf;\n}\nconst toString = useBuffer ? (bytes, start, end) => {\n  return end - start > 64 ? globalThis.Buffer.from(bytes.subarray(start, end)).toString('utf8') : utf8Slice(bytes, start, end);\n} : (bytes, start, end) => {\n  return end - start > 64 ? textDecoder.decode(bytes.subarray(start, end)) : utf8Slice(bytes, start, end);\n};\nconst fromString = useBuffer ? string => {\n  return string.length > 64 ? globalThis.Buffer.from(string) : utf8ToBytes(string);\n} : string => {\n  return string.length > 64 ? textEncoder.encode(string) : utf8ToBytes(string);\n};\nconst fromArray = arr => {\n  return Uint8Array.from(arr);\n};\nconst slice = useBuffer ? (bytes, start, end) => {\n  if (isBuffer(bytes)) {\n    return new Uint8Array(bytes.subarray(start, end));\n  }\n  return bytes.slice(start, end);\n} : (bytes, start, end) => {\n  return bytes.slice(start, end);\n};\nconst concat = useBuffer ? (chunks, length) => {\n  chunks = chunks.map(c => c instanceof Uint8Array ? c : globalThis.Buffer.from(c));\n  return asU8A(globalThis.Buffer.concat(chunks, length));\n} : (chunks, length) => {\n  const out = new Uint8Array(length);\n  let off = 0;\n  for (let b of chunks) {\n    if (off + b.length > out.length) {\n      b = b.subarray(0, out.length - off);\n    }\n    out.set(b, off);\n    off += b.length;\n  }\n  return out;\n};\nconst alloc = useBuffer ? size => {\n  return globalThis.Buffer.allocUnsafe(size);\n} : size => {\n  return new Uint8Array(size);\n};\nconst toHex = useBuffer ? d => {\n  if (typeof d === 'string') {\n    return d;\n  }\n  return globalThis.Buffer.from(toBytes(d)).toString('hex');\n} : d => {\n  if (typeof d === 'string') {\n    return d;\n  }\n  return Array.prototype.reduce.call(toBytes(d), (p, c) => `${ p }${ c.toString(16).padStart(2, '0') }`, '');\n};\nconst fromHex = useBuffer ? hex => {\n  if (hex instanceof Uint8Array) {\n    return hex;\n  }\n  return globalThis.Buffer.from(hex, 'hex');\n} : hex => {\n  if (hex instanceof Uint8Array) {\n    return hex;\n  }\n  if (!hex.length) {\n    return new Uint8Array(0);\n  }\n  return new Uint8Array(hex.split('').map((c, i, d) => i % 2 === 0 ? `0x${ c }${ d[i + 1] }` : '').filter(Boolean).map(e => parseInt(e, 16)));\n};\nfunction toBytes(obj) {\n  if (obj instanceof Uint8Array && obj.constructor.name === 'Uint8Array') {\n    return obj;\n  }\n  if (obj instanceof ArrayBuffer) {\n    return new Uint8Array(obj);\n  }\n  if (ArrayBuffer.isView(obj)) {\n    return new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength);\n  }\n  throw new Error('Unknown type, must be binary type');\n}\nfunction compare(b1, b2) {\n  if (isBuffer(b1) && isBuffer(b2)) {\n    return b1.compare(b2);\n  }\n  for (let i = 0; i < b1.length; i++) {\n    if (b1[i] === b2[i]) {\n      continue;\n    }\n    return b1[i] < b2[i] ? -1 : 1;\n  }\n  return 0;\n}\nfunction utf8ToBytes(string, units = Infinity) {\n  let codePoint;\n  const length = string.length;\n  let leadSurrogate = null;\n  const bytes = [];\n  for (let i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i);\n    if (codePoint > 55295 && codePoint < 57344) {\n      if (!leadSurrogate) {\n        if (codePoint > 56319) {\n          if ((units -= 3) > -1)\n            bytes.push(239, 191, 189);\n          continue;\n        } else if (i + 1 === length) {\n          if ((units -= 3) > -1)\n            bytes.push(239, 191, 189);\n          continue;\n        }\n        leadSurrogate = codePoint;\n        continue;\n      }\n      if (codePoint < 56320) {\n        if ((units -= 3) > -1)\n          bytes.push(239, 191, 189);\n        leadSurrogate = codePoint;\n        continue;\n      }\n      codePoint = (leadSurrogate - 55296 << 10 | codePoint - 56320) + 65536;\n    } else if (leadSurrogate) {\n      if ((units -= 3) > -1)\n        bytes.push(239, 191, 189);\n    }\n    leadSurrogate = null;\n    if (codePoint < 128) {\n      if ((units -= 1) < 0)\n        break;\n      bytes.push(codePoint);\n    } else if (codePoint < 2048) {\n      if ((units -= 2) < 0)\n        break;\n      bytes.push(codePoint >> 6 | 192, codePoint & 63 | 128);\n    } else if (codePoint < 65536) {\n      if ((units -= 3) < 0)\n        break;\n      bytes.push(codePoint >> 12 | 224, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);\n    } else if (codePoint < 1114112) {\n      if ((units -= 4) < 0)\n        break;\n      bytes.push(codePoint >> 18 | 240, codePoint >> 12 & 63 | 128, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);\n    } else {\n      throw new Error('Invalid code point');\n    }\n  }\n  return bytes;\n}\nfunction utf8Slice(buf, offset, end) {\n  const res = [];\n  while (offset < end) {\n    const firstByte = buf[offset];\n    let codePoint = null;\n    let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;\n    if (offset + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint;\n      switch (bytesPerSequence) {\n      case 1:\n        if (firstByte < 128) {\n          codePoint = firstByte;\n        }\n        break;\n      case 2:\n        secondByte = buf[offset + 1];\n        if ((secondByte & 192) === 128) {\n          tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;\n          if (tempCodePoint > 127) {\n            codePoint = tempCodePoint;\n          }\n        }\n        break;\n      case 3:\n        secondByte = buf[offset + 1];\n        thirdByte = buf[offset + 2];\n        if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {\n          tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;\n          if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {\n            codePoint = tempCodePoint;\n          }\n        }\n        break;\n      case 4:\n        secondByte = buf[offset + 1];\n        thirdByte = buf[offset + 2];\n        fourthByte = buf[offset + 3];\n        if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {\n          tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;\n          if (tempCodePoint > 65535 && tempCodePoint < 1114112) {\n            codePoint = tempCodePoint;\n          }\n        }\n      }\n    }\n    if (codePoint === null) {\n      codePoint = 65533;\n      bytesPerSequence = 1;\n    } else if (codePoint > 65535) {\n      codePoint -= 65536;\n      res.push(codePoint >>> 10 & 1023 | 55296);\n      codePoint = 56320 | codePoint & 1023;\n    }\n    res.push(codePoint);\n    offset += bytesPerSequence;\n  }\n  return decodeCodePointsArray(res);\n}\nconst MAX_ARGUMENTS_LENGTH = 4096;\nfunction decodeCodePointsArray(codePoints) {\n  const len = codePoints.length;\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints);\n  }\n  let res = '';\n  let i = 0;\n  while (i < len) {\n    res += String.fromCharCode.apply(String, codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH));\n  }\n  return res;\n}\n\nexports.alloc = alloc;\nexports.asU8A = asU8A;\nexports.compare = compare;\nexports.concat = concat;\nexports.decodeCodePointsArray = decodeCodePointsArray;\nexports.fromArray = fromArray;\nexports.fromHex = fromHex;\nexports.fromString = fromString;\nexports.slice = slice;\nexports.toHex = toHex;\nexports.toString = toString;\nexports.useBuffer = useBuffer;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst decodeErrPrefix = 'CBOR decode error:';\nconst encodeErrPrefix = 'CBOR encode error:';\nconst uintMinorPrefixBytes = [];\nuintMinorPrefixBytes[23] = 1;\nuintMinorPrefixBytes[24] = 2;\nuintMinorPrefixBytes[25] = 3;\nuintMinorPrefixBytes[26] = 5;\nuintMinorPrefixBytes[27] = 9;\nfunction assertEnoughData(data, pos, need) {\n  if (data.length - pos < need) {\n    throw new Error(`${ decodeErrPrefix } not enough data for type`);\n  }\n}\n\nexports.assertEnoughData = assertEnoughData;\nexports.decodeErrPrefix = decodeErrPrefix;\nexports.encodeErrPrefix = encodeErrPrefix;\nexports.uintMinorPrefixBytes = uintMinorPrefixBytes;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar common = require('./common.js');\nvar token = require('./token.js');\nvar jump = require('./jump.js');\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = jump.quick[byt];\n    if (token === undefined) {\n      const decoder = jump.jump[byt];\n      if (!decoder) {\n        throw new Error(`${ common.decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ common.decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ common.decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ common.decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token$1 = tokeniser.next();\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n    throw new Error(`${ common.decodeErrPrefix } tag not supported (${ token$1.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ common.decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ common.decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ common.decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ common.decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar is = require('./is.js');\nvar token = require('./token.js');\nvar bl = require('./bl.js');\nvar common = require('./common.js');\nvar jump = require('./jump.js');\nvar byteUtils = require('./byte-utils.js');\nvar _0uint = require('./0uint.js');\nvar _1negint = require('./1negint.js');\nvar _2bytes = require('./2bytes.js');\nvar _3string = require('./3string.js');\nvar _4array = require('./4array.js');\nvar _5map = require('./5map.js');\nvar _6tag = require('./6tag.js');\nvar _7float = require('./7float.js');\n\nconst defaultEncodeOptions = {\n  float64: false,\n  mapSorter,\n  quickEncodeToken: jump.quickEncodeToken\n};\nconst cborEncoders = [];\ncborEncoders[token.Type.uint.major] = _0uint.encodeUint;\ncborEncoders[token.Type.negint.major] = _1negint.encodeNegint;\ncborEncoders[token.Type.bytes.major] = _2bytes.encodeBytes;\ncborEncoders[token.Type.string.major] = _3string.encodeString;\ncborEncoders[token.Type.array.major] = _4array.encodeArray;\ncborEncoders[token.Type.map.major] = _5map.encodeMap;\ncborEncoders[token.Type.tag.major] = _6tag.encodeTag;\ncborEncoders[token.Type.float.major] = _7float.encodeFloat;\nconst buf = new bl.Bl();\nclass Ref {\n  constructor(obj, parent) {\n    this.obj = obj;\n    this.parent = parent;\n  }\n  includes(obj) {\n    let p = this;\n    do {\n      if (p.obj === obj) {\n        return true;\n      }\n    } while (p = p.parent);\n    return false;\n  }\n  static createCheck(stack, obj) {\n    if (stack && stack.includes(obj)) {\n      throw new Error(`${ common.encodeErrPrefix } object contains circular references`);\n    }\n    return new Ref(obj, stack);\n  }\n}\nconst simpleTokens = {\n  null: new token.Token(token.Type.null, null),\n  undefined: new token.Token(token.Type.undefined, undefined),\n  true: new token.Token(token.Type.true, true),\n  false: new token.Token(token.Type.false, false),\n  emptyArray: new token.Token(token.Type.array, 0),\n  emptyMap: new token.Token(token.Type.map, 0)\n};\nconst typeEncoders = {\n  number(obj, _typ, _options, _refStack) {\n    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {\n      return new token.Token(token.Type.float, obj);\n    } else if (obj >= 0) {\n      return new token.Token(token.Type.uint, obj);\n    } else {\n      return new token.Token(token.Type.negint, obj);\n    }\n  },\n  bigint(obj, _typ, _options, _refStack) {\n    if (obj >= BigInt(0)) {\n      return new token.Token(token.Type.uint, obj);\n    } else {\n      return new token.Token(token.Type.negint, obj);\n    }\n  },\n  Uint8Array(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.bytes, obj);\n  },\n  string(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.string, obj);\n  },\n  boolean(obj, _typ, _options, _refStack) {\n    return obj ? simpleTokens.true : simpleTokens.false;\n  },\n  null(_obj, _typ, _options, _refStack) {\n    return simpleTokens.null;\n  },\n  undefined(_obj, _typ, _options, _refStack) {\n    return simpleTokens.undefined;\n  },\n  ArrayBuffer(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.bytes, new Uint8Array(obj));\n  },\n  DataView(obj, _typ, _options, _refStack) {\n    return new token.Token(token.Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength));\n  },\n  Array(obj, _typ, options, refStack) {\n    if (!obj.length) {\n      if (options.addBreakTokens === true) {\n        return [\n          simpleTokens.emptyArray,\n          new token.Token(token.Type.break)\n        ];\n      }\n      return simpleTokens.emptyArray;\n    }\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n    for (const e of obj) {\n      entries[i++] = objectToTokens(e, options, refStack);\n    }\n    if (options.addBreakTokens) {\n      return [\n        new token.Token(token.Type.array, obj.length),\n        entries,\n        new token.Token(token.Type.break)\n      ];\n    }\n    return [\n      new token.Token(token.Type.array, obj.length),\n      entries\n    ];\n  },\n  Object(obj, typ, options, refStack) {\n    const isMap = typ !== 'Object';\n    const keys = isMap ? obj.keys() : Object.keys(obj);\n    const length = isMap ? obj.size : keys.length;\n    if (!length) {\n      if (options.addBreakTokens === true) {\n        return [\n          simpleTokens.emptyMap,\n          new token.Token(token.Type.break)\n        ];\n      }\n      return simpleTokens.emptyMap;\n    }\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n    for (const key of keys) {\n      entries[i++] = [\n        objectToTokens(key, options, refStack),\n        objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)\n      ];\n    }\n    sortMapEntries(entries, options);\n    if (options.addBreakTokens) {\n      return [\n        new token.Token(token.Type.map, length),\n        entries,\n        new token.Token(token.Type.break)\n      ];\n    }\n    return [\n      new token.Token(token.Type.map, length),\n      entries\n    ];\n  }\n};\ntypeEncoders.Map = typeEncoders.Object;\ntypeEncoders.Buffer = typeEncoders.Uint8Array;\nfor (const typ of 'Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64'.split(' ')) {\n  typeEncoders[`${ typ }Array`] = typeEncoders.DataView;\n}\nfunction objectToTokens(obj, options = {}, refStack) {\n  const typ = is.is(obj);\n  const customTypeEncoder = options && options.typeEncoders && options.typeEncoders[typ] || typeEncoders[typ];\n  if (typeof customTypeEncoder === 'function') {\n    const tokens = customTypeEncoder(obj, typ, options, refStack);\n    if (tokens != null) {\n      return tokens;\n    }\n  }\n  const typeEncoder = typeEncoders[typ];\n  if (!typeEncoder) {\n    throw new Error(`${ common.encodeErrPrefix } unsupported type: ${ typ }`);\n  }\n  return typeEncoder(obj, typ, options, refStack);\n}\nfunction sortMapEntries(entries, options) {\n  if (options.mapSorter) {\n    entries.sort(options.mapSorter);\n  }\n}\nfunction mapSorter(e1, e2) {\n  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0];\n  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0];\n  if (keyToken1.type !== keyToken2.type) {\n    return keyToken1.type.compare(keyToken2.type);\n  }\n  const major = keyToken1.type.major;\n  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2);\n  if (tcmp === 0) {\n    console.warn('WARNING: complex key types used, CBOR key sorting guarantees are gone');\n  }\n  return tcmp;\n}\nfunction tokensToEncoded(buf, tokens, encoders, options) {\n  if (Array.isArray(tokens)) {\n    for (const token of tokens) {\n      tokensToEncoded(buf, token, encoders, options);\n    }\n  } else {\n    encoders[tokens.type.major](buf, tokens, options);\n  }\n}\nfunction encodeCustom(data, encoders, options) {\n  const tokens = objectToTokens(data, options);\n  if (!Array.isArray(tokens) && options.quickEncodeToken) {\n    const quickBytes = options.quickEncodeToken(tokens);\n    if (quickBytes) {\n      return quickBytes;\n    }\n    const encoder = encoders[tokens.type.major];\n    if (encoder.encodedSize) {\n      const size = encoder.encodedSize(tokens, options);\n      const buf = new bl.Bl(size);\n      encoder(buf, tokens, options);\n      if (buf.chunks.length !== 1) {\n        throw new Error(`Unexpected error: pre-calculated length for ${ tokens } was wrong`);\n      }\n      return byteUtils.asU8A(buf.chunks[0]);\n    }\n  }\n  tokensToEncoded(buf, tokens, encoders, options);\n  return buf.toBytes(true);\n}\nfunction encode(data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options);\n  return encodeCustom(data, cborEncoders, options);\n}\n\nexports.Ref = Ref;\nexports.encode = encode;\nexports.encodeCustom = encodeCustom;\nexports.objectToTokens = objectToTokens;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst typeofs = [\n  'string',\n  'number',\n  'bigint',\n  'symbol'\n];\nconst objectTypeNames = [\n  'Function',\n  'Generator',\n  'AsyncGenerator',\n  'GeneratorFunction',\n  'AsyncGeneratorFunction',\n  'AsyncFunction',\n  'Observable',\n  'Array',\n  'Buffer',\n  'Object',\n  'RegExp',\n  'Date',\n  'Error',\n  'Map',\n  'Set',\n  'WeakMap',\n  'WeakSet',\n  'ArrayBuffer',\n  'SharedArrayBuffer',\n  'DataView',\n  'Promise',\n  'URL',\n  'HTMLElement',\n  'Int8Array',\n  'Uint8Array',\n  'Uint8ClampedArray',\n  'Int16Array',\n  'Uint16Array',\n  'Int32Array',\n  'Uint32Array',\n  'Float32Array',\n  'Float64Array',\n  'BigInt64Array',\n  'BigUint64Array'\n];\nfunction is(value) {\n  if (value === null) {\n    return 'null';\n  }\n  if (value === undefined) {\n    return 'undefined';\n  }\n  if (value === true || value === false) {\n    return 'boolean';\n  }\n  const typeOf = typeof value;\n  if (typeofs.includes(typeOf)) {\n    return typeOf;\n  }\n  if (typeOf === 'function') {\n    return 'Function';\n  }\n  if (Array.isArray(value)) {\n    return 'Array';\n  }\n  if (isBuffer(value)) {\n    return 'Buffer';\n  }\n  const objectType = getObjectType(value);\n  if (objectType) {\n    return objectType;\n  }\n  return 'Object';\n}\nfunction isBuffer(value) {\n  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value);\n}\nfunction getObjectType(value) {\n  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1);\n  if (objectTypeNames.includes(objectTypeName)) {\n    return objectTypeName;\n  }\n  return undefined;\n}\n\nexports.is = is;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar token = require('./token.js');\nvar _0uint = require('./0uint.js');\nvar _1negint = require('./1negint.js');\nvar _2bytes = require('./2bytes.js');\nvar _3string = require('./3string.js');\nvar _4array = require('./4array.js');\nvar _5map = require('./5map.js');\nvar _6tag = require('./6tag.js');\nvar _7float = require('./7float.js');\nvar common = require('./common.js');\nvar byteUtils = require('./byte-utils.js');\n\nfunction invalidMinor(data, pos, minor) {\n  throw new Error(`${ common.decodeErrPrefix } encountered invalid minor (${ minor }) for major ${ data[pos] >>> 5 }`);\n}\nfunction errorer(msg) {\n  return () => {\n    throw new Error(`${ common.decodeErrPrefix } ${ msg }`);\n  };\n}\nconst jump = [];\nfor (let i = 0; i <= 23; i++) {\n  jump[i] = invalidMinor;\n}\njump[24] = _0uint.decodeUint8;\njump[25] = _0uint.decodeUint16;\njump[26] = _0uint.decodeUint32;\njump[27] = _0uint.decodeUint64;\njump[28] = invalidMinor;\njump[29] = invalidMinor;\njump[30] = invalidMinor;\njump[31] = invalidMinor;\nfor (let i = 32; i <= 55; i++) {\n  jump[i] = invalidMinor;\n}\njump[56] = _1negint.decodeNegint8;\njump[57] = _1negint.decodeNegint16;\njump[58] = _1negint.decodeNegint32;\njump[59] = _1negint.decodeNegint64;\njump[60] = invalidMinor;\njump[61] = invalidMinor;\njump[62] = invalidMinor;\njump[63] = invalidMinor;\nfor (let i = 64; i <= 87; i++) {\n  jump[i] = _2bytes.decodeBytesCompact;\n}\njump[88] = _2bytes.decodeBytes8;\njump[89] = _2bytes.decodeBytes16;\njump[90] = _2bytes.decodeBytes32;\njump[91] = _2bytes.decodeBytes64;\njump[92] = invalidMinor;\njump[93] = invalidMinor;\njump[94] = invalidMinor;\njump[95] = errorer('indefinite length bytes/strings are not supported');\nfor (let i = 96; i <= 119; i++) {\n  jump[i] = _3string.decodeStringCompact;\n}\njump[120] = _3string.decodeString8;\njump[121] = _3string.decodeString16;\njump[122] = _3string.decodeString32;\njump[123] = _3string.decodeString64;\njump[124] = invalidMinor;\njump[125] = invalidMinor;\njump[126] = invalidMinor;\njump[127] = errorer('indefinite length bytes/strings are not supported');\nfor (let i = 128; i <= 151; i++) {\n  jump[i] = _4array.decodeArrayCompact;\n}\njump[152] = _4array.decodeArray8;\njump[153] = _4array.decodeArray16;\njump[154] = _4array.decodeArray32;\njump[155] = _4array.decodeArray64;\njump[156] = invalidMinor;\njump[157] = invalidMinor;\njump[158] = invalidMinor;\njump[159] = _4array.decodeArrayIndefinite;\nfor (let i = 160; i <= 183; i++) {\n  jump[i] = _5map.decodeMapCompact;\n}\njump[184] = _5map.decodeMap8;\njump[185] = _5map.decodeMap16;\njump[186] = _5map.decodeMap32;\njump[187] = _5map.decodeMap64;\njump[188] = invalidMinor;\njump[189] = invalidMinor;\njump[190] = invalidMinor;\njump[191] = _5map.decodeMapIndefinite;\nfor (let i = 192; i <= 215; i++) {\n  jump[i] = _6tag.decodeTagCompact;\n}\njump[216] = _6tag.decodeTag8;\njump[217] = _6tag.decodeTag16;\njump[218] = _6tag.decodeTag32;\njump[219] = _6tag.decodeTag64;\njump[220] = invalidMinor;\njump[221] = invalidMinor;\njump[222] = invalidMinor;\njump[223] = invalidMinor;\nfor (let i = 224; i <= 243; i++) {\n  jump[i] = errorer('simple values are not supported');\n}\njump[244] = invalidMinor;\njump[245] = invalidMinor;\njump[246] = invalidMinor;\njump[247] = _7float.decodeUndefined;\njump[248] = errorer('simple values are not supported');\njump[249] = _7float.decodeFloat16;\njump[250] = _7float.decodeFloat32;\njump[251] = _7float.decodeFloat64;\njump[252] = invalidMinor;\njump[253] = invalidMinor;\njump[254] = invalidMinor;\njump[255] = _7float.decodeBreak;\nconst quick = [];\nfor (let i = 0; i < 24; i++) {\n  quick[i] = new token.Token(token.Type.uint, i, 1);\n}\nfor (let i = -1; i >= -24; i--) {\n  quick[31 - i] = new token.Token(token.Type.negint, i, 1);\n}\nquick[64] = new token.Token(token.Type.bytes, new Uint8Array(0), 1);\nquick[96] = new token.Token(token.Type.string, '', 1);\nquick[128] = new token.Token(token.Type.array, 0, 1);\nquick[160] = new token.Token(token.Type.map, 0, 1);\nquick[244] = new token.Token(token.Type.false, false, 1);\nquick[245] = new token.Token(token.Type.true, true, 1);\nquick[246] = new token.Token(token.Type.null, null, 1);\nfunction quickEncodeToken(token$1) {\n  switch (token$1.type) {\n  case token.Type.false:\n    return byteUtils.fromArray([244]);\n  case token.Type.true:\n    return byteUtils.fromArray([245]);\n  case token.Type.null:\n    return byteUtils.fromArray([246]);\n  case token.Type.bytes:\n    if (!token$1.value.length) {\n      return byteUtils.fromArray([64]);\n    }\n    return;\n  case token.Type.string:\n    if (token$1.value === '') {\n      return byteUtils.fromArray([96]);\n    }\n    return;\n  case token.Type.array:\n    if (token$1.value === 0) {\n      return byteUtils.fromArray([128]);\n    }\n    return;\n  case token.Type.map:\n    if (token$1.value === 0) {\n      return byteUtils.fromArray([160]);\n    }\n    return;\n  case token.Type.uint:\n    if (token$1.value < 24) {\n      return byteUtils.fromArray([Number(token$1.value)]);\n    }\n    return;\n  case token.Type.negint:\n    if (token$1.value >= -24) {\n      return byteUtils.fromArray([31 - Number(token$1.value)]);\n    }\n  }\n}\n\nexports.jump = jump;\nexports.quick = quick;\nexports.quickEncodeToken = quickEncodeToken;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nclass Type {\n  constructor(major, name, terminal) {\n    this.major = major;\n    this.majorEncoded = major << 5;\n    this.name = name;\n    this.terminal = terminal;\n  }\n  toString() {\n    return `Type[${ this.major }].${ this.name }`;\n  }\n  compare(typ) {\n    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0;\n  }\n}\nType.uint = new Type(0, 'uint', true);\nType.negint = new Type(1, 'negint', true);\nType.bytes = new Type(2, 'bytes', true);\nType.string = new Type(3, 'string', true);\nType.array = new Type(4, 'array', false);\nType.map = new Type(5, 'map', false);\nType.tag = new Type(6, 'tag', false);\nType.float = new Type(7, 'float', true);\nType.false = new Type(7, 'false', true);\nType.true = new Type(7, 'true', true);\nType.null = new Type(7, 'null', true);\nType.undefined = new Type(7, 'undefined', true);\nType.break = new Type(7, 'break', true);\nclass Token {\n  constructor(type, value, encodedLength) {\n    this.type = type;\n    this.value = value;\n    this.encodedLength = encodedLength;\n    this.encodedBytes = undefined;\n  }\n  toString() {\n    return `Token[${ this.type }].${ this.value }`;\n  }\n}\n\nexports.Token = Token;\nexports.Type = Type;\n","module.exports = function (xs, fn) {\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        var x = fn(xs[i], i);\n        if (isArray(x)) res.push.apply(res, x);\n        else res.push(x);\n    }\n    return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n    return Object.prototype.toString.call(xs) === '[object Array]';\n};\n","\"use strict\";\n/**\n * Returns a `Buffer` instance from the given data URI `uri`.\n *\n * @param {String} uri Data URI to turn into a Buffer instance\n * @return {Buffer} Buffer instance from Data URI\n * @api public\n */\nfunction dataUriToBuffer(uri) {\n    if (!/^data:/i.test(uri)) {\n        throw new TypeError('`uri` does not appear to be a Data URI (must begin with \"data:\")');\n    }\n    // strip newlines\n    uri = uri.replace(/\\r?\\n/g, '');\n    // split the URI up into the \"metadata\" and the \"data\" portions\n    const firstComma = uri.indexOf(',');\n    if (firstComma === -1 || firstComma <= 4) {\n        throw new TypeError('malformed data: URI');\n    }\n    // remove the \"data:\" scheme and parse the metadata\n    const meta = uri.substring(5, firstComma).split(';');\n    let charset = '';\n    let base64 = false;\n    const type = meta[0] || 'text/plain';\n    let typeFull = type;\n    for (let i = 1; i < meta.length; i++) {\n        if (meta[i] === 'base64') {\n            base64 = true;\n        }\n        else {\n            typeFull += `;${meta[i]}`;\n            if (meta[i].indexOf('charset=') === 0) {\n                charset = meta[i].substring(8);\n            }\n        }\n    }\n    // defaults to US-ASCII only if type is not provided\n    if (!meta[0] && !charset.length) {\n        typeFull += ';charset=US-ASCII';\n        charset = 'US-ASCII';\n    }\n    // get the encoded data portion and decode URI-encoded chars\n    const encoding = base64 ? 'base64' : 'ascii';\n    const data = unescape(uri.substring(firstComma + 1));\n    const buffer = Buffer.from(data, encoding);\n    // set `.type` and `.typeFull` properties to MIME type\n    buffer.type = type;\n    buffer.typeFull = typeFull;\n    // set the `.charset` property\n    buffer.charset = charset;\n    return buffer;\n}\nmodule.exports = dataUriToBuffer;\n//# sourceMappingURL=index.js.map","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar Path = require('path');\nvar fs = require('fs');\nvar glob = require('it-glob');\nvar errCode = require('err-code');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar Path__default = /*#__PURE__*/_interopDefaultLegacy(Path);\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\nvar glob__default = /*#__PURE__*/_interopDefaultLegacy(glob);\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nasync function getFilesFromPath(paths, options) {\n  const files = [];\n  for await (const file of filesFromPath(paths, options)) {\n    files.push(file);\n  }\n  return files;\n}\nasync function* filesFromPath(paths, options) {\n  options = options || {};\n  if (typeof paths === 'string') {\n    paths = [paths];\n  }\n  const globSourceOptions = {\n    recursive: true,\n    glob: {\n      dot: Boolean(options.hidden),\n      ignore: Array.isArray(options.ignore) ? options.ignore : [],\n      follow: options.followSymlinks != null ? options.followSymlinks : true\n    }\n  };\n  for await (const path of paths) {\n    if (typeof path !== 'string') {\n      throw errCode__default['default'](new Error('Path must be a string'), 'ERR_INVALID_PATH', { path });\n    }\n    const absolutePath = Path__default['default'].resolve(process.cwd(), path);\n    const stat = await fs.promises.stat(absolutePath);\n    const prefix = Path__default['default'].dirname(absolutePath);\n    let mode = options.mode;\n    if (options.preserveMode) {\n      mode = stat.mode;\n    }\n    let mtime = options.mtime;\n    if (options.preserveMtime) {\n      mtime = stat.mtime;\n    }\n    yield* toGlobSource({\n      path,\n      type: stat.isDirectory() ? 'dir' : 'file',\n      prefix,\n      mode,\n      mtime,\n      size: stat.size,\n      preserveMode: options.preserveMode,\n      preserveMtime: options.preserveMtime\n    }, globSourceOptions);\n  }\n}\nasync function* toGlobSource({path, type, prefix, mode, mtime, size, preserveMode, preserveMtime}, options) {\n  options = options || {};\n  const baseName = Path__default['default'].basename(path);\n  if (type === 'file') {\n    yield {\n      name: `/${ baseName.replace(prefix, '') }`,\n      stream: () => fs__default['default'].createReadStream(Path__default['default'].isAbsolute(path) ? path : Path__default['default'].join(process.cwd(), path)),\n      mode,\n      mtime,\n      size\n    };\n    return;\n  }\n  const globOptions = Object.assign({}, options.glob, {\n    cwd: path,\n    nodir: false,\n    realpath: false,\n    absolute: true\n  });\n  for await (const p of glob__default['default'](path, '**/*', globOptions)) {\n    const stat = await fs.promises.stat(p);\n    if (!stat.isFile()) {\n      continue;\n    }\n    if (preserveMode || preserveMtime) {\n      if (preserveMode) {\n        mode = stat.mode;\n      }\n      if (preserveMtime) {\n        mtime = stat.mtime;\n      }\n    }\n    yield {\n      name: toPosix(p.replace(prefix, '')),\n      stream: () => fs__default['default'].createReadStream(p),\n      mode,\n      mtime,\n      size: stat.size\n    };\n  }\n}\nconst toPosix = path => path.replace(/\\\\/g, '/');\n\nexports.filesFromPath = filesFromPath;\nexports.getFilesFromPath = getFilesFromPath;\n","'use strict'\n\n// @ts-ignore\nconst SparseArray = require('sparse-array')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n/**\n * @typedef {import('./consumable-hash').InfiniteHash} InfiniteHash\n * @typedef {import('../').UserBucketOptions} UserBucketOptions\n */\n\n/**\n * @template V\n * @typedef {object} BucketChild<V>\n * @property {string} key\n * @property {V} value\n * @property {InfiniteHash} hash\n */\n\n/**\n * @template B\n *\n * @typedef {object} SA<B>\n * @property {number} length\n * @property {() => B[]} compactArray\n * @property {(i: number) => B} get\n * @property {(i: number, value: B) => void} set\n * @property {<A> (fn: (acc: A, curr: B, index: number) => A, initial: A) => B} reduce\n * @property {(fn: (item: B) => boolean) => B | undefined} find\n * @property {() => number[]} bitField\n * @property {(i: number) => void} unset\n */\n\n/**\n * @template T\n *\n * @typedef {object} BucketPosition<T>\n * @property {Bucket<T>} bucket\n * @property {number} pos\n * @property {InfiniteHash} hash\n * @property {BucketChild<T>} [existingChild]\n */\n\n/**\n * @typedef {object} BucketOptions\n * @property {number} bits\n * @property {(value: Uint8Array | InfiniteHash) => InfiniteHash} hash\n */\n\n/**\n * @template T\n */\nclass Bucket {\n  /**\n   * @param {BucketOptions} options\n   * @param {Bucket<T>} [parent]\n   * @param {number} [posAtParent=0]\n   */\n  constructor (options, parent, posAtParent = 0) {\n    this._options = options\n    this._popCount = 0\n    this._parent = parent\n    this._posAtParent = posAtParent\n\n    /** @type {SA<Bucket<T> | BucketChild<T>>} */\n    this._children = new SparseArray()\n\n    /** @type {string | null} */\n    this.key = null\n  }\n\n  /**\n   * @param {string} key\n   * @param {T} value\n   */\n  async put (key, value) {\n    const place = await this._findNewBucketAndPos(key)\n\n    await place.bucket._putAt(place, key, value)\n  }\n\n  /**\n   * @param {string} key\n   */\n  async get (key) {\n    const child = await this._findChild(key)\n\n    if (child) {\n      return child.value\n    }\n  }\n\n  /**\n   * @param {string} key\n   */\n  async del (key) {\n    const place = await this._findPlace(key)\n    const child = place.bucket._at(place.pos)\n\n    if (child && child.key === key) {\n      place.bucket._delAt(place.pos)\n    }\n  }\n\n  /**\n   * @returns {number}\n   */\n  leafCount () {\n    const children = this._children.compactArray()\n\n    return children.reduce((acc, child) => {\n      if (child instanceof Bucket) {\n        return acc + child.leafCount()\n      }\n\n      return acc + 1\n    }, 0)\n  }\n\n  childrenCount () {\n    return this._children.length\n  }\n\n  onlyChild () {\n    return this._children.get(0)\n  }\n\n  /**\n   * @returns {Iterable<BucketChild<T>>}\n   */\n  * eachLeafSeries () {\n    const children = this._children.compactArray()\n\n    for (const child of children) {\n      if (child instanceof Bucket) {\n        yield * child.eachLeafSeries()\n      } else {\n        yield child\n      }\n    }\n\n    // this is necessary because tsc requires a @return annotation as it\n    // can't derive a return type due to the recursion, and eslint requires\n    // a return statement when there is a @return annotation\n    return []\n  }\n\n  /**\n   * @param {(value: BucketChild<T>, index: number) => T} map\n   * @param {(reduced: any) => any} reduce\n   */\n  serialize (map, reduce) {\n    /** @type {T[]} */\n    const acc = []\n    // serialize to a custom non-sparse representation\n    return reduce(this._children.reduce((acc, child, index) => {\n      if (child) {\n        if (child instanceof Bucket) {\n          acc.push(child.serialize(map, reduce))\n        } else {\n          acc.push(map(child, index))\n        }\n      }\n      return acc\n    }, acc))\n  }\n\n  /**\n   * @param {(value: BucketChild<T>) => Promise<T[]>} asyncMap\n   * @param {(reduced: any) => Promise<any>} asyncReduce\n   */\n  asyncTransform (asyncMap, asyncReduce) {\n    return asyncTransformBucket(this, asyncMap, asyncReduce)\n  }\n\n  toJSON () {\n    return this.serialize(mapNode, reduceNodes)\n  }\n\n  prettyPrint () {\n    return JSON.stringify(this.toJSON(), null, '  ')\n  }\n\n  tableSize () {\n    return Math.pow(2, this._options.bits)\n  }\n\n  /**\n   * @param {string} key\n   * @returns {Promise<BucketChild<T> | undefined>}\n   */\n  async _findChild (key) {\n    const result = await this._findPlace(key)\n    const child = result.bucket._at(result.pos)\n\n    if (child instanceof Bucket) {\n      // should not be possible, this._findPlace should always\n      // return a location for a child, not a bucket\n      return undefined\n    }\n\n    if (child && child.key === key) {\n      return child\n    }\n  }\n\n  /**\n   * @param {string | InfiniteHash} key\n   * @returns {Promise<BucketPosition<T>>}\n   */\n  async _findPlace (key) {\n    const hashValue = this._options.hash(typeof key === 'string' ? uint8ArrayFromString(key) : key)\n    const index = await hashValue.take(this._options.bits)\n\n    const child = this._children.get(index)\n\n    if (child instanceof Bucket) {\n      return child._findPlace(hashValue)\n    }\n\n    return {\n      bucket: this,\n      pos: index,\n      hash: hashValue,\n      existingChild: child\n    }\n  }\n\n  /**\n   * @param {string | InfiniteHash} key\n   * @returns {Promise<BucketPosition<T>>}\n   */\n  async _findNewBucketAndPos (key) {\n    const place = await this._findPlace(key)\n\n    if (place.existingChild && place.existingChild.key !== key) {\n      // conflict\n      const bucket = new Bucket(this._options, place.bucket, place.pos)\n      place.bucket._putObjectAt(place.pos, bucket)\n\n      // put the previous value\n      const newPlace = await bucket._findPlace(place.existingChild.hash)\n      newPlace.bucket._putAt(newPlace, place.existingChild.key, place.existingChild.value)\n\n      return bucket._findNewBucketAndPos(place.hash)\n    }\n\n    // no conflict, we found the place\n    return place\n  }\n\n  /**\n   * @param {BucketPosition<T>} place\n   * @param {string} key\n   * @param {T} value\n   */\n  _putAt (place, key, value) {\n    this._putObjectAt(place.pos, {\n      key: key,\n      value: value,\n      hash: place.hash\n    })\n  }\n\n  /**\n   * @param {number} pos\n   * @param {Bucket<T> | BucketChild<T>} object\n   */\n  _putObjectAt (pos, object) {\n    if (!this._children.get(pos)) {\n      this._popCount++\n    }\n    this._children.set(pos, object)\n  }\n\n  /**\n   * @param {number} pos\n   */\n  _delAt (pos) {\n    if (pos === -1) {\n      throw new Error('Invalid position')\n    }\n\n    if (this._children.get(pos)) {\n      this._popCount--\n    }\n    this._children.unset(pos)\n    this._level()\n  }\n\n  _level () {\n    if (this._parent && this._popCount <= 1) {\n      if (this._popCount === 1) {\n        // remove myself from parent, replacing me with my only child\n        const onlyChild = this._children.find(exists)\n\n        if (onlyChild && !(onlyChild instanceof Bucket)) {\n          const hash = onlyChild.hash\n          hash.untake(this._options.bits)\n          const place = {\n            pos: this._posAtParent,\n            hash: hash,\n            bucket: this._parent\n          }\n          this._parent._putAt(place, onlyChild.key, onlyChild.value)\n        }\n      } else {\n        this._parent._delAt(this._posAtParent)\n      }\n    }\n  }\n\n  /**\n   * @param {number} index\n   * @returns {BucketChild<T> | Bucket<T> | undefined}\n   */\n  _at (index) {\n    return this._children.get(index)\n  }\n}\n\n/**\n * @param {any} o\n */\nfunction exists (o) {\n  return Boolean(o)\n}\n\n/**\n *\n * @param {*} node\n * @param {number} index\n */\nfunction mapNode (node, index) {\n  return node.key\n}\n\n/**\n * @param {*} nodes\n */\nfunction reduceNodes (nodes) {\n  return nodes\n}\n\n/**\n * @template T\n *\n * @param {Bucket<T>} bucket\n * @param {(value: BucketChild<T>) => Promise<T[]>} asyncMap\n * @param {(reduced: any) => Promise<any>} asyncReduce\n */\nasync function asyncTransformBucket (bucket, asyncMap, asyncReduce) {\n  const output = []\n\n  for (const child of bucket._children.compactArray()) {\n    if (child instanceof Bucket) {\n      await asyncTransformBucket(child, asyncMap, asyncReduce)\n    } else {\n      const mappedChildren = await asyncMap(child)\n\n      output.push({\n        bitField: bucket._children.bitField(),\n        children: mappedChildren\n      })\n    }\n  }\n\n  return asyncReduce(output)\n}\n\nmodule.exports = Bucket\n","'use strict'\n\nconst START_MASKS = [\n  0b11111111,\n  0b11111110,\n  0b11111100,\n  0b11111000,\n  0b11110000,\n  0b11100000,\n  0b11000000,\n  0b10000000\n]\n\nconst STOP_MASKS = [\n  0b00000001,\n  0b00000011,\n  0b00000111,\n  0b00001111,\n  0b00011111,\n  0b00111111,\n  0b01111111,\n  0b11111111\n]\n\nmodule.exports = class ConsumableBuffer {\n  /**\n   * @param {Uint8Array} value\n   */\n  constructor (value) {\n    this._value = value\n    this._currentBytePos = value.length - 1\n    this._currentBitPos = 7\n  }\n\n  availableBits () {\n    return this._currentBitPos + 1 + this._currentBytePos * 8\n  }\n\n  totalBits () {\n    return this._value.length * 8\n  }\n\n  /**\n   * @param {number} bits\n   */\n  take (bits) {\n    let pendingBits = bits\n    let result = 0\n    while (pendingBits && this._haveBits()) {\n      const byte = this._value[this._currentBytePos]\n      const availableBits = this._currentBitPos + 1\n      const taking = Math.min(availableBits, pendingBits)\n      const value = byteBitsToInt(byte, availableBits - taking, taking)\n      result = (result << taking) + value\n\n      pendingBits -= taking\n\n      this._currentBitPos -= taking\n      if (this._currentBitPos < 0) {\n        this._currentBitPos = 7\n        this._currentBytePos--\n      }\n    }\n\n    return result\n  }\n\n  /**\n   * @param {number} bits\n   */\n  untake (bits) {\n    this._currentBitPos += bits\n    while (this._currentBitPos > 7) {\n      this._currentBitPos -= 8\n      this._currentBytePos += 1\n    }\n  }\n\n  _haveBits () {\n    return this._currentBytePos >= 0\n  }\n}\n\n/**\n * @param {number} byte\n * @param {number} start\n * @param {number} length\n */\nfunction byteBitsToInt (byte, start, length) {\n  const mask = maskFor(start, length)\n  return (byte & mask) >>> start\n}\n\n/**\n * @param {number} start\n * @param {number} length\n */\nfunction maskFor (start, length) {\n  return START_MASKS[start] & STOP_MASKS[Math.min(length + start - 1, 7)]\n}\n","'use strict'\n\nconst ConsumableBuffer = require('./consumable-buffer')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\n/**\n * @param {(value: Uint8Array) => Promise<Uint8Array>} hashFn\n */\nfunction wrapHash (hashFn) {\n  /**\n   * @param {InfiniteHash | Uint8Array} value\n   */\n  function hashing (value) {\n    if (value instanceof InfiniteHash) {\n      // already a hash. return it\n      return value\n    } else {\n      return new InfiniteHash(value, hashFn)\n    }\n  }\n\n  return hashing\n}\n\nclass InfiniteHash {\n  /**\n   *\n   * @param {Uint8Array} value\n   * @param {(value: Uint8Array) => Promise<Uint8Array>} hashFn\n   */\n  constructor (value, hashFn) {\n    if (!(value instanceof Uint8Array)) {\n      throw new Error('can only hash Uint8Arrays')\n    }\n\n    this._value = value\n    this._hashFn = hashFn\n    this._depth = -1\n    this._availableBits = 0\n    this._currentBufferIndex = 0\n\n    /** @type {ConsumableBuffer[]} */\n    this._buffers = []\n  }\n\n  /**\n   * @param {number} bits\n   */\n  async take (bits) {\n    let pendingBits = bits\n\n    while (this._availableBits < pendingBits) {\n      await this._produceMoreBits()\n    }\n\n    let result = 0\n\n    while (pendingBits > 0) {\n      const hash = this._buffers[this._currentBufferIndex]\n      const available = Math.min(hash.availableBits(), pendingBits)\n      const took = hash.take(available)\n      result = (result << available) + took\n      pendingBits -= available\n      this._availableBits -= available\n\n      if (hash.availableBits() === 0) {\n        this._currentBufferIndex++\n      }\n    }\n\n    return result\n  }\n\n  /**\n   * @param {number} bits\n   */\n  untake (bits) {\n    let pendingBits = bits\n\n    while (pendingBits > 0) {\n      const hash = this._buffers[this._currentBufferIndex]\n      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits)\n      hash.untake(availableForUntake)\n      pendingBits -= availableForUntake\n      this._availableBits += availableForUntake\n\n      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {\n        this._depth--\n        this._currentBufferIndex--\n      }\n    }\n  }\n\n  async _produceMoreBits () {\n    this._depth++\n\n    const value = this._depth ? uint8ArrayConcat([this._value, Uint8Array.from([this._depth])]) : this._value\n    const hashValue = await this._hashFn(value)\n    const buffer = new ConsumableBuffer(hashValue)\n\n    this._buffers.push(buffer)\n    this._availableBits += buffer.availableBits()\n  }\n}\n\nmodule.exports = wrapHash\nmodule.exports.InfiniteHash = InfiniteHash\n","'use strict'\n\nconst Bucket = require('./bucket')\nconst wrapHash = require('./consumable-hash')\n\n/**\n * @typedef {object} UserBucketOptions\n * @property {(value: Uint8Array) => Promise<Uint8Array>} hashFn\n * @property {number} [bits=8]\n */\n\n/**\n * @param {UserBucketOptions} options\n */\nfunction createHAMT (options) {\n  if (!options || !options.hashFn) {\n    throw new Error('please define an options.hashFn')\n  }\n\n  const bucketOptions = {\n    bits: options.bits || 8,\n    hash: wrapHash(options.hashFn)\n  }\n\n  return new Bucket(bucketOptions)\n}\n\nmodule.exports = {\n  createHAMT,\n  Bucket\n}\n","'use strict'\n\nconst drain = require('it-drain')\nconst filter = require('it-filter')\nconst take = require('it-take')\nconst all = require('it-all')\n\n/**\n * Collect all values from the iterable and sort them using\n * the passed sorter function\n *\n * @template T\n * @param {AsyncIterable<T> | Iterable<T>} iterable\n * @param {(a: T, b: T) => -1 | 0 | 1} sorter\n * @returns {AsyncIterable<T>}\n */\nconst sortAll = (iterable, sorter) => {\n  return (async function * () {\n    const values = await all(iterable)\n    yield * values.sort(sorter)\n  })()\n}\n\n/**\n * @typedef {import('./types').Options} Options\n * @typedef {import('./types').Pair} Pair\n * @typedef {import('./types').Blockstore} Blockstore\n * @typedef {import('./types').Query} Query\n * @typedef {import('./types').KeyQuery} KeyQuery\n * @typedef {import('./types').Batch} Batch\n *\n * @typedef {import('multiformats').CID} CID\n */\n\n/**\n * @template O\n * @typedef {import('interface-store').AwaitIterable<O>} AwaitIterable\n */\n\n/**\n * @implements {Blockstore}\n */\nclass BlockstoreAdapter {\n  /**\n   * @returns {Promise<void>}\n   */\n  open () {\n    return Promise.reject(new Error('.open is not implemented'))\n  }\n\n  /**\n   * @returns {Promise<void>}\n   */\n  close () {\n    return Promise.reject(new Error('.close is not implemented'))\n  }\n\n  /**\n   * @param {CID} key\n   * @param {Uint8Array} val\n   * @param {Options} [options]\n   * @returns {Promise<void>}\n   */\n  put (key, val, options) {\n    return Promise.reject(new Error('.put is not implemented'))\n  }\n\n  /**\n   * @param {CID} key\n   * @param {Options} [options]\n   * @returns {Promise<Uint8Array>}\n   */\n  get (key, options) {\n    return Promise.reject(new Error('.get is not implemented'))\n  }\n\n  /**\n   * @param {CID} key\n   * @param {Options} [options]\n   * @returns {Promise<boolean>}\n   */\n  has (key, options) {\n    return Promise.reject(new Error('.has is not implemented'))\n  }\n\n  /**\n   * @param {CID} key\n   * @param {Options} [options]\n   * @returns {Promise<void>}\n   */\n  delete (key, options) {\n    return Promise.reject(new Error('.delete is not implemented'))\n  }\n\n  /**\n   * @param {AwaitIterable<Pair>} source\n   * @param {Options} [options]\n   * @returns {AsyncIterable<Pair>}\n   */\n  async * putMany (source, options = {}) {\n    for await (const { key, value } of source) {\n      await this.put(key, value, options)\n      yield { key, value }\n    }\n  }\n\n  /**\n   * @param {AwaitIterable<CID>} source\n   * @param {Options} [options]\n   * @returns {AsyncIterable<Uint8Array>}\n   */\n  async * getMany (source, options = {}) {\n    for await (const key of source) {\n      yield this.get(key, options)\n    }\n  }\n\n  /**\n   * @param {AwaitIterable<CID>} source\n   * @param {Options} [options]\n   * @returns {AsyncIterable<CID>}\n   */\n  async * deleteMany (source, options = {}) {\n    for await (const key of source) {\n      await this.delete(key, options)\n      yield key\n    }\n  }\n\n  /**\n   * @returns {Batch}\n   */\n  batch () {\n    /** @type {Pair[]} */\n    let puts = []\n    /** @type {CID[]} */\n    let dels = []\n\n    return {\n      put (key, value) {\n        puts.push({ key, value })\n      },\n\n      delete (key) {\n        dels.push(key)\n      },\n      commit: async (options) => {\n        await drain(this.putMany(puts, options))\n        puts = []\n        await drain(this.deleteMany(dels, options))\n        dels = []\n      }\n    }\n  }\n\n  /**\n   * Extending classes should override `query` or implement this method\n   *\n   * @param {Query} q\n   * @param {Options} [options]\n   * @returns {AsyncIterable<Pair>}\n   */\n  // eslint-disable-next-line require-yield\n  async * _all (q, options) {\n    throw new Error('._all is not implemented')\n  }\n\n  /**\n   * Extending classes should override `queryKeys` or implement this method\n   *\n   * @param {KeyQuery} q\n   * @param {Options} [options]\n   * @returns {AsyncIterable<CID>}\n   */\n  // eslint-disable-next-line require-yield\n  async * _allKeys (q, options) {\n    throw new Error('._allKeys is not implemented')\n  }\n\n  /**\n   * @param {Query} q\n   * @param {Options} [options]\n   */\n  query (q, options) {\n    let it = this._all(q, options)\n\n    if (q.prefix != null) {\n      it = filter(it, (/** @type {Pair} */ e) =>\n        e.key.toString().startsWith(q.prefix || '')\n      )\n    }\n\n    if (Array.isArray(q.filters)) {\n      it = q.filters.reduce((it, f) => filter(it, f), it)\n    }\n\n    if (Array.isArray(q.orders)) {\n      it = q.orders.reduce((it, f) => sortAll(it, f), it)\n    }\n\n    if (q.offset != null) {\n      let i = 0\n      it = filter(it, () => i++ >= (q.offset || 0))\n    }\n\n    if (q.limit != null) {\n      it = take(it, q.limit)\n    }\n\n    return it\n  }\n\n  /**\n   * @param {KeyQuery} q\n   * @param {Options} [options]\n   */\n  queryKeys (q, options) {\n    let it = this._allKeys(q, options)\n\n    if (q.prefix != null) {\n      it = filter(it, (/** @type {CID} */ cid) => cid.toString().startsWith(q.prefix || ''))\n    }\n\n    if (Array.isArray(q.filters)) {\n      it = q.filters.reduce((it, f) => filter(it, f), it)\n    }\n\n    if (Array.isArray(q.orders)) {\n      it = q.orders.reduce((it, f) => sortAll(it, f), it)\n    }\n\n    if (q.offset != null) {\n      let i = 0\n      it = filter(it, () => i++ >= /** @type {number} */ (q.offset))\n    }\n\n    if (q.limit != null) {\n      it = take(it, q.limit)\n    }\n\n    return it\n  }\n}\n\nmodule.exports = BlockstoreAdapter\n","'use strict'\n\nconst errCode = require('err-code')\n\n/**\n * @param {Error} [err]\n */\nfunction notFoundError (err) {\n  err = err || new Error('Not Found')\n  return errCode(err, 'ERR_NOT_FOUND')\n}\n\nmodule.exports = {\n  notFoundError\n}\n","'use strict'\n\nconst BlockstoreAdapter = require('./adapter')\nconst MemoryBlockstore = require('./memory')\n\n/**\n * @typedef {import('./types').Options} Options\n * @typedef {import('./types').Pair} Pair\n * @typedef {import('./types').Batch} Batch\n * @typedef {import('./types').Blockstore} Blockstore\n * @typedef {import('./types').QueryFilter} QueryFilter\n * @typedef {import('./types').QueryOrder} QueryOrder\n * @typedef {import('./types').Query} Query\n * @typedef {import('./types').KeyQueryFilter} KeyQueryFilter\n * @typedef {import('./types').KeyQueryOrder} KeyQueryOrder\n * @typedef {import('./types').KeyQuery} KeyQuery\n */\n\nmodule.exports = {\n  BlockstoreAdapter,\n  MemoryBlockstore\n}\n","'use strict'\n\nconst Adapter = require('./adapter')\nconst { base32 } = require('multiformats/bases/base32')\nconst raw = require('multiformats/codecs/raw')\nconst { CID } = require('multiformats/cid')\nconst Digest = require('multiformats/hashes/digest')\nconst Errors = require('./errors')\n\n/**\n * @typedef {import('./types').Pair} Pair\n * @typedef {import('./types').Blockstore} Blockstore\n * @typedef {import('interface-store').Options} Options\n */\n\n/**\n * @class MemoryBlockstore\n * @implements {Blockstore}\n */\nclass MemoryBlockstore extends Adapter {\n  constructor () {\n    super()\n\n    /** @type {Record<string, Uint8Array>} */\n    this.data = {}\n  }\n\n  open () {\n    return Promise.resolve()\n  }\n\n  close () {\n    return Promise.resolve()\n  }\n\n  /**\n   * @param {CID} key\n   * @param {Uint8Array} val\n   */\n  async put (key, val) { // eslint-disable-line require-await\n    this.data[base32.encode(key.multihash.bytes)] = val\n  }\n\n  /**\n   * @param {CID} key\n   */\n  async get (key) {\n    const exists = await this.has(key)\n    if (!exists) throw Errors.notFoundError()\n    return this.data[base32.encode(key.multihash.bytes)]\n  }\n\n  /**\n   * @param {CID} key\n   */\n  async has (key) { // eslint-disable-line require-await\n    return this.data[base32.encode(key.multihash.bytes)] !== undefined\n  }\n\n  /**\n   * @param {CID} key\n   */\n  async delete (key) { // eslint-disable-line require-await\n    delete this.data[base32.encode(key.multihash.bytes)]\n  }\n\n  async * _all () {\n    yield * Object.entries(this.data)\n      .map(([key, value]) => ({ key: CID.createV1(raw.code, Digest.decode(base32.decode(key))), value }))\n  }\n\n  async * _allKeys () {\n    yield * Object.entries(this.data)\n      .map(([key]) => CID.createV1(raw.code, Digest.decode(base32.decode(key))))\n  }\n}\n\nmodule.exports = MemoryBlockstore\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.FsBlockStore = void 0;\nconst fs_1 = __importDefault(require(\"fs\"));\nconst os_1 = __importDefault(require(\"os\"));\nconst multiformats_1 = require(\"multiformats\");\nconst interface_blockstore_1 = require(\"interface-blockstore\");\nclass FsBlockStore extends interface_blockstore_1.BlockstoreAdapter {\n    constructor() {\n        super();\n        this.path = `${os_1.default.tmpdir()}/${(parseInt(String(Math.random() * 1e9), 10)).toString() + Date.now()}`;\n        this._opened = false;\n    }\n    async _open() {\n        if (this._opening) {\n            await this._opening;\n        }\n        else {\n            this._opening = fs_1.default.promises.mkdir(this.path);\n            await this._opening;\n            this._opened = true;\n        }\n    }\n    async put(cid, bytes) {\n        if (!this._opened) {\n            await this._open();\n        }\n        const cidStr = cid.toString();\n        const location = `${this.path}/${cidStr}`;\n        await fs_1.default.promises.writeFile(location, bytes);\n    }\n    async get(cid) {\n        if (!this._opened) {\n            await this._open();\n        }\n        const cidStr = cid.toString();\n        const location = `${this.path}/${cidStr}`;\n        const bytes = await fs_1.default.promises.readFile(location);\n        return bytes;\n    }\n    async *blocks() {\n        if (!this._opened) {\n            await this._open();\n        }\n        const cids = await fs_1.default.promises.readdir(this.path);\n        for (const cidStr of cids) {\n            const location = `${this.path}/${cidStr}`;\n            const bytes = await fs_1.default.promises.readFile(location);\n            yield { cid: multiformats_1.CID.parse(cidStr), bytes };\n        }\n    }\n    async close() {\n        if (this._opened) {\n            await fs_1.default.promises.rm(this.path, { recursive: true });\n        }\n        this._opened = false;\n    }\n}\nexports.FsBlockStore = FsBlockStore;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.MemoryBlockStore = void 0;\nconst multiformats_1 = require(\"multiformats\");\nconst interface_blockstore_1 = require(\"interface-blockstore\");\nclass MemoryBlockStore extends interface_blockstore_1.BlockstoreAdapter {\n    constructor() {\n        super();\n        this.store = new Map();\n    }\n    async *blocks() {\n        for (const [cidStr, bytes] of this.store.entries()) {\n            yield { cid: multiformats_1.CID.parse(cidStr), bytes };\n        }\n    }\n    put(cid, bytes) {\n        this.store.set(cid.toString(), bytes);\n        return Promise.resolve();\n    }\n    get(cid) {\n        const bytes = this.store.get(cid.toString());\n        if (!bytes) {\n            throw new Error(`block with cid ${cid.toString()} no found`);\n        }\n        return Promise.resolve(bytes);\n    }\n    close() {\n        this.store.clear();\n        return Promise.resolve();\n    }\n}\nexports.MemoryBlockStore = MemoryBlockStore;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.unixfsImporterOptionsDefault = void 0;\nconst sha2_1 = require(\"multiformats/hashes/sha2\");\nexports.unixfsImporterOptionsDefault = {\n    cidVersion: 1,\n    chunker: 'fixed',\n    maxChunkSize: 262144,\n    hasher: sha2_1.sha256,\n    rawLeaves: true,\n    wrapWithDirectory: true\n};\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.pack = void 0;\nconst it_last_1 = __importDefault(require(\"it-last\"));\nconst it_pipe_1 = __importDefault(require(\"it-pipe\"));\nconst car_1 = require(\"@ipld/car\");\nconst ipfs_unixfs_importer_1 = require(\"ipfs-unixfs-importer\");\nconst index_js_1 = __importDefault(require(\"ipfs-core-utils/src/files/normalise-input/index.js\"));\nconst memory_1 = require(\"../blockstore/memory\");\nconst constants_1 = require(\"./constants\");\nasync function pack({ input, blockstore: userBlockstore, maxChunkSize, wrapWithDirectory }) {\n    if (!input || (Array.isArray(input) && !input.length)) {\n        throw new Error('missing input file(s)');\n    }\n    const blockstore = userBlockstore ? userBlockstore : new memory_1.MemoryBlockStore();\n    // Consume the source\n    const rootEntry = await it_last_1.default(it_pipe_1.default(index_js_1.default(input), (source) => ipfs_unixfs_importer_1.importer(source, blockstore, {\n        ...constants_1.unixfsImporterOptionsDefault,\n        maxChunkSize: maxChunkSize || constants_1.unixfsImporterOptionsDefault.maxChunkSize,\n        wrapWithDirectory: wrapWithDirectory === false ? false : constants_1.unixfsImporterOptionsDefault.wrapWithDirectory\n    })));\n    if (!rootEntry || !rootEntry.cid) {\n        throw new Error('given input could not be parsed correctly');\n    }\n    const root = rootEntry.cid;\n    const { writer, out } = await car_1.CarWriter.create([root]);\n    for await (const block of blockstore.blocks()) {\n        writer.put(block);\n    }\n    writer.close();\n    if (!userBlockstore) {\n        await blockstore.close();\n    }\n    return { root, out };\n}\nexports.pack = pack;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.unpackStream = exports.unpack = void 0;\nconst browser_readablestream_to_it_1 = __importDefault(require(\"browser-readablestream-to-it\"));\nconst iterator_1 = require(\"@ipld/car/iterator\");\nconst ipfs_unixfs_exporter_1 = __importDefault(require(\"ipfs-unixfs-exporter\"));\nconst verifying_get_only_blockstore_1 = require(\"./utils/verifying-get-only-blockstore\");\nconst memory_1 = require(\"../blockstore/memory\");\n// Export unixfs entries from car file\nasync function* unpack(carReader, roots) {\n    const verifyingBlockService = verifying_get_only_blockstore_1.VerifyingGetOnlyBlockStore.fromCarReader(carReader);\n    if (!roots || roots.length === 0) {\n        roots = await carReader.getRoots();\n    }\n    for (const root of roots) {\n        yield* ipfs_unixfs_exporter_1.default.recursive(root, verifyingBlockService, { /* options */});\n    }\n}\nexports.unpack = unpack;\nasync function* unpackStream(readable, { roots, blockstore: userBlockstore } = {}) {\n    const carIterator = await iterator_1.CarBlockIterator.fromIterable(asAsyncIterable(readable));\n    const blockstore = userBlockstore || new memory_1.MemoryBlockStore();\n    for await (const block of carIterator) {\n        await blockstore.put(block.cid, block.bytes);\n    }\n    const verifyingBlockStore = verifying_get_only_blockstore_1.VerifyingGetOnlyBlockStore.fromBlockstore(blockstore);\n    if (!roots || roots.length === 0) {\n        roots = await carIterator.getRoots();\n    }\n    for (const root of roots) {\n        yield* ipfs_unixfs_exporter_1.default.recursive(root, verifyingBlockStore);\n    }\n}\nexports.unpackStream = unpackStream;\n/**\n * Upgrade a ReadableStream to an AsyncIterable if it isn't already\n *\n * ReadableStream (e.g res.body) is asyncIterable in node, but not in chrome, yet.\n * see: https://bugs.chromium.org/p/chromium/issues/detail?id=929585\n */\nfunction asAsyncIterable(readable) {\n    // @ts-ignore how to convince tsc that we are checking the type here?\n    return Symbol.asyncIterator in readable ? readable : browser_readablestream_to_it_1.default(readable);\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.VerifyingGetOnlyBlockStore = void 0;\nconst uint8arrays_1 = require(\"uint8arrays\");\nconst sha2_1 = require(\"multiformats/hashes/sha2\");\nconst interface_blockstore_1 = require(\"interface-blockstore\");\nclass VerifyingGetOnlyBlockStore extends interface_blockstore_1.BlockstoreAdapter {\n    constructor(blockstore) {\n        super();\n        this.store = blockstore;\n    }\n    async get(cid) {\n        const res = await this.store.get(cid);\n        if (!res) {\n            throw new Error(`Incomplete CAR. Block missing for CID ${cid}`);\n        }\n        if (!isValid({ cid, bytes: res })) {\n            throw new Error(`Invalid CAR. Hash of block data does not match CID ${cid}`);\n        }\n        return res;\n    }\n    static fromBlockstore(b) {\n        return new VerifyingGetOnlyBlockStore(b);\n    }\n    static fromCarReader(cr) {\n        return new VerifyingGetOnlyBlockStore({\n            // Return bytes in the same fashion as a Blockstore implementation\n            get: async (cid) => {\n                const block = await cr.get(cid);\n                return block === null || block === void 0 ? void 0 : block.bytes;\n            }\n        });\n    }\n}\nexports.VerifyingGetOnlyBlockStore = VerifyingGetOnlyBlockStore;\nasync function isValid({ cid, bytes }) {\n    const hash = await sha2_1.sha256.digest(bytes);\n    return uint8arrays_1.equals(hash.digest, cid.multihash.digest);\n}\n","'use strict'\n\nconst normaliseContent = require('./normalise-content')\nconst normaliseInput = require('./normalise-input')\n\n/**\n * @typedef {import('ipfs-core-types/src/utils').ImportCandidateStream} ImportCandidateStream\n * @typedef {import('ipfs-unixfs-importer').ImportCandidate} ImportCandidate\n */\n\n/**\n * Transforms any of the `ipfs.add` input types into\n *\n * ```\n * AsyncIterable<{ path, mode, mtime, content: AsyncIterable<Uint8Array> }>\n * ```\n *\n * See https://github.com/ipfs/js-ipfs/blob/master/docs/core-api/FILES.md#ipfsadddata-options\n *\n * @param {ImportCandidateStream} input\n * @returns {AsyncGenerator<ImportCandidate, void, undefined>}\n */\nmodule.exports = (input) => normaliseInput(input, normaliseContent)\n","'use strict'\n\nconst errCode = require('err-code')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst browserStreamToIt = require('browser-readablestream-to-it')\nconst blobToIt = require('blob-to-it')\nconst itPeekable = require('it-peekable')\nconst all = require('it-all')\nconst map = require('it-map')\nconst {\n  isBytes,\n  isReadableStream,\n  isBlob\n} = require('./utils')\n\n/**\n * @param {import('./normalise-input').ToContent} input\n */\nasync function * toAsyncIterable (input) {\n  // Bytes | String\n  if (isBytes(input)) {\n    yield toBytes(input)\n    return\n  }\n\n  if (typeof input === 'string' || input instanceof String) {\n    yield toBytes(input.toString())\n    return\n  }\n\n  // Blob\n  if (isBlob(input)) {\n    yield * blobToIt(input)\n    return\n  }\n\n  // Browser stream\n  if (isReadableStream(input)) {\n    input = browserStreamToIt(input)\n  }\n\n  // (Async)Iterator<?>\n  if (Symbol.iterator in input || Symbol.asyncIterator in input) {\n    /** @type {any} peekable */\n    const peekable = itPeekable(input)\n\n    /** @type {any} value */\n    const { value, done } = await peekable.peek()\n\n    if (done) {\n      // make sure empty iterators result in empty files\n      yield * []\n      return\n    }\n\n    peekable.push(value)\n\n    // (Async)Iterable<Number>\n    if (Number.isInteger(value)) {\n      yield Uint8Array.from((await all(peekable)))\n      return\n    }\n\n    // (Async)Iterable<Bytes|String>\n    if (isBytes(value) || typeof value === 'string' || value instanceof String) {\n      yield * map(peekable, toBytes)\n      return\n    }\n  }\n\n  throw errCode(new Error(`Unexpected input: ${input}`), 'ERR_UNEXPECTED_INPUT')\n}\n\n/**\n * @param {ArrayBuffer | ArrayBufferView | string | InstanceType<typeof window.String> | number[]} chunk\n */\nfunction toBytes (chunk) {\n  if (chunk instanceof Uint8Array) {\n    return chunk\n  }\n\n  if (ArrayBuffer.isView(chunk)) {\n    return new Uint8Array(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n  }\n\n  if (chunk instanceof ArrayBuffer) {\n    return new Uint8Array(chunk)\n  }\n\n  if (Array.isArray(chunk)) {\n    return Uint8Array.from(chunk)\n  }\n\n  return uint8ArrayFromString(chunk.toString())\n}\n\nmodule.exports = toAsyncIterable\n","'use strict'\n\nconst errCode = require('err-code')\nconst browserStreamToIt = require('browser-readablestream-to-it')\nconst itPeekable = require('it-peekable')\nconst map = require('it-map')\nconst {\n  isBytes,\n  isBlob,\n  isReadableStream,\n  isFileObject\n} = require('./utils')\nconst {\n  parseMtime,\n  parseMode\n} = require('ipfs-unixfs')\n\n/**\n * @typedef {import('ipfs-core-types/src/utils').ToContent} ToContent\n * @typedef {import('ipfs-unixfs-importer').ImportCandidate} ImporterImportCandidate\n * @typedef {import('ipfs-core-types/src/utils').ImportCandidate} ImportCandidate\n */\n\n/**\n * @param {import('ipfs-core-types/src/utils').ImportCandidateStream} input\n * @param {(content:ToContent) => AsyncIterable<Uint8Array>} normaliseContent\n */\n// eslint-disable-next-line complexity\nmodule.exports = async function * normaliseInput (input, normaliseContent) {\n  if (input === null || input === undefined) {\n    return\n  }\n\n  // String\n  if (typeof input === 'string' || input instanceof String) {\n    yield toFileObject(input.toString(), normaliseContent)\n    return\n  }\n\n  // Uint8Array|ArrayBuffer|TypedArray\n  // Blob|File\n  if (isBytes(input) || isBlob(input)) {\n    yield toFileObject(input, normaliseContent)\n    return\n  }\n\n  // Browser ReadableStream\n  if (isReadableStream(input)) {\n    input = browserStreamToIt(input)\n  }\n\n  // Iterable<?>\n  if (Symbol.iterator in input || Symbol.asyncIterator in input) {\n    /** @type {any} peekable */\n    const peekable = itPeekable(input)\n\n    /** @type {any} value **/\n    const { value, done } = await peekable.peek()\n\n    if (done) {\n      // make sure empty iterators result in empty files\n      yield * []\n      return\n    }\n\n    peekable.push(value)\n\n    // (Async)Iterable<Number>\n    // (Async)Iterable<Bytes>\n    if (Number.isInteger(value) || isBytes(value)) {\n      yield toFileObject(peekable, normaliseContent)\n      return\n    }\n\n    // (Async)Iterable<Blob>\n    // (Async)Iterable<String>\n    // (Async)Iterable<{ path, content }>\n    if (isFileObject(value) || isBlob(value) || typeof value === 'string' || value instanceof String) {\n      yield * map(peekable, (/** @type {ImportCandidate} */ value) => toFileObject(value, normaliseContent))\n      return\n    }\n\n    // (Async)Iterable<(Async)Iterable<?>>\n    // (Async)Iterable<ReadableStream<?>>\n    // ReadableStream<(Async)Iterable<?>>\n    // ReadableStream<ReadableStream<?>>\n    if (value[Symbol.iterator] || value[Symbol.asyncIterator] || isReadableStream(value)) {\n      yield * map(peekable, (/** @type {ImportCandidate} */ value) => toFileObject(value, normaliseContent))\n      return\n    }\n  }\n\n  // { path, content: ? }\n  // Note: Detected _after_ (Async)Iterable<?> because Node.js streams have a\n  // `path` property that passes this check.\n  if (isFileObject(input)) {\n    yield toFileObject(input, normaliseContent)\n    return\n  }\n\n  throw errCode(new Error('Unexpected input: ' + typeof input), 'ERR_UNEXPECTED_INPUT')\n}\n\n/**\n * @param {ImportCandidate} input\n * @param {(content:ToContent) => AsyncIterable<Uint8Array>} normaliseContent\n */\nasync function toFileObject (input, normaliseContent) {\n  // @ts-ignore - Those properties don't exist on most input types\n  const { path, mode, mtime, content } = input\n\n  /** @type {ImporterImportCandidate} */\n  const file = {\n    path: path || '',\n    mode: parseMode(mode),\n    mtime: parseMtime(mtime)\n  }\n\n  if (content) {\n    file.content = await normaliseContent(content)\n  } else if (!path) { // Not already a file object with path or content prop\n    // @ts-ignore - input still can be different ToContent\n    file.content = await normaliseContent(input)\n  }\n\n  return file\n}\n","'use strict'\n\nconst { Blob } = globalThis\n\n/**\n * @param {any} obj\n * @returns {obj is ArrayBufferView|ArrayBuffer}\n */\nfunction isBytes (obj) {\n  return ArrayBuffer.isView(obj) || obj instanceof ArrayBuffer\n}\n\n/**\n * @param {any} obj\n * @returns {obj is Blob}\n */\nfunction isBlob (obj) {\n  return typeof Blob !== 'undefined' && obj instanceof Blob\n}\n\n/**\n * An object with a path or content property\n *\n * @param {any} obj\n * @returns {obj is import('ipfs-core-types/src/utils').ImportCandidate}\n */\nfunction isFileObject (obj) {\n  return typeof obj === 'object' && (obj.path || obj.content)\n}\n\n/**\n * @param {any} value\n * @returns {value is ReadableStream}\n */\nconst isReadableStream = (value) =>\n  value && typeof value.getReader === 'function'\n\nmodule.exports = {\n  isBytes,\n  isBlob,\n  isFileObject,\n  isReadableStream\n}\n","'use strict'\n\nconst {\n  Data: PBData\n} = require('./unixfs')\nconst errcode = require('err-code')\n\n/**\n * @typedef {import('./types').Mtime} Mtime\n * @typedef {import('./types').MtimeLike} MtimeLike\n */\n\nconst types = [\n  'raw',\n  'directory',\n  'file',\n  'metadata',\n  'symlink',\n  'hamt-sharded-directory'\n]\n\nconst dirTypes = [\n  'directory',\n  'hamt-sharded-directory'\n]\n\nconst DEFAULT_FILE_MODE = parseInt('0644', 8)\nconst DEFAULT_DIRECTORY_MODE = parseInt('0755', 8)\n\n/**\n * @param {string | number | undefined} [mode]\n */\nfunction parseMode (mode) {\n  if (mode == null) {\n    return undefined\n  }\n\n  if (typeof mode === 'number') {\n    return mode & 0xFFF\n  }\n\n  mode = mode.toString()\n\n  if (mode.substring(0, 1) === '0') {\n    // octal string\n    return parseInt(mode, 8) & 0xFFF\n  }\n\n  // decimal string\n  return parseInt(mode, 10) & 0xFFF\n}\n\n/**\n * @param {any} input\n */\nfunction parseMtime (input) {\n  if (input == null) {\n    return undefined\n  }\n\n  /** @type {Mtime | undefined} */\n  let mtime\n\n  // { secs, nsecs }\n  if (input.secs != null) {\n    mtime = {\n      secs: input.secs,\n      nsecs: input.nsecs\n    }\n  }\n\n  // UnixFS TimeSpec\n  if (input.Seconds != null) {\n    mtime = {\n      secs: input.Seconds,\n      nsecs: input.FractionalNanoseconds\n    }\n  }\n\n  // process.hrtime()\n  if (Array.isArray(input)) {\n    mtime = {\n      secs: input[0],\n      nsecs: input[1]\n    }\n  }\n\n  // Javascript Date\n  if (input instanceof Date) {\n    const ms = input.getTime()\n    const secs = Math.floor(ms / 1000)\n\n    mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n  }\n\n  /*\n  TODO: https://github.com/ipfs/aegir/issues/487\n\n  // process.hrtime.bigint()\n  if (input instanceof BigInt) {\n    const secs = input / BigInt(1e9)\n    const nsecs = input - (secs * BigInt(1e9))\n\n    mtime = {\n      secs: parseInt(secs.toString()),\n      nsecs: parseInt(nsecs.toString())\n    }\n  }\n  */\n\n  if (!Object.prototype.hasOwnProperty.call(mtime, 'secs')) {\n    return undefined\n  }\n\n  if (mtime != null && mtime.nsecs != null && (mtime.nsecs < 0 || mtime.nsecs > 999999999)) {\n    throw errcode(new Error('mtime-nsecs must be within the range [0,999999999]'), 'ERR_INVALID_MTIME_NSECS')\n  }\n\n  return mtime\n}\n\nclass Data {\n  /**\n   * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md\n   *\n   * @param {Uint8Array} marshaled\n   */\n  static unmarshal (marshaled) {\n    const message = PBData.decode(marshaled)\n    const decoded = PBData.toObject(message, {\n      defaults: false,\n      arrays: true,\n      longs: Number,\n      objects: false\n    })\n\n    const data = new Data({\n      type: types[decoded.Type],\n      data: decoded.Data,\n      blockSizes: decoded.blocksizes,\n      mode: decoded.mode,\n      mtime: decoded.mtime\n        ? {\n            secs: decoded.mtime.Seconds,\n            nsecs: decoded.mtime.FractionalNanoseconds\n          }\n        : undefined\n    })\n\n    // make sure we honour the original mode\n    data._originalMode = decoded.mode || 0\n\n    return data\n  }\n\n  /**\n   * @param {object} [options]\n   * @param {string} [options.type='file']\n   * @param {Uint8Array} [options.data]\n   * @param {number[]} [options.blockSizes]\n   * @param {number} [options.hashType]\n   * @param {number} [options.fanout]\n   * @param {MtimeLike | null} [options.mtime]\n   * @param {number | string} [options.mode]\n   */\n  constructor (options = {\n    type: 'file'\n  }) {\n    const {\n      type,\n      data,\n      blockSizes,\n      hashType,\n      fanout,\n      mtime,\n      mode\n    } = options\n\n    if (type && !types.includes(type)) {\n      throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    this.type = type || 'file'\n    this.data = data\n    this.hashType = hashType\n    this.fanout = fanout\n\n    /** @type {number[]} */\n    this.blockSizes = blockSizes || []\n    this._originalMode = 0\n    this.mode = parseMode(mode)\n\n    if (mtime) {\n      this.mtime = parseMtime(mtime)\n\n      if (this.mtime && !this.mtime.nsecs) {\n        this.mtime.nsecs = 0\n      }\n    }\n  }\n\n  /**\n   * @param {number | undefined} mode\n   */\n  set mode (mode) {\n    this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE\n\n    const parsedMode = parseMode(mode)\n\n    if (parsedMode !== undefined) {\n      this._mode = parsedMode\n    }\n  }\n\n  /**\n   * @returns {number | undefined}\n   */\n  get mode () {\n    return this._mode\n  }\n\n  isDirectory () {\n    return Boolean(this.type && dirTypes.includes(this.type))\n  }\n\n  /**\n   * @param {number} size\n   */\n  addBlockSize (size) {\n    this.blockSizes.push(size)\n  }\n\n  /**\n   * @param {number} index\n   */\n  removeBlockSize (index) {\n    this.blockSizes.splice(index, 1)\n  }\n\n  /**\n   * Returns `0` for directories or `data.length + sum(blockSizes)` for everything else\n   */\n  fileSize () {\n    if (this.isDirectory()) {\n      // dirs don't have file size\n      return 0\n    }\n\n    let sum = 0\n    this.blockSizes.forEach((size) => {\n      sum += size\n    })\n\n    if (this.data) {\n      sum += this.data.length\n    }\n\n    return sum\n  }\n\n  /**\n   * encode to protobuf Uint8Array\n   */\n  marshal () {\n    let type\n\n    switch (this.type) {\n      case 'raw': type = PBData.DataType.Raw; break\n      case 'directory': type = PBData.DataType.Directory; break\n      case 'file': type = PBData.DataType.File; break\n      case 'metadata': type = PBData.DataType.Metadata; break\n      case 'symlink': type = PBData.DataType.Symlink; break\n      case 'hamt-sharded-directory': type = PBData.DataType.HAMTShard; break\n      default:\n        throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    let data = this.data\n\n    if (!this.data || !this.data.length) {\n      data = undefined\n    }\n\n    let mode\n\n    if (this.mode != null) {\n      mode = (this._originalMode & 0xFFFFF000) | (parseMode(this.mode) || 0)\n\n      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {\n        mode = undefined\n      }\n\n      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {\n        mode = undefined\n      }\n    }\n\n    let mtime\n\n    if (this.mtime != null) {\n      const parsed = parseMtime(this.mtime)\n\n      if (parsed) {\n        mtime = {\n          Seconds: parsed.secs,\n          FractionalNanoseconds: parsed.nsecs\n        }\n\n        if (mtime.FractionalNanoseconds === 0) {\n          delete mtime.FractionalNanoseconds\n        }\n      }\n    }\n\n    const pbData = {\n      Type: type,\n      Data: data,\n      filesize: this.isDirectory() ? undefined : this.fileSize(),\n      blocksizes: this.blockSizes,\n      hashType: this.hashType,\n      fanout: this.fanout,\n      mode,\n      mtime\n    }\n\n    return PBData.encode(pbData).finish()\n  }\n}\n\nmodule.exports = {\n  UnixFS: Data,\n  parseMode,\n  parseMtime\n}\n","/*eslint-disable*/\n\"use strict\";\n\nvar $protobuf = require(\"protobufjs/minimal\");\n\n// Common aliases\nvar $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;\n\n// Exported root namespace\nvar $root = $protobuf.roots[\"ipfs-unixfs\"] || ($protobuf.roots[\"ipfs-unixfs\"] = {});\n\n$root.Data = (function() {\n\n    /**\n     * Properties of a Data.\n     * @exports IData\n     * @interface IData\n     * @property {Data.DataType} Type Data Type\n     * @property {Uint8Array|null} [Data] Data Data\n     * @property {number|null} [filesize] Data filesize\n     * @property {Array.<number>|null} [blocksizes] Data blocksizes\n     * @property {number|null} [hashType] Data hashType\n     * @property {number|null} [fanout] Data fanout\n     * @property {number|null} [mode] Data mode\n     * @property {IUnixTime|null} [mtime] Data mtime\n     */\n\n    /**\n     * Constructs a new Data.\n     * @exports Data\n     * @classdesc Represents a Data.\n     * @implements IData\n     * @constructor\n     * @param {IData=} [p] Properties to set\n     */\n    function Data(p) {\n        this.blocksizes = [];\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Data Type.\n     * @member {Data.DataType} Type\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Type = 0;\n\n    /**\n     * Data Data.\n     * @member {Uint8Array} Data\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Data = $util.newBuffer([]);\n\n    /**\n     * Data filesize.\n     * @member {number} filesize\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.filesize = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data blocksizes.\n     * @member {Array.<number>} blocksizes\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.blocksizes = $util.emptyArray;\n\n    /**\n     * Data hashType.\n     * @member {number} hashType\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.hashType = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data fanout.\n     * @member {number} fanout\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.fanout = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data mode.\n     * @member {number} mode\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mode = 0;\n\n    /**\n     * Data mtime.\n     * @member {IUnixTime|null|undefined} mtime\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mtime = null;\n\n    /**\n     * Encodes the specified Data message. Does not implicitly {@link Data.verify|verify} messages.\n     * @function encode\n     * @memberof Data\n     * @static\n     * @param {IData} m Data message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Data.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int32(m.Type);\n        if (m.Data != null && Object.hasOwnProperty.call(m, \"Data\"))\n            w.uint32(18).bytes(m.Data);\n        if (m.filesize != null && Object.hasOwnProperty.call(m, \"filesize\"))\n            w.uint32(24).uint64(m.filesize);\n        if (m.blocksizes != null && m.blocksizes.length) {\n            for (var i = 0; i < m.blocksizes.length; ++i)\n                w.uint32(32).uint64(m.blocksizes[i]);\n        }\n        if (m.hashType != null && Object.hasOwnProperty.call(m, \"hashType\"))\n            w.uint32(40).uint64(m.hashType);\n        if (m.fanout != null && Object.hasOwnProperty.call(m, \"fanout\"))\n            w.uint32(48).uint64(m.fanout);\n        if (m.mode != null && Object.hasOwnProperty.call(m, \"mode\"))\n            w.uint32(56).uint32(m.mode);\n        if (m.mtime != null && Object.hasOwnProperty.call(m, \"mtime\"))\n            $root.UnixTime.encode(m.mtime, w.uint32(66).fork()).ldelim();\n        return w;\n    };\n\n    /**\n     * Decodes a Data message from the specified reader or buffer.\n     * @function decode\n     * @memberof Data\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Data} Data\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Data.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Data();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Type = r.int32();\n                break;\n            case 2:\n                m.Data = r.bytes();\n                break;\n            case 3:\n                m.filesize = r.uint64();\n                break;\n            case 4:\n                if (!(m.blocksizes && m.blocksizes.length))\n                    m.blocksizes = [];\n                if ((t & 7) === 2) {\n                    var c2 = r.uint32() + r.pos;\n                    while (r.pos < c2)\n                        m.blocksizes.push(r.uint64());\n                } else\n                    m.blocksizes.push(r.uint64());\n                break;\n            case 5:\n                m.hashType = r.uint64();\n                break;\n            case 6:\n                m.fanout = r.uint64();\n                break;\n            case 7:\n                m.mode = r.uint32();\n                break;\n            case 8:\n                m.mtime = $root.UnixTime.decode(r, r.uint32());\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Type\"))\n            throw $util.ProtocolError(\"missing required 'Type'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates a Data message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Data\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Data} Data\n     */\n    Data.fromObject = function fromObject(d) {\n        if (d instanceof $root.Data)\n            return d;\n        var m = new $root.Data();\n        switch (d.Type) {\n        case \"Raw\":\n        case 0:\n            m.Type = 0;\n            break;\n        case \"Directory\":\n        case 1:\n            m.Type = 1;\n            break;\n        case \"File\":\n        case 2:\n            m.Type = 2;\n            break;\n        case \"Metadata\":\n        case 3:\n            m.Type = 3;\n            break;\n        case \"Symlink\":\n        case 4:\n            m.Type = 4;\n            break;\n        case \"HAMTShard\":\n        case 5:\n            m.Type = 5;\n            break;\n        }\n        if (d.Data != null) {\n            if (typeof d.Data === \"string\")\n                $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);\n            else if (d.Data.length)\n                m.Data = d.Data;\n        }\n        if (d.filesize != null) {\n            if ($util.Long)\n                (m.filesize = $util.Long.fromValue(d.filesize)).unsigned = true;\n            else if (typeof d.filesize === \"string\")\n                m.filesize = parseInt(d.filesize, 10);\n            else if (typeof d.filesize === \"number\")\n                m.filesize = d.filesize;\n            else if (typeof d.filesize === \"object\")\n                m.filesize = new $util.LongBits(d.filesize.low >>> 0, d.filesize.high >>> 0).toNumber(true);\n        }\n        if (d.blocksizes) {\n            if (!Array.isArray(d.blocksizes))\n                throw TypeError(\".Data.blocksizes: array expected\");\n            m.blocksizes = [];\n            for (var i = 0; i < d.blocksizes.length; ++i) {\n                if ($util.Long)\n                    (m.blocksizes[i] = $util.Long.fromValue(d.blocksizes[i])).unsigned = true;\n                else if (typeof d.blocksizes[i] === \"string\")\n                    m.blocksizes[i] = parseInt(d.blocksizes[i], 10);\n                else if (typeof d.blocksizes[i] === \"number\")\n                    m.blocksizes[i] = d.blocksizes[i];\n                else if (typeof d.blocksizes[i] === \"object\")\n                    m.blocksizes[i] = new $util.LongBits(d.blocksizes[i].low >>> 0, d.blocksizes[i].high >>> 0).toNumber(true);\n            }\n        }\n        if (d.hashType != null) {\n            if ($util.Long)\n                (m.hashType = $util.Long.fromValue(d.hashType)).unsigned = true;\n            else if (typeof d.hashType === \"string\")\n                m.hashType = parseInt(d.hashType, 10);\n            else if (typeof d.hashType === \"number\")\n                m.hashType = d.hashType;\n            else if (typeof d.hashType === \"object\")\n                m.hashType = new $util.LongBits(d.hashType.low >>> 0, d.hashType.high >>> 0).toNumber(true);\n        }\n        if (d.fanout != null) {\n            if ($util.Long)\n                (m.fanout = $util.Long.fromValue(d.fanout)).unsigned = true;\n            else if (typeof d.fanout === \"string\")\n                m.fanout = parseInt(d.fanout, 10);\n            else if (typeof d.fanout === \"number\")\n                m.fanout = d.fanout;\n            else if (typeof d.fanout === \"object\")\n                m.fanout = new $util.LongBits(d.fanout.low >>> 0, d.fanout.high >>> 0).toNumber(true);\n        }\n        if (d.mode != null) {\n            m.mode = d.mode >>> 0;\n        }\n        if (d.mtime != null) {\n            if (typeof d.mtime !== \"object\")\n                throw TypeError(\".Data.mtime: object expected\");\n            m.mtime = $root.UnixTime.fromObject(d.mtime);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Data message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Data\n     * @static\n     * @param {Data} m Data\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Data.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.arrays || o.defaults) {\n            d.blocksizes = [];\n        }\n        if (o.defaults) {\n            d.Type = o.enums === String ? \"Raw\" : 0;\n            if (o.bytes === String)\n                d.Data = \"\";\n            else {\n                d.Data = [];\n                if (o.bytes !== Array)\n                    d.Data = $util.newBuffer(d.Data);\n            }\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.filesize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.filesize = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.hashType = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.hashType = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.fanout = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.fanout = o.longs === String ? \"0\" : 0;\n            d.mode = 0;\n            d.mtime = null;\n        }\n        if (m.Type != null && m.hasOwnProperty(\"Type\")) {\n            d.Type = o.enums === String ? $root.Data.DataType[m.Type] : m.Type;\n        }\n        if (m.Data != null && m.hasOwnProperty(\"Data\")) {\n            d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;\n        }\n        if (m.filesize != null && m.hasOwnProperty(\"filesize\")) {\n            if (typeof m.filesize === \"number\")\n                d.filesize = o.longs === String ? String(m.filesize) : m.filesize;\n            else\n                d.filesize = o.longs === String ? $util.Long.prototype.toString.call(m.filesize) : o.longs === Number ? new $util.LongBits(m.filesize.low >>> 0, m.filesize.high >>> 0).toNumber(true) : m.filesize;\n        }\n        if (m.blocksizes && m.blocksizes.length) {\n            d.blocksizes = [];\n            for (var j = 0; j < m.blocksizes.length; ++j) {\n                if (typeof m.blocksizes[j] === \"number\")\n                    d.blocksizes[j] = o.longs === String ? String(m.blocksizes[j]) : m.blocksizes[j];\n                else\n                    d.blocksizes[j] = o.longs === String ? $util.Long.prototype.toString.call(m.blocksizes[j]) : o.longs === Number ? new $util.LongBits(m.blocksizes[j].low >>> 0, m.blocksizes[j].high >>> 0).toNumber(true) : m.blocksizes[j];\n            }\n        }\n        if (m.hashType != null && m.hasOwnProperty(\"hashType\")) {\n            if (typeof m.hashType === \"number\")\n                d.hashType = o.longs === String ? String(m.hashType) : m.hashType;\n            else\n                d.hashType = o.longs === String ? $util.Long.prototype.toString.call(m.hashType) : o.longs === Number ? new $util.LongBits(m.hashType.low >>> 0, m.hashType.high >>> 0).toNumber(true) : m.hashType;\n        }\n        if (m.fanout != null && m.hasOwnProperty(\"fanout\")) {\n            if (typeof m.fanout === \"number\")\n                d.fanout = o.longs === String ? String(m.fanout) : m.fanout;\n            else\n                d.fanout = o.longs === String ? $util.Long.prototype.toString.call(m.fanout) : o.longs === Number ? new $util.LongBits(m.fanout.low >>> 0, m.fanout.high >>> 0).toNumber(true) : m.fanout;\n        }\n        if (m.mode != null && m.hasOwnProperty(\"mode\")) {\n            d.mode = m.mode;\n        }\n        if (m.mtime != null && m.hasOwnProperty(\"mtime\")) {\n            d.mtime = $root.UnixTime.toObject(m.mtime, o);\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Data to JSON.\n     * @function toJSON\n     * @memberof Data\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Data.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    /**\n     * DataType enum.\n     * @name Data.DataType\n     * @enum {number}\n     * @property {number} Raw=0 Raw value\n     * @property {number} Directory=1 Directory value\n     * @property {number} File=2 File value\n     * @property {number} Metadata=3 Metadata value\n     * @property {number} Symlink=4 Symlink value\n     * @property {number} HAMTShard=5 HAMTShard value\n     */\n    Data.DataType = (function() {\n        var valuesById = {}, values = Object.create(valuesById);\n        values[valuesById[0] = \"Raw\"] = 0;\n        values[valuesById[1] = \"Directory\"] = 1;\n        values[valuesById[2] = \"File\"] = 2;\n        values[valuesById[3] = \"Metadata\"] = 3;\n        values[valuesById[4] = \"Symlink\"] = 4;\n        values[valuesById[5] = \"HAMTShard\"] = 5;\n        return values;\n    })();\n\n    return Data;\n})();\n\n$root.UnixTime = (function() {\n\n    /**\n     * Properties of an UnixTime.\n     * @exports IUnixTime\n     * @interface IUnixTime\n     * @property {number} Seconds UnixTime Seconds\n     * @property {number|null} [FractionalNanoseconds] UnixTime FractionalNanoseconds\n     */\n\n    /**\n     * Constructs a new UnixTime.\n     * @exports UnixTime\n     * @classdesc Represents an UnixTime.\n     * @implements IUnixTime\n     * @constructor\n     * @param {IUnixTime=} [p] Properties to set\n     */\n    function UnixTime(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * UnixTime Seconds.\n     * @member {number} Seconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.Seconds = $util.Long ? $util.Long.fromBits(0,0,false) : 0;\n\n    /**\n     * UnixTime FractionalNanoseconds.\n     * @member {number} FractionalNanoseconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.FractionalNanoseconds = 0;\n\n    /**\n     * Encodes the specified UnixTime message. Does not implicitly {@link UnixTime.verify|verify} messages.\n     * @function encode\n     * @memberof UnixTime\n     * @static\n     * @param {IUnixTime} m UnixTime message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    UnixTime.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int64(m.Seconds);\n        if (m.FractionalNanoseconds != null && Object.hasOwnProperty.call(m, \"FractionalNanoseconds\"))\n            w.uint32(21).fixed32(m.FractionalNanoseconds);\n        return w;\n    };\n\n    /**\n     * Decodes an UnixTime message from the specified reader or buffer.\n     * @function decode\n     * @memberof UnixTime\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {UnixTime} UnixTime\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    UnixTime.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.UnixTime();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Seconds = r.int64();\n                break;\n            case 2:\n                m.FractionalNanoseconds = r.fixed32();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Seconds\"))\n            throw $util.ProtocolError(\"missing required 'Seconds'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates an UnixTime message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof UnixTime\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {UnixTime} UnixTime\n     */\n    UnixTime.fromObject = function fromObject(d) {\n        if (d instanceof $root.UnixTime)\n            return d;\n        var m = new $root.UnixTime();\n        if (d.Seconds != null) {\n            if ($util.Long)\n                (m.Seconds = $util.Long.fromValue(d.Seconds)).unsigned = false;\n            else if (typeof d.Seconds === \"string\")\n                m.Seconds = parseInt(d.Seconds, 10);\n            else if (typeof d.Seconds === \"number\")\n                m.Seconds = d.Seconds;\n            else if (typeof d.Seconds === \"object\")\n                m.Seconds = new $util.LongBits(d.Seconds.low >>> 0, d.Seconds.high >>> 0).toNumber();\n        }\n        if (d.FractionalNanoseconds != null) {\n            m.FractionalNanoseconds = d.FractionalNanoseconds >>> 0;\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from an UnixTime message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof UnixTime\n     * @static\n     * @param {UnixTime} m UnixTime\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    UnixTime.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, false);\n                d.Seconds = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.Seconds = o.longs === String ? \"0\" : 0;\n            d.FractionalNanoseconds = 0;\n        }\n        if (m.Seconds != null && m.hasOwnProperty(\"Seconds\")) {\n            if (typeof m.Seconds === \"number\")\n                d.Seconds = o.longs === String ? String(m.Seconds) : m.Seconds;\n            else\n                d.Seconds = o.longs === String ? $util.Long.prototype.toString.call(m.Seconds) : o.longs === Number ? new $util.LongBits(m.Seconds.low >>> 0, m.Seconds.high >>> 0).toNumber() : m.Seconds;\n        }\n        if (m.FractionalNanoseconds != null && m.hasOwnProperty(\"FractionalNanoseconds\")) {\n            d.FractionalNanoseconds = m.FractionalNanoseconds;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this UnixTime to JSON.\n     * @function toJSON\n     * @memberof UnixTime\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    UnixTime.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return UnixTime;\n})();\n\n$root.Metadata = (function() {\n\n    /**\n     * Properties of a Metadata.\n     * @exports IMetadata\n     * @interface IMetadata\n     * @property {string|null} [MimeType] Metadata MimeType\n     */\n\n    /**\n     * Constructs a new Metadata.\n     * @exports Metadata\n     * @classdesc Represents a Metadata.\n     * @implements IMetadata\n     * @constructor\n     * @param {IMetadata=} [p] Properties to set\n     */\n    function Metadata(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Metadata MimeType.\n     * @member {string} MimeType\n     * @memberof Metadata\n     * @instance\n     */\n    Metadata.prototype.MimeType = \"\";\n\n    /**\n     * Encodes the specified Metadata message. Does not implicitly {@link Metadata.verify|verify} messages.\n     * @function encode\n     * @memberof Metadata\n     * @static\n     * @param {IMetadata} m Metadata message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Metadata.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        if (m.MimeType != null && Object.hasOwnProperty.call(m, \"MimeType\"))\n            w.uint32(10).string(m.MimeType);\n        return w;\n    };\n\n    /**\n     * Decodes a Metadata message from the specified reader or buffer.\n     * @function decode\n     * @memberof Metadata\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Metadata} Metadata\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Metadata.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Metadata();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.MimeType = r.string();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        return m;\n    };\n\n    /**\n     * Creates a Metadata message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Metadata\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Metadata} Metadata\n     */\n    Metadata.fromObject = function fromObject(d) {\n        if (d instanceof $root.Metadata)\n            return d;\n        var m = new $root.Metadata();\n        if (d.MimeType != null) {\n            m.MimeType = String(d.MimeType);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Metadata message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Metadata\n     * @static\n     * @param {Metadata} m Metadata\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Metadata.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            d.MimeType = \"\";\n        }\n        if (m.MimeType != null && m.hasOwnProperty(\"MimeType\")) {\n            d.MimeType = m.MimeType;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Metadata to JSON.\n     * @function toJSON\n     * @memberof Metadata\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Metadata.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return Metadata;\n})();\n\nmodule.exports = $root;\n","'use strict'\n\nconst errCode = require('err-code')\nconst { CID } = require('multiformats/cid')\nconst resolve = require('./resolvers')\nconst last = require('it-last')\n\n/**\n * @typedef {import('ipfs-unixfs').UnixFS} UnixFS\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('./types').ExporterOptions} ExporterOptions\n * @typedef {import('./types').UnixFSFile} UnixFSFile\n * @typedef {import('./types').UnixFSDirectory} UnixFSDirectory\n * @typedef {import('./types').ObjectNode} ObjectNode\n * @typedef {import('./types').RawNode} RawNode\n * @typedef {import('./types').IdentityNode} IdentityNode\n * @typedef {import('./types').UnixFSEntry} UnixFSEntry\n */\n\nconst toPathComponents = (path = '') => {\n  // split on / unless escaped with \\\n  return (path\n    .trim()\n    .match(/([^\\\\^/]|\\\\\\/)+/g) || [])\n    .filter(Boolean)\n}\n\n/**\n * @param {string|Uint8Array|CID} path\n */\nconst cidAndRest = (path) => {\n  if (path instanceof Uint8Array) {\n    return {\n      cid: CID.decode(path),\n      toResolve: []\n    }\n  }\n\n  const cid = CID.asCID(path)\n  if (cid) {\n    return {\n      cid,\n      toResolve: []\n    }\n  }\n\n  if (typeof path === 'string') {\n    if (path.indexOf('/ipfs/') === 0) {\n      path = path.substring(6)\n    }\n\n    const output = toPathComponents(path)\n\n    return {\n      cid: CID.parse(output[0]),\n      toResolve: output.slice(1)\n    }\n  }\n\n  throw errCode(new Error(`Unknown path type ${path}`), 'ERR_BAD_PATH')\n}\n\n/**\n * @param {string | CID} path\n * @param {Blockstore} blockstore\n * @param {ExporterOptions} [options]\n */\nasync function * walkPath (path, blockstore, options = {}) {\n  let {\n    cid,\n    toResolve\n  } = cidAndRest(path)\n  let name = cid.toString()\n  let entryPath = name\n  const startingDepth = toResolve.length\n\n  while (true) {\n    const result = await resolve(cid, name, entryPath, toResolve, startingDepth, blockstore, options)\n\n    if (!result.entry && !result.next) {\n      throw errCode(new Error(`Could not resolve ${path}`), 'ERR_NOT_FOUND')\n    }\n\n    if (result.entry) {\n      yield result.entry\n    }\n\n    if (!result.next) {\n      return\n    }\n\n    // resolve further parts\n    toResolve = result.next.toResolve\n    cid = result.next.cid\n    name = result.next.name\n    entryPath = result.next.path\n  }\n}\n\n/**\n * @param {string | CID} path\n * @param {Blockstore} blockstore\n * @param {ExporterOptions} [options]\n */\nasync function exporter (path, blockstore, options = {}) {\n  const result = await last(walkPath(path, blockstore, options))\n\n  if (!result) {\n    throw errCode(new Error(`Could not resolve ${path}`), 'ERR_NOT_FOUND')\n  }\n\n  return result\n}\n\n/**\n * @param {string | CID} path\n * @param {Blockstore} blockstore\n * @param {ExporterOptions} [options]\n */\nasync function * recursive (path, blockstore, options = {}) {\n  const node = await exporter(path, blockstore, options)\n\n  if (!node) {\n    return\n  }\n\n  yield node\n\n  if (node.type === 'directory') {\n    for await (const child of recurse(node, options)) {\n      yield child\n    }\n  }\n\n  /**\n   * @param {UnixFSDirectory} node\n   * @param {ExporterOptions} options\n   * @returns {AsyncGenerator<UnixFSEntry, void, any>}\n   */\n  async function * recurse (node, options) {\n    for await (const file of node.content(options)) {\n      yield file\n\n      if (file instanceof Uint8Array) {\n        continue\n      }\n\n      if (file.type === 'directory') {\n        yield * recurse(file, options)\n      }\n    }\n  }\n}\n\nmodule.exports = {\n  exporter,\n  walkPath,\n  recursive\n}\n","'use strict'\n\nconst { CID } = require('multiformats/cid')\nconst errCode = require('err-code')\nconst dagCbor = require('@ipld/dag-cbor')\n\n/**\n * @typedef {import('../types').Resolver} Resolver\n */\n\n/**\n * @type {Resolver}\n */\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  const block = await blockstore.get(cid)\n  const object = dagCbor.decode(block)\n  let subObject = object\n  let subPath = path\n\n  while (toResolve.length) {\n    const prop = toResolve[0]\n\n    if (prop in subObject) {\n      // remove the bit of the path we have resolved\n      toResolve.shift()\n      subPath = `${subPath}/${prop}`\n\n      const subObjectCid = CID.asCID(subObject[prop])\n      if (subObjectCid) {\n        return {\n          entry: {\n            type: 'object',\n            name,\n            path,\n            cid,\n            node: block,\n            depth,\n            size: block.length,\n            content: async function * () {\n              yield object\n            }\n          },\n          next: {\n            cid: subObjectCid,\n            name: prop,\n            path: subPath,\n            toResolve\n          }\n        }\n      }\n\n      subObject = subObject[prop]\n    } else {\n      // cannot resolve further\n      throw errCode(new Error(`No property named ${prop} found in cbor node ${cid}`), 'ERR_NO_PROP')\n    }\n  }\n\n  return {\n    entry: {\n      type: 'object',\n      name,\n      path,\n      cid,\n      node: block,\n      depth,\n      size: block.length,\n      content: async function * () {\n        yield object\n      }\n    }\n  }\n}\n\nmodule.exports = resolve\n","'use strict'\n\nconst errCode = require('err-code')\nconst extractDataFromBlock = require('../utils/extract-data-from-block')\nconst validateOffsetAndLength = require('../utils/validate-offset-and-length')\nconst mh = require('multiformats/hashes/digest')\n\n/**\n * @typedef {import('../types').ExporterOptions} ExporterOptions\n * @typedef {import('../types').Resolver} Resolver\n */\n\n/**\n * @param {Uint8Array} node\n */\nconst rawContent = (node) => {\n  /**\n   * @param {ExporterOptions} options\n   */\n  async function * contentGenerator (options = {}) {\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(node.length, options.offset, options.length)\n\n    yield extractDataFromBlock(node, 0, offset, offset + length)\n  }\n\n  return contentGenerator\n}\n\n/**\n * @type {Resolver}\n */\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  if (toResolve.length) {\n    throw errCode(new Error(`No link named ${path} found in raw node ${cid}`), 'ERR_NOT_FOUND')\n  }\n  const buf = await mh.decode(cid.multihash.bytes)\n\n  return {\n    entry: {\n      type: 'identity',\n      name,\n      path,\n      cid,\n      content: rawContent(buf.digest),\n      depth,\n      size: buf.digest.length,\n      node: buf.digest\n    }\n  }\n}\n\nmodule.exports = resolve\n","'use strict'\n\nconst errCode = require('err-code')\n\nconst dagPb = require('@ipld/dag-pb')\nconst dagCbor = require('@ipld/dag-cbor')\nconst raw = require('multiformats/codecs/raw')\nconst { identity } = require('multiformats/hashes/identity')\n\n/**\n * @typedef {import('../types').Resolver} Resolver\n * @typedef {import('../types').Resolve} Resolve\n */\n\n/**\n * @type {{ [ key: string ]: Resolver }}\n */\nconst resolvers = {\n  [dagPb.code]: require('./unixfs-v1'),\n  [raw.code]: require('./raw'),\n  [dagCbor.code]: require('./dag-cbor'),\n  [identity.code]: require('./identity')\n}\n\n/**\n * @type {Resolve}\n */\nfunction resolve (cid, name, path, toResolve, depth, blockstore, options) {\n  const resolver = resolvers[cid.code]\n\n  if (!resolver) {\n    throw errCode(new Error(`No resolver for code ${cid.code}`), 'ERR_NO_RESOLVER')\n  }\n\n  return resolver(cid, name, path, toResolve, resolve, depth, blockstore, options)\n}\n\nmodule.exports = resolve\n","'use strict'\n\nconst errCode = require('err-code')\nconst extractDataFromBlock = require('../utils/extract-data-from-block')\nconst validateOffsetAndLength = require('../utils/validate-offset-and-length')\n\n/**\n * @typedef {import('../types').ExporterOptions} ExporterOptions\n */\n\n/**\n * @param {Uint8Array} node\n */\nconst rawContent = (node) => {\n  /**\n   * @param {ExporterOptions} options\n   */\n  async function * contentGenerator (options = {}) {\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(node.length, options.offset, options.length)\n\n    yield extractDataFromBlock(node, 0, offset, offset + length)\n  }\n\n  return contentGenerator\n}\n\n/**\n * @type {import('../types').Resolver}\n */\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  if (toResolve.length) {\n    throw errCode(new Error(`No link named ${path} found in raw node ${cid}`), 'ERR_NOT_FOUND')\n  }\n\n  const block = await blockstore.get(cid, options)\n\n  return {\n    entry: {\n      type: 'raw',\n      name,\n      path,\n      cid,\n      content: rawContent(block),\n      depth,\n      size: block.length,\n      node: block\n    }\n  }\n}\n\nmodule.exports = resolve\n","'use strict'\n\n/**\n * @typedef {import('../../../types').ExporterOptions} ExporterOptions\n * @typedef {import('../../../types').UnixfsV1DirectoryContent} UnixfsV1DirectoryContent\n * @typedef {import('../../../types').UnixfsV1Resolver} UnixfsV1Resolver\n */\n\n/**\n * @type {UnixfsV1Resolver}\n */\nconst directoryContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  /**\n   * @param {ExporterOptions} [options]\n   * @returns {UnixfsV1DirectoryContent}\n   */\n  async function * yieldDirectoryContent (options = {}) {\n    const offset = options.offset || 0\n    const length = options.length || node.Links.length\n    const links = node.Links.slice(offset, length)\n\n    for (const link of links) {\n      const result = await resolve(link.Hash, link.Name || '', `${path}/${link.Name || ''}`, [], depth + 1, blockstore, options)\n\n      if (result.entry) {\n        yield result.entry\n      }\n    }\n  }\n\n  return yieldDirectoryContent\n}\n\nmodule.exports = directoryContent\n","'use strict'\n\nconst extractDataFromBlock = require('../../../utils/extract-data-from-block')\nconst validateOffsetAndLength = require('../../../utils/validate-offset-and-length')\nconst { UnixFS } = require('ipfs-unixfs')\nconst errCode = require('err-code')\nconst dagPb = require('@ipld/dag-pb')\nconst dagCbor = require('@ipld/dag-cbor')\nconst raw = require('multiformats/codecs/raw')\n\n/**\n * @typedef {import('../../../types').ExporterOptions} ExporterOptions\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n *\n * @param {Blockstore} blockstore\n * @param {PBNode} node\n * @param {number} start\n * @param {number} end\n * @param {number} streamPosition\n * @param {ExporterOptions} options\n * @returns {AsyncIterable<Uint8Array>}\n */\nasync function * emitBytes (blockstore, node, start, end, streamPosition = 0, options) {\n  // a `raw` node\n  if (node instanceof Uint8Array) {\n    const buf = extractDataFromBlock(node, streamPosition, start, end)\n\n    if (buf.length) {\n      yield buf\n    }\n\n    streamPosition += buf.length\n\n    return streamPosition\n  }\n\n  if (node.Data == null) {\n    throw errCode(new Error('no data in PBNode'), 'ERR_NOT_UNIXFS')\n  }\n\n  let file\n\n  try {\n    file = UnixFS.unmarshal(node.Data)\n  } catch (err) {\n    throw errCode(err, 'ERR_NOT_UNIXFS')\n  }\n\n  // might be a unixfs `raw` node or have data on intermediate nodes\n  if (file.data && file.data.length) {\n    const buf = extractDataFromBlock(file.data, streamPosition, start, end)\n\n    if (buf.length) {\n      yield buf\n    }\n\n    streamPosition += file.data.length\n  }\n\n  let childStart = streamPosition\n\n  // work out which child nodes contain the requested data\n  for (let i = 0; i < node.Links.length; i++) {\n    const childLink = node.Links[i]\n    const childEnd = streamPosition + file.blockSizes[i]\n\n    if ((start >= childStart && start < childEnd) || // child has offset byte\n        (end > childStart && end <= childEnd) || // child has end byte\n        (start < childStart && end > childEnd)) { // child is between offset and end bytes\n      const block = await blockstore.get(childLink.Hash, {\n        signal: options.signal\n      })\n      let child\n      switch (childLink.Hash.code) {\n        case dagPb.code:\n          child = await dagPb.decode(block)\n          break\n        case raw.code:\n          child = block\n          break\n        case dagCbor.code:\n          child = await dagCbor.decode(block)\n          break\n        default:\n          throw Error(`Unsupported codec: ${childLink.Hash.code}`)\n      }\n\n      for await (const buf of emitBytes(blockstore, child, start, end, streamPosition, options)) {\n        streamPosition += buf.length\n\n        yield buf\n      }\n    }\n\n    streamPosition = childEnd\n    childStart = childEnd + 1\n  }\n}\n\n/**\n * @type {import('../').UnixfsV1Resolver}\n */\nconst fileContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  /**\n   * @param {ExporterOptions} options\n   */\n  function yieldFileContent (options = {}) {\n    const fileSize = unixfs.fileSize()\n\n    if (fileSize === undefined) {\n      throw new Error('File was a directory')\n    }\n\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length)\n\n    const start = offset\n    const end = offset + length\n\n    return emitBytes(blockstore, node, start, end, 0, options)\n  }\n\n  return yieldFileContent\n}\n\nmodule.exports = fileContent\n","'use strict'\n\nconst { decode } = require('@ipld/dag-pb')\n\n/**\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('../../../types').ExporterOptions} ExporterOptions\n * @typedef {import('../../../types').Resolve} Resolve\n * @typedef {import('../../../types').UnixfsV1DirectoryContent} UnixfsV1DirectoryContent\n * @typedef {import('../../../types').UnixfsV1Resolver} UnixfsV1Resolver\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n */\n\n/**\n * @type {UnixfsV1Resolver}\n */\nconst hamtShardedDirectoryContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  /**\n   * @param {ExporterOptions} options\n   *\n   */\n  function yieldHamtDirectoryContent (options = {}) {\n    return listDirectory(node, path, resolve, depth, blockstore, options)\n  }\n\n  return yieldHamtDirectoryContent\n}\n\n/**\n * @param {PBNode} node\n * @param {string} path\n * @param {Resolve} resolve\n * @param {number} depth\n * @param {Blockstore} blockstore\n * @param {ExporterOptions} options\n *\n * @returns {UnixfsV1DirectoryContent}\n */\nasync function * listDirectory (node, path, resolve, depth, blockstore, options) {\n  const links = node.Links\n\n  for (const link of links) {\n    const name = link.Name != null ? link.Name.substring(2) : null\n\n    if (name) {\n      const result = await resolve(link.Hash, name, `${path}/${name}`, [], depth + 1, blockstore, options)\n\n      yield result.entry\n    } else {\n      // descend into subshard\n      const block = await blockstore.get(link.Hash)\n      node = decode(block)\n\n      for await (const file of listDirectory(node, path, resolve, depth, blockstore, options)) {\n        yield file\n      }\n    }\n  }\n}\n\nmodule.exports = hamtShardedDirectoryContent\n","'use strict'\n\nconst errCode = require('err-code')\nconst { UnixFS } = require('ipfs-unixfs')\nconst findShardCid = require('../../utils/find-cid-in-shard')\nconst { decode } = require('@ipld/dag-pb')\n\n/**\n * @typedef {import('../../types').Resolve} Resolve\n * @typedef {import('../../types').Resolver} Resolver\n * @typedef {import('../../types').UnixfsV1Resolver} UnixfsV1Resolver\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n */\n\n/**\n * @param {PBNode} node\n * @param {string} name\n */\nconst findLinkCid = (node, name) => {\n  const link = node.Links.find(link => link.Name === name)\n\n  return link && link.Hash\n}\n\n/**\n * @type {{ [key: string]: UnixfsV1Resolver }}\n */\nconst contentExporters = {\n  raw: require('./content/file'),\n  file: require('./content/file'),\n  directory: require('./content/directory'),\n  'hamt-sharded-directory': require('./content/hamt-sharded-directory'),\n  metadata: (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    return () => []\n  },\n  symlink: (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    return () => []\n  }\n}\n\n/**\n * @type {Resolver}\n */\nconst unixFsResolver = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n  const block = await blockstore.get(cid, options)\n  const node = decode(block)\n  let unixfs\n  let next\n\n  if (!name) {\n    name = cid.toString()\n  }\n\n  if (node.Data == null) {\n    throw errCode(new Error('no data in PBNode'), 'ERR_NOT_UNIXFS')\n  }\n\n  try {\n    unixfs = UnixFS.unmarshal(node.Data)\n  } catch (err) {\n    // non-UnixFS dag-pb node? It could happen.\n    throw errCode(err, 'ERR_NOT_UNIXFS')\n  }\n\n  if (!path) {\n    path = name\n  }\n\n  if (toResolve.length) {\n    let linkCid\n\n    if (unixfs && unixfs.type === 'hamt-sharded-directory') {\n      // special case - unixfs v1 hamt shards\n      linkCid = await findShardCid(node, toResolve[0], blockstore)\n    } else {\n      linkCid = findLinkCid(node, toResolve[0])\n    }\n\n    if (!linkCid) {\n      throw errCode(new Error('file does not exist'), 'ERR_NOT_FOUND')\n    }\n\n    // remove the path component we have resolved\n    const nextName = toResolve.shift()\n    const nextPath = `${path}/${nextName}`\n\n    next = {\n      cid: linkCid,\n      toResolve,\n      name: nextName || '',\n      path: nextPath\n    }\n  }\n\n  return {\n    entry: {\n      type: unixfs.isDirectory() ? 'directory' : 'file',\n      name,\n      path,\n      cid,\n      // @ts-ignore\n      content: contentExporters[unixfs.type](cid, node, unixfs, path, resolve, depth, blockstore),\n      unixfs,\n      depth,\n      node,\n      size: unixfs.fileSize()\n    },\n    next\n  }\n}\n\nmodule.exports = unixFsResolver\n","'use strict'\n\n/**\n * @param {Uint8Array} block\n * @param {number} blockStart\n * @param {number} requestedStart\n * @param {number} requestedEnd\n */\nmodule.exports = function extractDataFromBlock (block, blockStart, requestedStart, requestedEnd) {\n  const blockLength = block.length\n  const blockEnd = blockStart + blockLength\n\n  if (requestedStart >= blockEnd || requestedEnd < blockStart) {\n    // If we are looking for a byte range that is starts after the start of the block,\n    // return an empty block.  This can happen when internal nodes contain data\n    return new Uint8Array(0)\n  }\n\n  if (requestedEnd >= blockStart && requestedEnd < blockEnd) {\n    // If the end byte is in the current block, truncate the block to the end byte\n    block = block.slice(0, requestedEnd - blockStart)\n  }\n\n  if (requestedStart >= blockStart && requestedStart < blockEnd) {\n    // If the start byte is in the current block, skip to the start byte\n    block = block.slice(requestedStart - blockStart)\n  }\n\n  return block\n}\n","'use strict'\n\nconst { Bucket, createHAMT } = require('hamt-sharding')\nconst { decode } = require('@ipld/dag-pb')\n// @ts-ignore - no types available\nconst mur = require('murmurhash3js-revisited')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n/**\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('multiformats/cid').CID} CID\n * @typedef {import('../types').ExporterOptions} ExporterOptions\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\n// FIXME: this is copy/pasted from ipfs-unixfs-importer/src/options.js\n/**\n * @param {Uint8Array} buf\n */\nconst hashFn = async function (buf) {\n  return uint8ArrayFromString(mur.x64.hash128(buf), 'base16').slice(0, 8).reverse()\n}\n\n/**\n * @param {PBLink[]} links\n * @param {Bucket<boolean>} bucket\n * @param {Bucket<boolean>} rootBucket\n */\nconst addLinksToHamtBucket = (links, bucket, rootBucket) => {\n  return Promise.all(\n    links.map(link => {\n      if (link.Name == null) {\n        // TODO(@rvagg): what do? this is technically possible\n        throw new Error('Unexpected Link without a Name')\n      }\n      if (link.Name.length === 2) {\n        const pos = parseInt(link.Name, 16)\n\n        return bucket._putObjectAt(pos, new Bucket({\n          hash: rootBucket._options.hash,\n          bits: rootBucket._options.bits\n        }, bucket, pos))\n      }\n\n      return rootBucket.put(link.Name.substring(2), true)\n    })\n  )\n}\n\n/**\n * @param {number} position\n */\nconst toPrefix = (position) => {\n  return position\n    .toString(16)\n    .toUpperCase()\n    .padStart(2, '0')\n    .substring(0, 2)\n}\n\n/**\n * @param {import('hamt-sharding').Bucket.BucketPosition<boolean>} position\n */\nconst toBucketPath = (position) => {\n  let bucket = position.bucket\n  const path = []\n\n  while (bucket._parent) {\n    path.push(bucket)\n\n    bucket = bucket._parent\n  }\n\n  path.push(bucket)\n\n  return path.reverse()\n}\n\n/**\n * @typedef {object} ShardTraversalContext\n * @property {number} hamtDepth\n * @property {Bucket<boolean>} rootBucket\n * @property {Bucket<boolean>} lastBucket\n *\n * @param {PBNode} node\n * @param {string} name\n * @param {Blockstore} blockstore\n * @param {ShardTraversalContext} [context]\n * @param {ExporterOptions} [options]\n * @returns {Promise<CID|null>}\n */\nconst findShardCid = async (node, name, blockstore, context, options) => {\n  if (!context) {\n    const rootBucket = createHAMT({\n      hashFn\n    })\n\n    context = {\n      rootBucket,\n      hamtDepth: 1,\n      lastBucket: rootBucket\n    }\n  }\n\n  await addLinksToHamtBucket(node.Links, context.lastBucket, context.rootBucket)\n\n  const position = await context.rootBucket._findNewBucketAndPos(name)\n  let prefix = toPrefix(position.pos)\n  const bucketPath = toBucketPath(position)\n\n  if (bucketPath.length > context.hamtDepth) {\n    context.lastBucket = bucketPath[context.hamtDepth]\n\n    prefix = toPrefix(context.lastBucket._posAtParent)\n  }\n\n  const link = node.Links.find(link => {\n    if (link.Name == null) {\n      return false\n    }\n\n    const entryPrefix = link.Name.substring(0, 2)\n    const entryName = link.Name.substring(2)\n\n    if (entryPrefix !== prefix) {\n      // not the entry or subshard we're looking for\n      return false\n    }\n\n    if (entryName && entryName !== name) {\n      // not the entry we're looking for\n      return false\n    }\n\n    return true\n  })\n\n  if (!link) {\n    return null\n  }\n\n  if (link.Name != null && link.Name.substring(2) === name) {\n    return link.Hash\n  }\n\n  context.hamtDepth++\n\n  const block = await blockstore.get(link.Hash, options)\n  node = decode(block)\n\n  return findShardCid(node, name, blockstore, context, options)\n}\n\nmodule.exports = findShardCid\n","'use strict'\n\nconst errCode = require('err-code')\n\n/**\n * @param {number} size\n * @param {number} [offset]\n * @param {number} [length]\n */\nconst validateOffsetAndLength = (size, offset, length) => {\n  if (!offset) {\n    offset = 0\n  }\n\n  if (offset < 0) {\n    throw errCode(new Error('Offset must be greater than or equal to 0'), 'ERR_INVALID_PARAMS')\n  }\n\n  if (offset > size) {\n    throw errCode(new Error('Offset must be less than the file size'), 'ERR_INVALID_PARAMS')\n  }\n\n  if (!length && length !== 0) {\n    length = size - offset\n  }\n\n  if (length < 0) {\n    throw errCode(new Error('Length must be greater than or equal to 0'), 'ERR_INVALID_PARAMS')\n  }\n\n  if (offset + length > size) {\n    length = size - offset\n  }\n\n  return {\n    offset,\n    length\n  }\n}\n\nmodule.exports = validateOffsetAndLength\n","'use strict'\n\nconst { Buffer } = require('buffer')\nconst symbol = Symbol.for('BufferList')\n\nfunction BufferList (buf) {\n  if (!(this instanceof BufferList)) {\n    return new BufferList(buf)\n  }\n\n  BufferList._init.call(this, buf)\n}\n\nBufferList._init = function _init (buf) {\n  Object.defineProperty(this, symbol, { value: true })\n\n  this._bufs = []\n  this.length = 0\n\n  if (buf) {\n    this.append(buf)\n  }\n}\n\nBufferList.prototype._new = function _new (buf) {\n  return new BufferList(buf)\n}\n\nBufferList.prototype._offset = function _offset (offset) {\n  if (offset === 0) {\n    return [0, 0]\n  }\n\n  let tot = 0\n\n  for (let i = 0; i < this._bufs.length; i++) {\n    const _t = tot + this._bufs[i].length\n    if (offset < _t || i === this._bufs.length - 1) {\n      return [i, offset - tot]\n    }\n    tot = _t\n  }\n}\n\nBufferList.prototype._reverseOffset = function (blOffset) {\n  const bufferId = blOffset[0]\n  let offset = blOffset[1]\n\n  for (let i = 0; i < bufferId; i++) {\n    offset += this._bufs[i].length\n  }\n\n  return offset\n}\n\nBufferList.prototype.get = function get (index) {\n  if (index > this.length || index < 0) {\n    return undefined\n  }\n\n  const offset = this._offset(index)\n\n  return this._bufs[offset[0]][offset[1]]\n}\n\nBufferList.prototype.slice = function slice (start, end) {\n  if (typeof start === 'number' && start < 0) {\n    start += this.length\n  }\n\n  if (typeof end === 'number' && end < 0) {\n    end += this.length\n  }\n\n  return this.copy(null, 0, start, end)\n}\n\nBufferList.prototype.copy = function copy (dst, dstStart, srcStart, srcEnd) {\n  if (typeof srcStart !== 'number' || srcStart < 0) {\n    srcStart = 0\n  }\n\n  if (typeof srcEnd !== 'number' || srcEnd > this.length) {\n    srcEnd = this.length\n  }\n\n  if (srcStart >= this.length) {\n    return dst || Buffer.alloc(0)\n  }\n\n  if (srcEnd <= 0) {\n    return dst || Buffer.alloc(0)\n  }\n\n  const copy = !!dst\n  const off = this._offset(srcStart)\n  const len = srcEnd - srcStart\n  let bytes = len\n  let bufoff = (copy && dstStart) || 0\n  let start = off[1]\n\n  // copy/slice everything\n  if (srcStart === 0 && srcEnd === this.length) {\n    if (!copy) {\n      // slice, but full concat if multiple buffers\n      return this._bufs.length === 1\n        ? this._bufs[0]\n        : Buffer.concat(this._bufs, this.length)\n    }\n\n    // copy, need to copy individual buffers\n    for (let i = 0; i < this._bufs.length; i++) {\n      this._bufs[i].copy(dst, bufoff)\n      bufoff += this._bufs[i].length\n    }\n\n    return dst\n  }\n\n  // easy, cheap case where it's a subset of one of the buffers\n  if (bytes <= this._bufs[off[0]].length - start) {\n    return copy\n      ? this._bufs[off[0]].copy(dst, dstStart, start, start + bytes)\n      : this._bufs[off[0]].slice(start, start + bytes)\n  }\n\n  if (!copy) {\n    // a slice, we need something to copy in to\n    dst = Buffer.allocUnsafe(len)\n  }\n\n  for (let i = off[0]; i < this._bufs.length; i++) {\n    const l = this._bufs[i].length - start\n\n    if (bytes > l) {\n      this._bufs[i].copy(dst, bufoff, start)\n      bufoff += l\n    } else {\n      this._bufs[i].copy(dst, bufoff, start, start + bytes)\n      bufoff += l\n      break\n    }\n\n    bytes -= l\n\n    if (start) {\n      start = 0\n    }\n  }\n\n  // safeguard so that we don't return uninitialized memory\n  if (dst.length > bufoff) return dst.slice(0, bufoff)\n\n  return dst\n}\n\nBufferList.prototype.shallowSlice = function shallowSlice (start, end) {\n  start = start || 0\n  end = typeof end !== 'number' ? this.length : end\n\n  if (start < 0) {\n    start += this.length\n  }\n\n  if (end < 0) {\n    end += this.length\n  }\n\n  if (start === end) {\n    return this._new()\n  }\n\n  const startOffset = this._offset(start)\n  const endOffset = this._offset(end)\n  const buffers = this._bufs.slice(startOffset[0], endOffset[0] + 1)\n\n  if (endOffset[1] === 0) {\n    buffers.pop()\n  } else {\n    buffers[buffers.length - 1] = buffers[buffers.length - 1].slice(0, endOffset[1])\n  }\n\n  if (startOffset[1] !== 0) {\n    buffers[0] = buffers[0].slice(startOffset[1])\n  }\n\n  return this._new(buffers)\n}\n\nBufferList.prototype.toString = function toString (encoding, start, end) {\n  return this.slice(start, end).toString(encoding)\n}\n\nBufferList.prototype.consume = function consume (bytes) {\n  // first, normalize the argument, in accordance with how Buffer does it\n  bytes = Math.trunc(bytes)\n  // do nothing if not a positive number\n  if (Number.isNaN(bytes) || bytes <= 0) return this\n\n  while (this._bufs.length) {\n    if (bytes >= this._bufs[0].length) {\n      bytes -= this._bufs[0].length\n      this.length -= this._bufs[0].length\n      this._bufs.shift()\n    } else {\n      this._bufs[0] = this._bufs[0].slice(bytes)\n      this.length -= bytes\n      break\n    }\n  }\n\n  return this\n}\n\nBufferList.prototype.duplicate = function duplicate () {\n  const copy = this._new()\n\n  for (let i = 0; i < this._bufs.length; i++) {\n    copy.append(this._bufs[i])\n  }\n\n  return copy\n}\n\nBufferList.prototype.append = function append (buf) {\n  if (buf == null) {\n    return this\n  }\n\n  if (buf.buffer) {\n    // append a view of the underlying ArrayBuffer\n    this._appendBuffer(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength))\n  } else if (Array.isArray(buf)) {\n    for (let i = 0; i < buf.length; i++) {\n      this.append(buf[i])\n    }\n  } else if (this._isBufferList(buf)) {\n    // unwrap argument into individual BufferLists\n    for (let i = 0; i < buf._bufs.length; i++) {\n      this.append(buf._bufs[i])\n    }\n  } else {\n    // coerce number arguments to strings, since Buffer(number) does\n    // uninitialized memory allocation\n    if (typeof buf === 'number') {\n      buf = buf.toString()\n    }\n\n    this._appendBuffer(Buffer.from(buf))\n  }\n\n  return this\n}\n\nBufferList.prototype._appendBuffer = function appendBuffer (buf) {\n  this._bufs.push(buf)\n  this.length += buf.length\n}\n\nBufferList.prototype.indexOf = function (search, offset, encoding) {\n  if (encoding === undefined && typeof offset === 'string') {\n    encoding = offset\n    offset = undefined\n  }\n\n  if (typeof search === 'function' || Array.isArray(search)) {\n    throw new TypeError('The \"value\" argument must be one of type string, Buffer, BufferList, or Uint8Array.')\n  } else if (typeof search === 'number') {\n    search = Buffer.from([search])\n  } else if (typeof search === 'string') {\n    search = Buffer.from(search, encoding)\n  } else if (this._isBufferList(search)) {\n    search = search.slice()\n  } else if (Array.isArray(search.buffer)) {\n    search = Buffer.from(search.buffer, search.byteOffset, search.byteLength)\n  } else if (!Buffer.isBuffer(search)) {\n    search = Buffer.from(search)\n  }\n\n  offset = Number(offset || 0)\n\n  if (isNaN(offset)) {\n    offset = 0\n  }\n\n  if (offset < 0) {\n    offset = this.length + offset\n  }\n\n  if (offset < 0) {\n    offset = 0\n  }\n\n  if (search.length === 0) {\n    return offset > this.length ? this.length : offset\n  }\n\n  const blOffset = this._offset(offset)\n  let blIndex = blOffset[0] // index of which internal buffer we're working on\n  let buffOffset = blOffset[1] // offset of the internal buffer we're working on\n\n  // scan over each buffer\n  for (; blIndex < this._bufs.length; blIndex++) {\n    const buff = this._bufs[blIndex]\n\n    while (buffOffset < buff.length) {\n      const availableWindow = buff.length - buffOffset\n\n      if (availableWindow >= search.length) {\n        const nativeSearchResult = buff.indexOf(search, buffOffset)\n\n        if (nativeSearchResult !== -1) {\n          return this._reverseOffset([blIndex, nativeSearchResult])\n        }\n\n        buffOffset = buff.length - search.length + 1 // end of native search window\n      } else {\n        const revOffset = this._reverseOffset([blIndex, buffOffset])\n\n        if (this._match(revOffset, search)) {\n          return revOffset\n        }\n\n        buffOffset++\n      }\n    }\n\n    buffOffset = 0\n  }\n\n  return -1\n}\n\nBufferList.prototype._match = function (offset, search) {\n  if (this.length - offset < search.length) {\n    return false\n  }\n\n  for (let searchOffset = 0; searchOffset < search.length; searchOffset++) {\n    if (this.get(offset + searchOffset) !== search[searchOffset]) {\n      return false\n    }\n  }\n  return true\n}\n\n;(function () {\n  const methods = {\n    readDoubleBE: 8,\n    readDoubleLE: 8,\n    readFloatBE: 4,\n    readFloatLE: 4,\n    readInt32BE: 4,\n    readInt32LE: 4,\n    readUInt32BE: 4,\n    readUInt32LE: 4,\n    readInt16BE: 2,\n    readInt16LE: 2,\n    readUInt16BE: 2,\n    readUInt16LE: 2,\n    readInt8: 1,\n    readUInt8: 1,\n    readIntBE: null,\n    readIntLE: null,\n    readUIntBE: null,\n    readUIntLE: null\n  }\n\n  for (const m in methods) {\n    (function (m) {\n      if (methods[m] === null) {\n        BufferList.prototype[m] = function (offset, byteLength) {\n          return this.slice(offset, offset + byteLength)[m](0, byteLength)\n        }\n      } else {\n        BufferList.prototype[m] = function (offset = 0) {\n          return this.slice(offset, offset + methods[m])[m](0)\n        }\n      }\n    }(m))\n  }\n}())\n\n// Used internally by the class and also as an indicator of this object being\n// a `BufferList`. It's not possible to use `instanceof BufferList` in a browser\n// environment because there could be multiple different copies of the\n// BufferList class and some `BufferList`s might be `BufferList`s.\nBufferList.prototype._isBufferList = function _isBufferList (b) {\n  return b instanceof BufferList || BufferList.isBufferList(b)\n}\n\nBufferList.isBufferList = function isBufferList (b) {\n  return b != null && b[symbol]\n}\n\nmodule.exports = BufferList\n","'use strict'\n\nconst {\n  Data: PBData\n} = require('./unixfs')\nconst errcode = require('err-code')\n\n/**\n * @typedef {import('./types').Mtime} Mtime\n * @typedef {import('./types').MtimeLike} MtimeLike\n */\n\nconst types = [\n  'raw',\n  'directory',\n  'file',\n  'metadata',\n  'symlink',\n  'hamt-sharded-directory'\n]\n\nconst dirTypes = [\n  'directory',\n  'hamt-sharded-directory'\n]\n\nconst DEFAULT_FILE_MODE = parseInt('0644', 8)\nconst DEFAULT_DIRECTORY_MODE = parseInt('0755', 8)\n\n/**\n * @param {string | number | undefined} [mode]\n */\nfunction parseMode (mode) {\n  if (mode == null) {\n    return undefined\n  }\n\n  if (typeof mode === 'number') {\n    return mode & 0xFFF\n  }\n\n  mode = mode.toString()\n\n  if (mode.substring(0, 1) === '0') {\n    // octal string\n    return parseInt(mode, 8) & 0xFFF\n  }\n\n  // decimal string\n  return parseInt(mode, 10) & 0xFFF\n}\n\n/**\n * @param {any} input\n */\nfunction parseMtime (input) {\n  if (input == null) {\n    return undefined\n  }\n\n  /** @type {Mtime | undefined} */\n  let mtime\n\n  // { secs, nsecs }\n  if (input.secs != null) {\n    mtime = {\n      secs: input.secs,\n      nsecs: input.nsecs\n    }\n  }\n\n  // UnixFS TimeSpec\n  if (input.Seconds != null) {\n    mtime = {\n      secs: input.Seconds,\n      nsecs: input.FractionalNanoseconds\n    }\n  }\n\n  // process.hrtime()\n  if (Array.isArray(input)) {\n    mtime = {\n      secs: input[0],\n      nsecs: input[1]\n    }\n  }\n\n  // Javascript Date\n  if (input instanceof Date) {\n    const ms = input.getTime()\n    const secs = Math.floor(ms / 1000)\n\n    mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n  }\n\n  /*\n  TODO: https://github.com/ipfs/aegir/issues/487\n\n  // process.hrtime.bigint()\n  if (input instanceof BigInt) {\n    const secs = input / BigInt(1e9)\n    const nsecs = input - (secs * BigInt(1e9))\n\n    mtime = {\n      secs: parseInt(secs.toString()),\n      nsecs: parseInt(nsecs.toString())\n    }\n  }\n  */\n\n  if (!Object.prototype.hasOwnProperty.call(mtime, 'secs')) {\n    return undefined\n  }\n\n  if (mtime != null && mtime.nsecs != null && (mtime.nsecs < 0 || mtime.nsecs > 999999999)) {\n    throw errcode(new Error('mtime-nsecs must be within the range [0,999999999]'), 'ERR_INVALID_MTIME_NSECS')\n  }\n\n  return mtime\n}\n\nclass Data {\n  /**\n   * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md\n   *\n   * @param {Uint8Array} marshaled\n   */\n  static unmarshal (marshaled) {\n    const message = PBData.decode(marshaled)\n    const decoded = PBData.toObject(message, {\n      defaults: false,\n      arrays: true,\n      longs: Number,\n      objects: false\n    })\n\n    const data = new Data({\n      type: types[decoded.Type],\n      data: decoded.Data,\n      blockSizes: decoded.blocksizes,\n      mode: decoded.mode,\n      mtime: decoded.mtime\n        ? {\n            secs: decoded.mtime.Seconds,\n            nsecs: decoded.mtime.FractionalNanoseconds\n          }\n        : undefined\n    })\n\n    // make sure we honour the original mode\n    data._originalMode = decoded.mode || 0\n\n    return data\n  }\n\n  /**\n   * @param {object} [options]\n   * @param {string} [options.type='file']\n   * @param {Uint8Array} [options.data]\n   * @param {number[]} [options.blockSizes]\n   * @param {number} [options.hashType]\n   * @param {number} [options.fanout]\n   * @param {MtimeLike | null} [options.mtime]\n   * @param {number | string} [options.mode]\n   */\n  constructor (options = {\n    type: 'file'\n  }) {\n    const {\n      type,\n      data,\n      blockSizes,\n      hashType,\n      fanout,\n      mtime,\n      mode\n    } = options\n\n    if (type && !types.includes(type)) {\n      throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    this.type = type || 'file'\n    this.data = data\n    this.hashType = hashType\n    this.fanout = fanout\n\n    /** @type {number[]} */\n    this.blockSizes = blockSizes || []\n    this._originalMode = 0\n    this.mode = parseMode(mode)\n\n    if (mtime) {\n      this.mtime = parseMtime(mtime)\n\n      if (this.mtime && !this.mtime.nsecs) {\n        this.mtime.nsecs = 0\n      }\n    }\n  }\n\n  /**\n   * @param {number | undefined} mode\n   */\n  set mode (mode) {\n    this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE\n\n    const parsedMode = parseMode(mode)\n\n    if (parsedMode !== undefined) {\n      this._mode = parsedMode\n    }\n  }\n\n  /**\n   * @returns {number | undefined}\n   */\n  get mode () {\n    return this._mode\n  }\n\n  isDirectory () {\n    return Boolean(this.type && dirTypes.includes(this.type))\n  }\n\n  /**\n   * @param {number} size\n   */\n  addBlockSize (size) {\n    this.blockSizes.push(size)\n  }\n\n  /**\n   * @param {number} index\n   */\n  removeBlockSize (index) {\n    this.blockSizes.splice(index, 1)\n  }\n\n  /**\n   * Returns `0` for directories or `data.length + sum(blockSizes)` for everything else\n   */\n  fileSize () {\n    if (this.isDirectory()) {\n      // dirs don't have file size\n      return 0\n    }\n\n    let sum = 0\n    this.blockSizes.forEach((size) => {\n      sum += size\n    })\n\n    if (this.data) {\n      sum += this.data.length\n    }\n\n    return sum\n  }\n\n  /**\n   * encode to protobuf Uint8Array\n   */\n  marshal () {\n    let type\n\n    switch (this.type) {\n      case 'raw': type = PBData.DataType.Raw; break\n      case 'directory': type = PBData.DataType.Directory; break\n      case 'file': type = PBData.DataType.File; break\n      case 'metadata': type = PBData.DataType.Metadata; break\n      case 'symlink': type = PBData.DataType.Symlink; break\n      case 'hamt-sharded-directory': type = PBData.DataType.HAMTShard; break\n      default:\n        throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    let data = this.data\n\n    if (!this.data || !this.data.length) {\n      data = undefined\n    }\n\n    let mode\n\n    if (this.mode != null) {\n      mode = (this._originalMode & 0xFFFFF000) | (parseMode(this.mode) || 0)\n\n      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {\n        mode = undefined\n      }\n\n      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {\n        mode = undefined\n      }\n    }\n\n    let mtime\n\n    if (this.mtime != null) {\n      const parsed = parseMtime(this.mtime)\n\n      if (parsed) {\n        mtime = {\n          Seconds: parsed.secs,\n          FractionalNanoseconds: parsed.nsecs\n        }\n\n        if (mtime.FractionalNanoseconds === 0) {\n          delete mtime.FractionalNanoseconds\n        }\n      }\n    }\n\n    const pbData = {\n      Type: type,\n      Data: data,\n      filesize: this.isDirectory() ? undefined : this.fileSize(),\n      blocksizes: this.blockSizes,\n      hashType: this.hashType,\n      fanout: this.fanout,\n      mode,\n      mtime\n    }\n\n    return PBData.encode(pbData).finish()\n  }\n}\n\nmodule.exports = {\n  UnixFS: Data,\n  parseMode,\n  parseMtime\n}\n","/*eslint-disable*/\n\"use strict\";\n\nvar $protobuf = require(\"protobufjs/minimal\");\n\n// Common aliases\nvar $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;\n\n// Exported root namespace\nvar $root = $protobuf.roots[\"ipfs-unixfs\"] || ($protobuf.roots[\"ipfs-unixfs\"] = {});\n\n$root.Data = (function() {\n\n    /**\n     * Properties of a Data.\n     * @exports IData\n     * @interface IData\n     * @property {Data.DataType} Type Data Type\n     * @property {Uint8Array|null} [Data] Data Data\n     * @property {number|null} [filesize] Data filesize\n     * @property {Array.<number>|null} [blocksizes] Data blocksizes\n     * @property {number|null} [hashType] Data hashType\n     * @property {number|null} [fanout] Data fanout\n     * @property {number|null} [mode] Data mode\n     * @property {IUnixTime|null} [mtime] Data mtime\n     */\n\n    /**\n     * Constructs a new Data.\n     * @exports Data\n     * @classdesc Represents a Data.\n     * @implements IData\n     * @constructor\n     * @param {IData=} [p] Properties to set\n     */\n    function Data(p) {\n        this.blocksizes = [];\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Data Type.\n     * @member {Data.DataType} Type\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Type = 0;\n\n    /**\n     * Data Data.\n     * @member {Uint8Array} Data\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Data = $util.newBuffer([]);\n\n    /**\n     * Data filesize.\n     * @member {number} filesize\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.filesize = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data blocksizes.\n     * @member {Array.<number>} blocksizes\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.blocksizes = $util.emptyArray;\n\n    /**\n     * Data hashType.\n     * @member {number} hashType\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.hashType = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data fanout.\n     * @member {number} fanout\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.fanout = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data mode.\n     * @member {number} mode\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mode = 0;\n\n    /**\n     * Data mtime.\n     * @member {IUnixTime|null|undefined} mtime\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mtime = null;\n\n    /**\n     * Encodes the specified Data message. Does not implicitly {@link Data.verify|verify} messages.\n     * @function encode\n     * @memberof Data\n     * @static\n     * @param {IData} m Data message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Data.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int32(m.Type);\n        if (m.Data != null && Object.hasOwnProperty.call(m, \"Data\"))\n            w.uint32(18).bytes(m.Data);\n        if (m.filesize != null && Object.hasOwnProperty.call(m, \"filesize\"))\n            w.uint32(24).uint64(m.filesize);\n        if (m.blocksizes != null && m.blocksizes.length) {\n            for (var i = 0; i < m.blocksizes.length; ++i)\n                w.uint32(32).uint64(m.blocksizes[i]);\n        }\n        if (m.hashType != null && Object.hasOwnProperty.call(m, \"hashType\"))\n            w.uint32(40).uint64(m.hashType);\n        if (m.fanout != null && Object.hasOwnProperty.call(m, \"fanout\"))\n            w.uint32(48).uint64(m.fanout);\n        if (m.mode != null && Object.hasOwnProperty.call(m, \"mode\"))\n            w.uint32(56).uint32(m.mode);\n        if (m.mtime != null && Object.hasOwnProperty.call(m, \"mtime\"))\n            $root.UnixTime.encode(m.mtime, w.uint32(66).fork()).ldelim();\n        return w;\n    };\n\n    /**\n     * Decodes a Data message from the specified reader or buffer.\n     * @function decode\n     * @memberof Data\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Data} Data\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Data.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Data();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Type = r.int32();\n                break;\n            case 2:\n                m.Data = r.bytes();\n                break;\n            case 3:\n                m.filesize = r.uint64();\n                break;\n            case 4:\n                if (!(m.blocksizes && m.blocksizes.length))\n                    m.blocksizes = [];\n                if ((t & 7) === 2) {\n                    var c2 = r.uint32() + r.pos;\n                    while (r.pos < c2)\n                        m.blocksizes.push(r.uint64());\n                } else\n                    m.blocksizes.push(r.uint64());\n                break;\n            case 5:\n                m.hashType = r.uint64();\n                break;\n            case 6:\n                m.fanout = r.uint64();\n                break;\n            case 7:\n                m.mode = r.uint32();\n                break;\n            case 8:\n                m.mtime = $root.UnixTime.decode(r, r.uint32());\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Type\"))\n            throw $util.ProtocolError(\"missing required 'Type'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates a Data message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Data\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Data} Data\n     */\n    Data.fromObject = function fromObject(d) {\n        if (d instanceof $root.Data)\n            return d;\n        var m = new $root.Data();\n        switch (d.Type) {\n        case \"Raw\":\n        case 0:\n            m.Type = 0;\n            break;\n        case \"Directory\":\n        case 1:\n            m.Type = 1;\n            break;\n        case \"File\":\n        case 2:\n            m.Type = 2;\n            break;\n        case \"Metadata\":\n        case 3:\n            m.Type = 3;\n            break;\n        case \"Symlink\":\n        case 4:\n            m.Type = 4;\n            break;\n        case \"HAMTShard\":\n        case 5:\n            m.Type = 5;\n            break;\n        }\n        if (d.Data != null) {\n            if (typeof d.Data === \"string\")\n                $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);\n            else if (d.Data.length)\n                m.Data = d.Data;\n        }\n        if (d.filesize != null) {\n            if ($util.Long)\n                (m.filesize = $util.Long.fromValue(d.filesize)).unsigned = true;\n            else if (typeof d.filesize === \"string\")\n                m.filesize = parseInt(d.filesize, 10);\n            else if (typeof d.filesize === \"number\")\n                m.filesize = d.filesize;\n            else if (typeof d.filesize === \"object\")\n                m.filesize = new $util.LongBits(d.filesize.low >>> 0, d.filesize.high >>> 0).toNumber(true);\n        }\n        if (d.blocksizes) {\n            if (!Array.isArray(d.blocksizes))\n                throw TypeError(\".Data.blocksizes: array expected\");\n            m.blocksizes = [];\n            for (var i = 0; i < d.blocksizes.length; ++i) {\n                if ($util.Long)\n                    (m.blocksizes[i] = $util.Long.fromValue(d.blocksizes[i])).unsigned = true;\n                else if (typeof d.blocksizes[i] === \"string\")\n                    m.blocksizes[i] = parseInt(d.blocksizes[i], 10);\n                else if (typeof d.blocksizes[i] === \"number\")\n                    m.blocksizes[i] = d.blocksizes[i];\n                else if (typeof d.blocksizes[i] === \"object\")\n                    m.blocksizes[i] = new $util.LongBits(d.blocksizes[i].low >>> 0, d.blocksizes[i].high >>> 0).toNumber(true);\n            }\n        }\n        if (d.hashType != null) {\n            if ($util.Long)\n                (m.hashType = $util.Long.fromValue(d.hashType)).unsigned = true;\n            else if (typeof d.hashType === \"string\")\n                m.hashType = parseInt(d.hashType, 10);\n            else if (typeof d.hashType === \"number\")\n                m.hashType = d.hashType;\n            else if (typeof d.hashType === \"object\")\n                m.hashType = new $util.LongBits(d.hashType.low >>> 0, d.hashType.high >>> 0).toNumber(true);\n        }\n        if (d.fanout != null) {\n            if ($util.Long)\n                (m.fanout = $util.Long.fromValue(d.fanout)).unsigned = true;\n            else if (typeof d.fanout === \"string\")\n                m.fanout = parseInt(d.fanout, 10);\n            else if (typeof d.fanout === \"number\")\n                m.fanout = d.fanout;\n            else if (typeof d.fanout === \"object\")\n                m.fanout = new $util.LongBits(d.fanout.low >>> 0, d.fanout.high >>> 0).toNumber(true);\n        }\n        if (d.mode != null) {\n            m.mode = d.mode >>> 0;\n        }\n        if (d.mtime != null) {\n            if (typeof d.mtime !== \"object\")\n                throw TypeError(\".Data.mtime: object expected\");\n            m.mtime = $root.UnixTime.fromObject(d.mtime);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Data message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Data\n     * @static\n     * @param {Data} m Data\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Data.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.arrays || o.defaults) {\n            d.blocksizes = [];\n        }\n        if (o.defaults) {\n            d.Type = o.enums === String ? \"Raw\" : 0;\n            if (o.bytes === String)\n                d.Data = \"\";\n            else {\n                d.Data = [];\n                if (o.bytes !== Array)\n                    d.Data = $util.newBuffer(d.Data);\n            }\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.filesize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.filesize = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.hashType = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.hashType = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.fanout = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.fanout = o.longs === String ? \"0\" : 0;\n            d.mode = 0;\n            d.mtime = null;\n        }\n        if (m.Type != null && m.hasOwnProperty(\"Type\")) {\n            d.Type = o.enums === String ? $root.Data.DataType[m.Type] : m.Type;\n        }\n        if (m.Data != null && m.hasOwnProperty(\"Data\")) {\n            d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;\n        }\n        if (m.filesize != null && m.hasOwnProperty(\"filesize\")) {\n            if (typeof m.filesize === \"number\")\n                d.filesize = o.longs === String ? String(m.filesize) : m.filesize;\n            else\n                d.filesize = o.longs === String ? $util.Long.prototype.toString.call(m.filesize) : o.longs === Number ? new $util.LongBits(m.filesize.low >>> 0, m.filesize.high >>> 0).toNumber(true) : m.filesize;\n        }\n        if (m.blocksizes && m.blocksizes.length) {\n            d.blocksizes = [];\n            for (var j = 0; j < m.blocksizes.length; ++j) {\n                if (typeof m.blocksizes[j] === \"number\")\n                    d.blocksizes[j] = o.longs === String ? String(m.blocksizes[j]) : m.blocksizes[j];\n                else\n                    d.blocksizes[j] = o.longs === String ? $util.Long.prototype.toString.call(m.blocksizes[j]) : o.longs === Number ? new $util.LongBits(m.blocksizes[j].low >>> 0, m.blocksizes[j].high >>> 0).toNumber(true) : m.blocksizes[j];\n            }\n        }\n        if (m.hashType != null && m.hasOwnProperty(\"hashType\")) {\n            if (typeof m.hashType === \"number\")\n                d.hashType = o.longs === String ? String(m.hashType) : m.hashType;\n            else\n                d.hashType = o.longs === String ? $util.Long.prototype.toString.call(m.hashType) : o.longs === Number ? new $util.LongBits(m.hashType.low >>> 0, m.hashType.high >>> 0).toNumber(true) : m.hashType;\n        }\n        if (m.fanout != null && m.hasOwnProperty(\"fanout\")) {\n            if (typeof m.fanout === \"number\")\n                d.fanout = o.longs === String ? String(m.fanout) : m.fanout;\n            else\n                d.fanout = o.longs === String ? $util.Long.prototype.toString.call(m.fanout) : o.longs === Number ? new $util.LongBits(m.fanout.low >>> 0, m.fanout.high >>> 0).toNumber(true) : m.fanout;\n        }\n        if (m.mode != null && m.hasOwnProperty(\"mode\")) {\n            d.mode = m.mode;\n        }\n        if (m.mtime != null && m.hasOwnProperty(\"mtime\")) {\n            d.mtime = $root.UnixTime.toObject(m.mtime, o);\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Data to JSON.\n     * @function toJSON\n     * @memberof Data\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Data.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    /**\n     * DataType enum.\n     * @name Data.DataType\n     * @enum {number}\n     * @property {number} Raw=0 Raw value\n     * @property {number} Directory=1 Directory value\n     * @property {number} File=2 File value\n     * @property {number} Metadata=3 Metadata value\n     * @property {number} Symlink=4 Symlink value\n     * @property {number} HAMTShard=5 HAMTShard value\n     */\n    Data.DataType = (function() {\n        var valuesById = {}, values = Object.create(valuesById);\n        values[valuesById[0] = \"Raw\"] = 0;\n        values[valuesById[1] = \"Directory\"] = 1;\n        values[valuesById[2] = \"File\"] = 2;\n        values[valuesById[3] = \"Metadata\"] = 3;\n        values[valuesById[4] = \"Symlink\"] = 4;\n        values[valuesById[5] = \"HAMTShard\"] = 5;\n        return values;\n    })();\n\n    return Data;\n})();\n\n$root.UnixTime = (function() {\n\n    /**\n     * Properties of an UnixTime.\n     * @exports IUnixTime\n     * @interface IUnixTime\n     * @property {number} Seconds UnixTime Seconds\n     * @property {number|null} [FractionalNanoseconds] UnixTime FractionalNanoseconds\n     */\n\n    /**\n     * Constructs a new UnixTime.\n     * @exports UnixTime\n     * @classdesc Represents an UnixTime.\n     * @implements IUnixTime\n     * @constructor\n     * @param {IUnixTime=} [p] Properties to set\n     */\n    function UnixTime(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * UnixTime Seconds.\n     * @member {number} Seconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.Seconds = $util.Long ? $util.Long.fromBits(0,0,false) : 0;\n\n    /**\n     * UnixTime FractionalNanoseconds.\n     * @member {number} FractionalNanoseconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.FractionalNanoseconds = 0;\n\n    /**\n     * Encodes the specified UnixTime message. Does not implicitly {@link UnixTime.verify|verify} messages.\n     * @function encode\n     * @memberof UnixTime\n     * @static\n     * @param {IUnixTime} m UnixTime message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    UnixTime.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int64(m.Seconds);\n        if (m.FractionalNanoseconds != null && Object.hasOwnProperty.call(m, \"FractionalNanoseconds\"))\n            w.uint32(21).fixed32(m.FractionalNanoseconds);\n        return w;\n    };\n\n    /**\n     * Decodes an UnixTime message from the specified reader or buffer.\n     * @function decode\n     * @memberof UnixTime\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {UnixTime} UnixTime\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    UnixTime.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.UnixTime();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Seconds = r.int64();\n                break;\n            case 2:\n                m.FractionalNanoseconds = r.fixed32();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Seconds\"))\n            throw $util.ProtocolError(\"missing required 'Seconds'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates an UnixTime message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof UnixTime\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {UnixTime} UnixTime\n     */\n    UnixTime.fromObject = function fromObject(d) {\n        if (d instanceof $root.UnixTime)\n            return d;\n        var m = new $root.UnixTime();\n        if (d.Seconds != null) {\n            if ($util.Long)\n                (m.Seconds = $util.Long.fromValue(d.Seconds)).unsigned = false;\n            else if (typeof d.Seconds === \"string\")\n                m.Seconds = parseInt(d.Seconds, 10);\n            else if (typeof d.Seconds === \"number\")\n                m.Seconds = d.Seconds;\n            else if (typeof d.Seconds === \"object\")\n                m.Seconds = new $util.LongBits(d.Seconds.low >>> 0, d.Seconds.high >>> 0).toNumber();\n        }\n        if (d.FractionalNanoseconds != null) {\n            m.FractionalNanoseconds = d.FractionalNanoseconds >>> 0;\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from an UnixTime message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof UnixTime\n     * @static\n     * @param {UnixTime} m UnixTime\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    UnixTime.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, false);\n                d.Seconds = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.Seconds = o.longs === String ? \"0\" : 0;\n            d.FractionalNanoseconds = 0;\n        }\n        if (m.Seconds != null && m.hasOwnProperty(\"Seconds\")) {\n            if (typeof m.Seconds === \"number\")\n                d.Seconds = o.longs === String ? String(m.Seconds) : m.Seconds;\n            else\n                d.Seconds = o.longs === String ? $util.Long.prototype.toString.call(m.Seconds) : o.longs === Number ? new $util.LongBits(m.Seconds.low >>> 0, m.Seconds.high >>> 0).toNumber() : m.Seconds;\n        }\n        if (m.FractionalNanoseconds != null && m.hasOwnProperty(\"FractionalNanoseconds\")) {\n            d.FractionalNanoseconds = m.FractionalNanoseconds;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this UnixTime to JSON.\n     * @function toJSON\n     * @memberof UnixTime\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    UnixTime.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return UnixTime;\n})();\n\n$root.Metadata = (function() {\n\n    /**\n     * Properties of a Metadata.\n     * @exports IMetadata\n     * @interface IMetadata\n     * @property {string|null} [MimeType] Metadata MimeType\n     */\n\n    /**\n     * Constructs a new Metadata.\n     * @exports Metadata\n     * @classdesc Represents a Metadata.\n     * @implements IMetadata\n     * @constructor\n     * @param {IMetadata=} [p] Properties to set\n     */\n    function Metadata(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Metadata MimeType.\n     * @member {string} MimeType\n     * @memberof Metadata\n     * @instance\n     */\n    Metadata.prototype.MimeType = \"\";\n\n    /**\n     * Encodes the specified Metadata message. Does not implicitly {@link Metadata.verify|verify} messages.\n     * @function encode\n     * @memberof Metadata\n     * @static\n     * @param {IMetadata} m Metadata message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Metadata.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        if (m.MimeType != null && Object.hasOwnProperty.call(m, \"MimeType\"))\n            w.uint32(10).string(m.MimeType);\n        return w;\n    };\n\n    /**\n     * Decodes a Metadata message from the specified reader or buffer.\n     * @function decode\n     * @memberof Metadata\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Metadata} Metadata\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Metadata.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Metadata();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.MimeType = r.string();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        return m;\n    };\n\n    /**\n     * Creates a Metadata message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Metadata\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Metadata} Metadata\n     */\n    Metadata.fromObject = function fromObject(d) {\n        if (d instanceof $root.Metadata)\n            return d;\n        var m = new $root.Metadata();\n        if (d.MimeType != null) {\n            m.MimeType = String(d.MimeType);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Metadata message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Metadata\n     * @static\n     * @param {Metadata} m Metadata\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Metadata.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            d.MimeType = \"\";\n        }\n        if (m.MimeType != null && m.hasOwnProperty(\"MimeType\")) {\n            d.MimeType = m.MimeType;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Metadata to JSON.\n     * @function toJSON\n     * @memberof Metadata\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Metadata.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return Metadata;\n})();\n\nmodule.exports = $root;\n","'use strict'\n\n// @ts-ignore\nconst BufferList = require('bl/BufferList')\n\n/**\n * @type {import('../types').Chunker}\n */\nmodule.exports = async function * fixedSizeChunker (source, options) {\n  let bl = new BufferList()\n  let currentLength = 0\n  let emitted = false\n  const maxChunkSize = options.maxChunkSize\n\n  for await (const buffer of source) {\n    bl.append(buffer)\n\n    currentLength += buffer.length\n\n    while (currentLength >= maxChunkSize) {\n      yield bl.slice(0, maxChunkSize)\n      emitted = true\n\n      // throw away consumed bytes\n      if (maxChunkSize === bl.length) {\n        bl = new BufferList()\n        currentLength = 0\n      } else {\n        const newBl = new BufferList()\n        newBl.append(bl.shallowSlice(maxChunkSize))\n        bl = newBl\n\n        // update our offset\n        currentLength -= maxChunkSize\n      }\n    }\n  }\n\n  if (!emitted || currentLength) {\n    // return any remaining bytes or an empty buffer\n    yield bl.slice(0, currentLength)\n  }\n}\n","'use strict'\n\n// @ts-ignore\nconst BufferList = require('bl/BufferList')\n// @ts-ignore\nconst { create } = require('rabin-wasm')\nconst errcode = require('err-code')\n\n/**\n * @typedef {object} RabinOptions\n * @property {number} min\n * @property {number} max\n * @property {number} bits\n * @property {number} window\n * @property {number} polynomial\n */\n\n/**\n * @type {import('../types').Chunker}\n */\nmodule.exports = async function * rabinChunker (source, options) {\n  let min, max, avg\n\n  if (options.minChunkSize && options.maxChunkSize && options.avgChunkSize) {\n    avg = options.avgChunkSize\n    min = options.minChunkSize\n    max = options.maxChunkSize\n  } else if (!options.avgChunkSize) {\n    throw errcode(new Error('please specify an average chunk size'), 'ERR_INVALID_AVG_CHUNK_SIZE')\n  } else {\n    avg = options.avgChunkSize\n    min = avg / 3\n    max = avg + (avg / 2)\n  }\n\n  // validate min/max/avg in the same way as go\n  if (min < 16) {\n    throw errcode(new Error('rabin min must be greater than 16'), 'ERR_INVALID_MIN_CHUNK_SIZE')\n  }\n\n  if (max < min) {\n    max = min\n  }\n\n  if (avg < min) {\n    avg = min\n  }\n\n  const sizepow = Math.floor(Math.log2(avg))\n\n  for await (const chunk of rabin(source, {\n    min: min,\n    max: max,\n    bits: sizepow,\n    window: options.window,\n    polynomial: options.polynomial\n  })) {\n    yield chunk\n  }\n}\n\n/**\n * @param {AsyncIterable<Uint8Array>} source\n * @param {RabinOptions} options\n */\nasync function * rabin (source, options) {\n  const r = await create(options.bits, options.min, options.max, options.window)\n  const buffers = new BufferList()\n\n  for await (const chunk of source) {\n    buffers.append(chunk)\n\n    const sizes = r.fingerprint(chunk)\n\n    for (let i = 0; i < sizes.length; i++) {\n      const size = sizes[i]\n      const buf = buffers.slice(0, size)\n      buffers.consume(size)\n\n      yield buf\n    }\n  }\n\n  if (buffers.length) {\n    yield buffers.slice(0)\n  }\n}\n","'use strict'\n\nconst { UnixFS } = require('ipfs-unixfs')\nconst persist = require('../utils/persist')\nconst { encode, prepare } = require('@ipld/dag-pb')\n\n/**\n * @typedef {import('../types').Directory} Directory\n */\n\n/**\n * @type {import('../types').UnixFSV1DagBuilder<Directory>}\n */\nconst dirBuilder = async (item, blockstore, options) => {\n  const unixfs = new UnixFS({\n    type: 'directory',\n    mtime: item.mtime,\n    mode: item.mode\n  })\n\n  const buffer = encode(prepare({ Data: unixfs.marshal() }))\n  const cid = await persist(buffer, blockstore, options)\n  const path = item.path\n\n  return {\n    cid,\n    path,\n    unixfs,\n    size: buffer.length\n  }\n}\n\nmodule.exports = dirBuilder\n","'use strict'\n\nconst batch = require('it-batch')\n\n/**\n * @typedef {import('../../types').FileDAGBuilder} FileDAGBuilder\n */\n\n/**\n * @type {FileDAGBuilder}\n */\nfunction balanced (source, reduce, options) {\n  return reduceToParents(source, reduce, options)\n}\n\n/**\n * @type {FileDAGBuilder}\n */\nasync function reduceToParents (source, reduce, options) {\n  const roots = []\n\n  for await (const chunked of batch(source, options.maxChildrenPerNode)) {\n    roots.push(await reduce(chunked))\n  }\n\n  if (roots.length > 1) {\n    return reduceToParents(roots, reduce, options)\n  }\n\n  return roots[0]\n}\n\nmodule.exports = balanced\n","'use strict'\n\nconst { UnixFS } = require('ipfs-unixfs')\nconst persist = require('../../utils/persist')\nconst dagPb = require('@ipld/dag-pb')\nconst raw = require('multiformats/codecs/raw')\n\n/**\n * @typedef {import('../../types').BufferImporter} BufferImporter\n */\n\n/**\n * @type {BufferImporter}\n */\nasync function * bufferImporter (file, block, options) {\n  for await (let buffer of file.content) {\n    yield async () => {\n      options.progress(buffer.length, file.path)\n      let unixfs\n\n      /** @type {import('../../types').PersistOptions} */\n      const opts = {\n        codec: dagPb,\n        cidVersion: options.cidVersion,\n        hasher: options.hasher,\n        onlyHash: options.onlyHash\n      }\n\n      if (options.rawLeaves) {\n        opts.codec = raw\n        opts.cidVersion = 1\n      } else {\n        unixfs = new UnixFS({\n          type: options.leafType,\n          data: buffer,\n          mtime: file.mtime,\n          mode: file.mode\n        })\n\n        buffer = dagPb.encode({\n          Data: unixfs.marshal(),\n          Links: []\n        })\n      }\n\n      return {\n        cid: await persist(buffer, block, opts),\n        unixfs,\n        size: buffer.length\n      }\n    }\n  }\n}\n\nmodule.exports = bufferImporter\n","'use strict'\n\nconst all = require('it-all')\n\n/**\n * @type {import('../../types').FileDAGBuilder}\n */\nmodule.exports = async function (source, reduce) {\n  return reduce(await all(source))\n}\n","'use strict'\n\nconst errCode = require('err-code')\nconst { UnixFS } = require('ipfs-unixfs')\nconst persist = require('../../utils/persist')\nconst { encode, prepare } = require('@ipld/dag-pb')\nconst parallelBatch = require('it-parallel-batch')\nconst rawCodec = require('multiformats/codecs/raw')\nconst dagPb = require('@ipld/dag-pb')\n\n/**\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('../../types').File} File\n * @typedef {import('../../types').ImporterOptions} ImporterOptions\n * @typedef {import('../../types').Reducer} Reducer\n * @typedef {import('../../types').DAGBuilder} DAGBuilder\n * @typedef {import('../../types').FileDAGBuilder} FileDAGBuilder\n */\n\n/**\n * @type {{ [key: string]: FileDAGBuilder}}\n */\nconst dagBuilders = {\n  flat: require('./flat'),\n  balanced: require('./balanced'),\n  trickle: require('./trickle')\n}\n\n/**\n * @param {File} file\n * @param {Blockstore} blockstore\n * @param {ImporterOptions} options\n */\nasync function * buildFileBatch (file, blockstore, options) {\n  let count = -1\n  let previous\n  let bufferImporter\n\n  if (typeof options.bufferImporter === 'function') {\n    bufferImporter = options.bufferImporter\n  } else {\n    bufferImporter = require('./buffer-importer')\n  }\n\n  for await (const entry of parallelBatch(bufferImporter(file, blockstore, options), options.blockWriteConcurrency)) {\n    count++\n\n    if (count === 0) {\n      previous = entry\n      continue\n    } else if (count === 1 && previous) {\n      yield previous\n      previous = null\n    }\n\n    yield entry\n  }\n\n  if (previous) {\n    previous.single = true\n    yield previous\n  }\n}\n\n/**\n * @param {File} file\n * @param {Blockstore} blockstore\n * @param {ImporterOptions} options\n */\nconst reduce = (file, blockstore, options) => {\n  /**\n   * @type {Reducer}\n   */\n  async function reducer (leaves) {\n    if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n      const leaf = leaves[0]\n\n      if (leaf.cid.code === rawCodec.code && (file.mtime !== undefined || file.mode !== undefined)) {\n        // only one leaf node which is a buffer - we have metadata so convert it into a\n        // UnixFS entry otherwise we'll have nowhere to store the metadata\n        let buffer = await blockstore.get(leaf.cid)\n\n        leaf.unixfs = new UnixFS({\n          type: 'file',\n          mtime: file.mtime,\n          mode: file.mode,\n          data: buffer\n        })\n\n        buffer = encode(prepare({ Data: leaf.unixfs.marshal() }))\n\n        // // TODO vmx 2021-03-26: This is what the original code does, it checks\n        // // the multihash of the original leaf node and uses then the same\n        // // hasher. i wonder if that's really needed or if we could just use\n        // // the hasher from `options.hasher` instead.\n        // const multihash = mh.decode(leaf.cid.multihash.bytes)\n        // let hasher\n        // switch multihash {\n        //   case sha256.code {\n        //     hasher = sha256\n        //     break;\n        //   }\n        //   //case identity.code {\n        //   //  hasher = identity\n        //   //  break;\n        //   //}\n        //   default: {\n        //     throw new Error(`Unsupported hasher \"${multihash}\"`)\n        //   }\n        // }\n        leaf.cid = await persist(buffer, blockstore, {\n          ...options,\n          codec: dagPb,\n          hasher: options.hasher,\n          cidVersion: options.cidVersion\n        })\n        leaf.size = buffer.length\n      }\n\n      return {\n        cid: leaf.cid,\n        path: file.path,\n        unixfs: leaf.unixfs,\n        size: leaf.size\n      }\n    }\n\n    // create a parent node and add all the leaves\n    const f = new UnixFS({\n      type: 'file',\n      mtime: file.mtime,\n      mode: file.mode\n    })\n\n    const links = leaves\n      .filter(leaf => {\n        if (leaf.cid.code === rawCodec.code && leaf.size) {\n          return true\n        }\n\n        if (leaf.unixfs && !leaf.unixfs.data && leaf.unixfs.fileSize()) {\n          return true\n        }\n\n        return Boolean(leaf.unixfs && leaf.unixfs.data && leaf.unixfs.data.length)\n      })\n      .map((leaf) => {\n        if (leaf.cid.code === rawCodec.code) {\n          // node is a leaf buffer\n          f.addBlockSize(leaf.size)\n\n          return {\n            Name: '',\n            Tsize: leaf.size,\n            Hash: leaf.cid\n          }\n        }\n\n        if (!leaf.unixfs || !leaf.unixfs.data) {\n          // node is an intermediate node\n          f.addBlockSize((leaf.unixfs && leaf.unixfs.fileSize()) || 0)\n        } else {\n          // node is a unixfs 'file' leaf node\n          f.addBlockSize(leaf.unixfs.data.length)\n        }\n\n        return {\n          Name: '',\n          Tsize: leaf.size,\n          Hash: leaf.cid\n        }\n      })\n\n    const node = {\n      Data: f.marshal(),\n      Links: links\n    }\n    const buffer = encode(prepare(node))\n    const cid = await persist(buffer, blockstore, options)\n\n    return {\n      cid,\n      path: file.path,\n      unixfs: f,\n      size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n    }\n  }\n\n  return reducer\n}\n\n/**\n * @type {import('../../types').UnixFSV1DagBuilder<File>}\n */\nfunction fileBuilder (file, block, options) {\n  const dagBuilder = dagBuilders[options.strategy]\n\n  if (!dagBuilder) {\n    throw errCode(new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY')\n  }\n\n  return dagBuilder(buildFileBatch(file, block, options), reduce(file, block, options), options)\n}\n\nmodule.exports = fileBuilder\n","'use strict'\n\nconst batch = require('it-batch')\n\n/**\n * @typedef {import('ipfs-unixfs').UnixFS} UnixFS\n * @typedef {import('../../types').ImporterOptions} ImporterOptions\n * @typedef {import('../../types').InProgressImportResult} InProgressImportResult\n * @typedef {import('../../types').TrickleDagNode} TrickleDagNode\n * @typedef {import('../../types').Reducer} Reducer\n * @typedef {import('../../types').FileDAGBuilder} FileDAGBuilder\n */\n\n/**\n * @type {FileDAGBuilder}\n */\nmodule.exports = async function trickleStream (source, reduce, options) {\n  const root = new Root(options.layerRepeat)\n  let iteration = 0\n  let maxDepth = 1\n\n  /** @type {SubTree} */\n  let subTree = root\n\n  for await (const layer of batch(source, options.maxChildrenPerNode)) {\n    if (subTree.isFull()) {\n      if (subTree !== root) {\n        root.addChild(await subTree.reduce(reduce))\n      }\n\n      if (iteration && iteration % options.layerRepeat === 0) {\n        maxDepth++\n      }\n\n      subTree = new SubTree(maxDepth, options.layerRepeat, iteration)\n\n      iteration++\n    }\n\n    subTree.append(layer)\n  }\n\n  if (subTree && subTree !== root) {\n    root.addChild(await subTree.reduce(reduce))\n  }\n\n  return root.reduce(reduce)\n}\n\nclass SubTree {\n  /**\n   * @param {number} maxDepth\n   * @param {number} layerRepeat\n   * @param {number} [iteration=0]\n   */\n  constructor (maxDepth, layerRepeat, iteration = 0) {\n    this.maxDepth = maxDepth\n    this.layerRepeat = layerRepeat\n    this.currentDepth = 1\n    this.iteration = iteration\n\n    /** @type {TrickleDagNode} */\n    this.root = this.node = this.parent = {\n      children: [],\n      depth: this.currentDepth,\n      maxDepth,\n      maxChildren: (this.maxDepth - this.currentDepth) * this.layerRepeat\n    }\n  }\n\n  isFull () {\n    if (!this.root.data) {\n      return false\n    }\n\n    if (this.currentDepth < this.maxDepth && this.node.maxChildren) {\n      // can descend\n      this._addNextNodeToParent(this.node)\n\n      return false\n    }\n\n    // try to find new node from node.parent\n    const distantRelative = this._findParent(this.node, this.currentDepth)\n\n    if (distantRelative) {\n      this._addNextNodeToParent(distantRelative)\n\n      return false\n    }\n\n    return true\n  }\n\n  /**\n   * @param {TrickleDagNode} parent\n   */\n  _addNextNodeToParent (parent) {\n    this.parent = parent\n\n    // find site for new node\n    const nextNode = {\n      children: [],\n      depth: parent.depth + 1,\n      parent,\n      maxDepth: this.maxDepth,\n      maxChildren: Math.floor(parent.children.length / this.layerRepeat) * this.layerRepeat\n    }\n\n    // @ts-ignore\n    parent.children.push(nextNode)\n\n    this.currentDepth = nextNode.depth\n    this.node = nextNode\n  }\n\n  /**\n   *\n   * @param {InProgressImportResult[]} layer\n   */\n  append (layer) {\n    this.node.data = layer\n  }\n\n  /**\n   * @param {Reducer} reduce\n   */\n  reduce (reduce) {\n    return this._reduce(this.root, reduce)\n  }\n\n  /**\n   * @param {TrickleDagNode} node\n   * @param {Reducer} reduce\n   * @returns {Promise<InProgressImportResult>}\n   */\n  async _reduce (node, reduce) {\n    /** @type {InProgressImportResult[]} */\n    let children = []\n\n    if (node.children.length) {\n      children = await Promise.all(\n        node.children\n          // @ts-ignore\n          .filter(child => child.data)\n          // @ts-ignore\n          .map(child => this._reduce(child, reduce))\n      )\n    }\n\n    return reduce((node.data || []).concat(children))\n  }\n\n  /**\n   * @param {TrickleDagNode} node\n   * @param {number} depth\n   * @returns {TrickleDagNode | undefined}\n   */\n  _findParent (node, depth) {\n    const parent = node.parent\n\n    if (!parent || parent.depth === 0) {\n      return\n    }\n\n    if (parent.children.length === parent.maxChildren || !parent.maxChildren) {\n      // this layer is full, may be able to traverse to a different branch\n      return this._findParent(parent, depth)\n    }\n\n    return parent\n  }\n}\n\nclass Root extends SubTree {\n  /**\n   * @param {number} layerRepeat\n   */\n  constructor (layerRepeat) {\n    super(0, layerRepeat)\n\n    this.root.depth = 0\n    this.currentDepth = 1\n  }\n\n  /**\n   * @param {InProgressImportResult} child\n   */\n  addChild (child) {\n    this.root.children.push(child)\n  }\n\n  /**\n   * @param {Reducer} reduce\n   */\n  reduce (reduce) {\n    return reduce((this.root.data || []).concat(this.root.children))\n  }\n}\n","'use strict'\n\nconst dirBuilder = require('./dir')\nconst fileBuilder = require('./file')\nconst errCode = require('err-code')\n\n/**\n * @typedef {import('../types').File} File\n * @typedef {import('../types').Directory} Directory\n * @typedef {import('../types').DAGBuilder} DAGBuilder\n * @typedef {import('../types').Chunker} Chunker\n * @typedef {import('../types').ChunkValidator} ChunkValidator\n */\n\n/**\n * @param {any} thing\n * @returns {thing is Iterable<any>}\n */\nfunction isIterable (thing) {\n  return Symbol.iterator in thing\n}\n\n/**\n * @param {any} thing\n * @returns {thing is AsyncIterable<any>}\n */\nfunction isAsyncIterable (thing) {\n  return Symbol.asyncIterator in thing\n}\n\n/**\n * @param {Uint8Array | AsyncIterable<Uint8Array> | Iterable<Uint8Array>} content\n * @returns {AsyncIterable<Uint8Array>}\n */\nfunction contentAsAsyncIterable (content) {\n  try {\n    if (content instanceof Uint8Array) {\n      return (async function * () {\n        yield content\n      }())\n    } else if (isIterable(content)) {\n      return (async function * () {\n        yield * content\n      }())\n    } else if (isAsyncIterable(content)) {\n      return content\n    }\n  } catch {\n    throw errCode(new Error('Content was invalid'), 'ERR_INVALID_CONTENT')\n  }\n\n  throw errCode(new Error('Content was invalid'), 'ERR_INVALID_CONTENT')\n}\n\n/**\n * @type {DAGBuilder}\n */\nasync function * dagBuilder (source, blockstore, options) {\n  for await (const entry of source) {\n    if (entry.path) {\n      if (entry.path.substring(0, 2) === './') {\n        options.wrapWithDirectory = true\n      }\n\n      entry.path = entry.path\n        .split('/')\n        .filter(path => path && path !== '.')\n        .join('/')\n    }\n\n    if (entry.content) {\n      /**\n       * @type {Chunker}\n       */\n      let chunker\n\n      if (typeof options.chunker === 'function') {\n        chunker = options.chunker\n      } else if (options.chunker === 'rabin') {\n        chunker = require('../chunker/rabin')\n      } else {\n        chunker = require('../chunker/fixed-size')\n      }\n\n      /**\n       * @type {ChunkValidator}\n       */\n      let chunkValidator\n\n      if (typeof options.chunkValidator === 'function') {\n        chunkValidator = options.chunkValidator\n      } else {\n        chunkValidator = require('./validate-chunks')\n      }\n\n      /** @type {File} */\n      const file = {\n        path: entry.path,\n        mtime: entry.mtime,\n        mode: entry.mode,\n        content: chunker(chunkValidator(contentAsAsyncIterable(entry.content), options), options)\n      }\n\n      yield () => fileBuilder(file, blockstore, options)\n    } else if (entry.path) {\n      /** @type {Directory} */\n      const dir = {\n        path: entry.path,\n        mtime: entry.mtime,\n        mode: entry.mode\n      }\n\n      yield () => dirBuilder(dir, blockstore, options)\n    } else {\n      throw new Error('Import candidate must have content or path or both')\n    }\n  }\n}\n\nmodule.exports = dagBuilder\n","'use strict'\n\nconst errCode = require('err-code')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n/**\n * @typedef {import('../types').ChunkValidator} ChunkValidator\n */\n\n/**\n * @type {ChunkValidator}\n */\nasync function * validateChunks (source) {\n  for await (const content of source) {\n    if (content.length === undefined) {\n      throw errCode(new Error('Content was invalid'), 'ERR_INVALID_CONTENT')\n    }\n\n    if (typeof content === 'string' || content instanceof String) {\n      yield uint8ArrayFromString(content.toString())\n    } else if (Array.isArray(content)) {\n      yield Uint8Array.from(content)\n    } else if (content instanceof Uint8Array) {\n      yield content\n    } else {\n      throw errCode(new Error('Content was invalid'), 'ERR_INVALID_CONTENT')\n    }\n  }\n}\n\nmodule.exports = validateChunks\n","'use strict'\n\nconst { encode, prepare } = require('@ipld/dag-pb')\nconst { UnixFS } = require('ipfs-unixfs')\nconst Dir = require('./dir')\nconst persist = require('./utils/persist')\n\n/**\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('./dir').DirProps} DirProps\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('@ipld/dag-pb').PBLink} PBLink\n */\n\nclass DirFlat extends Dir {\n  /**\n   * @param {DirProps} props\n   * @param {ImporterOptions} options\n   */\n  constructor (props, options) {\n    super(props, options)\n\n    /** @type {{ [key: string]: InProgressImportResult | Dir }} */\n    this._children = {}\n  }\n\n  /**\n   * @param {string} name\n   * @param {InProgressImportResult | Dir} value\n   */\n  async put (name, value) {\n    this.cid = undefined\n    this.size = undefined\n\n    this._children[name] = value\n  }\n\n  /**\n   * @param {string} name\n   */\n  get (name) {\n    return Promise.resolve(this._children[name])\n  }\n\n  childCount () {\n    return Object.keys(this._children).length\n  }\n\n  directChildrenCount () {\n    return this.childCount()\n  }\n\n  onlyChild () {\n    return this._children[Object.keys(this._children)[0]]\n  }\n\n  async * eachChildSeries () {\n    const keys = Object.keys(this._children)\n\n    for (let i = 0; i < keys.length; i++) {\n      const key = keys[i]\n\n      yield {\n        key: key,\n        child: this._children[key]\n      }\n    }\n  }\n\n  /**\n   * @param {Blockstore} block\n   * @returns {AsyncIterable<ImportResult>}\n   */\n  async * flush (block) {\n    const children = Object.keys(this._children)\n    const links = []\n\n    for (let i = 0; i < children.length; i++) {\n      let child = this._children[children[i]]\n\n      if (child instanceof Dir) {\n        for await (const entry of child.flush(block)) {\n          child = entry\n\n          yield child\n        }\n      }\n\n      if (child.size != null && child.cid) {\n        links.push({\n          Name: children[i],\n          Tsize: child.size,\n          Hash: child.cid\n        })\n      }\n    }\n\n    const unixfs = new UnixFS({\n      type: 'directory',\n      mtime: this.mtime,\n      mode: this.mode\n    })\n\n    /** @type {PBNode} */\n    const node = { Data: unixfs.marshal(), Links: links }\n    const buffer = encode(prepare(node))\n    const cid = await persist(buffer, block, this.options)\n    const size = buffer.length + node.Links.reduce(\n      /**\n       * @param {number} acc\n       * @param {PBLink} curr\n       */\n      (acc, curr) => acc + (curr.Tsize == null ? 0 : curr.Tsize),\n      0)\n\n    this.cid = cid\n    this.size = size\n\n    yield {\n      cid,\n      unixfs,\n      path: this.path,\n      size\n    }\n  }\n}\n\nmodule.exports = DirFlat\n","'use strict'\n\nconst { encode, prepare } = require('@ipld/dag-pb')\nconst { UnixFS } = require('ipfs-unixfs')\nconst Dir = require('./dir')\nconst persist = require('./utils/persist')\nconst { createHAMT, Bucket } = require('hamt-sharding')\n\n/**\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n */\n\n/**\n * @typedef {import('./dir').DirProps} DirProps\n */\n\nclass DirSharded extends Dir {\n  /**\n   * @param {DirProps} props\n   * @param {ImporterOptions} options\n   */\n  constructor (props, options) {\n    super(props, options)\n\n    /** @type {Bucket<InProgressImportResult | Dir>} */\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    })\n  }\n\n  /**\n   * @param {string} name\n   * @param {InProgressImportResult | Dir} value\n   */\n  async put (name, value) {\n    await this._bucket.put(name, value)\n  }\n\n  /**\n   * @param {string} name\n   */\n  get (name) {\n    return this._bucket.get(name)\n  }\n\n  childCount () {\n    return this._bucket.leafCount()\n  }\n\n  directChildrenCount () {\n    return this._bucket.childrenCount()\n  }\n\n  onlyChild () {\n    return this._bucket.onlyChild()\n  }\n\n  async * eachChildSeries () {\n    for await (const { key, value } of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      }\n    }\n  }\n\n  /**\n   * @param {Blockstore} blockstore\n   * @returns {AsyncIterable<ImportResult>}\n   */\n  async * flush (blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield {\n        ...entry,\n        path: this.path\n      }\n    }\n  }\n}\n\nmodule.exports = DirSharded\n\n/**\n * @param {Bucket<?>} bucket\n * @param {Blockstore} blockstore\n * @param {*} shardRoot\n * @param {ImporterOptions} options\n * @returns {AsyncIterable<ImportResult>}\n */\nasync function * flush (bucket, blockstore, shardRoot, options) {\n  const children = bucket._children\n  const links = []\n  let childrenSize = 0\n\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i)\n\n    if (!child) {\n      continue\n    }\n\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0')\n\n    if (child instanceof Bucket) {\n      let shard\n\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard\n      }\n\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found')\n      }\n\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      })\n      childrenSize += shard.size\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value\n      let flushedDir\n\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry\n\n        yield flushedDir\n      }\n\n      const label = labelPrefix + child.key\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      })\n\n      childrenSize += flushedDir.size\n    } else {\n      const value = child.value\n\n      if (!value.cid) {\n        continue\n      }\n\n      const label = labelPrefix + child.key\n      const size = value.size\n\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      })\n      childrenSize += size\n    }\n  }\n\n  // go-ipfs uses little endian, that's why we have to\n  // reverse the bit field before storing it\n  const data = Uint8Array.from(children.bitField().reverse())\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  })\n\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  }\n  const buffer = encode(prepare(node))\n  const cid = await persist(buffer, blockstore, options)\n  const size = buffer.length + childrenSize\n\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  }\n}\n","'use strict'\n\n/**\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('multiformats/cid').CID} CID\n * @typedef {object} DirProps\n * @property {boolean} root\n * @property {boolean} dir\n * @property {string} path\n * @property {boolean} dirty\n * @property {boolean} flat\n * @property {Dir} [parent]\n * @property {string} [parentKey]\n * @property {import('ipfs-unixfs').UnixFS} [unixfs]\n * @property {number} [mode]\n * @property {import('ipfs-unixfs').Mtime} [mtime]\n */\nclass Dir {\n  /**\n   *\n   * @param {DirProps} props\n   * @param {ImporterOptions} options\n   */\n  constructor (props, options) {\n    this.options = options || {}\n\n    this.root = props.root\n    this.dir = props.dir\n    this.path = props.path\n    this.dirty = props.dirty\n    this.flat = props.flat\n    this.parent = props.parent\n    this.parentKey = props.parentKey\n    this.unixfs = props.unixfs\n    this.mode = props.mode\n    this.mtime = props.mtime\n\n    /** @type {CID | undefined} */\n    this.cid = undefined\n    /** @type {number | undefined} */\n    this.size = undefined\n  }\n\n  /**\n   * @param {string} name\n   * @param {InProgressImportResult | Dir} value\n   */\n  async put (name, value) { }\n\n  /**\n   * @param {string} name\n   * @returns {Promise<InProgressImportResult | Dir | undefined>}\n   */\n  get (name) {\n    return Promise.resolve(this)\n  }\n\n  /**\n   * @returns {AsyncIterable<{ key: string, child: InProgressImportResult | Dir}>}\n   */\n  async * eachChildSeries () { }\n\n  /**\n   * @param {Blockstore} blockstore\n   * @returns {AsyncIterable<ImportResult>}\n   */\n  async * flush (blockstore) { }\n}\n\nmodule.exports = Dir\n","'use strict'\n\nconst DirSharded = require('./dir-sharded')\nconst DirFlat = require('./dir-flat')\n\n/**\n * @typedef {import('./dir')} Dir\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n */\n\n/**\n * @param {Dir | null} child\n * @param {Dir} dir\n * @param {number} threshold\n * @param {ImporterOptions} options\n * @returns {Promise<DirSharded>}\n */\nmodule.exports = async function flatToShard (child, dir, threshold, options) {\n  let newDir = dir\n\n  if (dir instanceof DirFlat && dir.directChildrenCount() >= threshold) {\n    newDir = await convertToShard(dir, options)\n  }\n\n  const parent = newDir.parent\n\n  if (parent) {\n    if (newDir !== dir) {\n      if (child) {\n        child.parent = newDir\n      }\n\n      if (!newDir.parentKey) {\n        throw new Error('No parent key found')\n      }\n\n      await parent.put(newDir.parentKey, newDir)\n    }\n\n    return flatToShard(newDir, parent, threshold, options)\n  }\n\n  // @ts-ignore\n  return newDir\n}\n\n/**\n * @param {DirFlat} oldDir\n * @param {ImporterOptions} options\n */\nasync function convertToShard (oldDir, options) {\n  const newDir = new DirSharded({\n    root: oldDir.root,\n    dir: true,\n    parent: oldDir.parent,\n    parentKey: oldDir.parentKey,\n    path: oldDir.path,\n    dirty: oldDir.dirty,\n    flat: false,\n    mtime: oldDir.mtime,\n    mode: oldDir.mode\n  }, options)\n\n  for await (const { key, child } of oldDir.eachChildSeries()) {\n    await newDir.put(key, child)\n  }\n\n  return newDir\n}\n","'use strict'\n\nconst parallelBatch = require('it-parallel-batch')\nconst defaultOptions = require('./options')\n\n/**\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('./types').ImportCandidate} ImportCandidate\n * @typedef {import('./types').UserImporterOptions} UserImporterOptions\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('./types').Directory} Directory\n * @typedef {import('./types').File} File\n * @typedef {import('./types').ImportResult} ImportResult\n *\n * @typedef {import('./types').Chunker} Chunker\n * @typedef {import('./types').DAGBuilder} DAGBuilder\n * @typedef {import('./types').TreeBuilder} TreeBuilder\n * @typedef {import('./types').BufferImporter} BufferImporter\n * @typedef {import('./types').ChunkValidator} ChunkValidator\n * @typedef {import('./types').Reducer} Reducer\n * @typedef {import('./types').ProgressHandler} ProgressHandler\n */\n\n/**\n * @param {AsyncIterable<ImportCandidate> | Iterable<ImportCandidate> | ImportCandidate} source\n * @param {Blockstore} blockstore\n * @param {UserImporterOptions} options\n */\nasync function * importer (source, blockstore, options = {}) {\n  const opts = defaultOptions(options)\n\n  let dagBuilder\n\n  if (typeof options.dagBuilder === 'function') {\n    dagBuilder = options.dagBuilder\n  } else {\n    dagBuilder = require('./dag-builder')\n  }\n\n  let treeBuilder\n\n  if (typeof options.treeBuilder === 'function') {\n    treeBuilder = options.treeBuilder\n  } else {\n    treeBuilder = require('./tree-builder')\n  }\n\n  /** @type {AsyncIterable<ImportCandidate> | Iterable<ImportCandidate>} */\n  let candidates\n\n  if (Symbol.asyncIterator in source || Symbol.iterator in source) {\n    // @ts-ignore\n    candidates = source\n  } else {\n    // @ts-ignore\n    candidates = [source]\n  }\n\n  for await (const entry of treeBuilder(parallelBatch(dagBuilder(candidates, blockstore, opts), opts.fileImportConcurrency), blockstore, opts)) {\n    yield {\n      cid: entry.cid,\n      path: entry.path,\n      unixfs: entry.unixfs,\n      size: entry.size\n    }\n  }\n}\n\nmodule.exports = {\n  importer\n}\n","'use strict'\n\nconst mergeOptions = require('merge-options').bind({ ignoreUndefined: true })\nconst { sha256 } = require('multiformats/hashes/sha2')\n// @ts-ignore - no types available\nconst mur = require('murmurhash3js-revisited')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n/**\n * @param {Uint8Array} buf\n */\nasync function hamtHashFn (buf) {\n  return uint8ArrayFromString(mur.x64.hash128(buf), 'base16')\n    // Murmur3 outputs 128 bit but, accidentally, IPFS Go's\n    // implementation only uses the first 64, so we must do the same\n    // for parity..\n    .slice(0, 8)\n    // Invert buffer because that's how Go impl does it\n    .reverse()\n}\n\n/**\n * @typedef {import('./types').UserImporterOptions} UserImporterOptions\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n */\n\n/**\n * @type {ImporterOptions}\n */\nconst defaultOptions = {\n  chunker: 'fixed',\n  strategy: 'balanced', // 'flat', 'trickle'\n  rawLeaves: false,\n  onlyHash: false,\n  reduceSingleLeafToSelf: true,\n  hasher: sha256,\n  leafType: 'file', // 'raw'\n  cidVersion: 0,\n  progress: () => () => {},\n  shardSplitThreshold: 1000,\n  fileImportConcurrency: 50,\n  blockWriteConcurrency: 10,\n  minChunkSize: 262144,\n  maxChunkSize: 262144,\n  avgChunkSize: 262144,\n  window: 16,\n  // FIXME: This number is too big for JavaScript\n  // https://github.com/ipfs/go-ipfs-chunker/blob/d0125832512163708c0804a3cda060e21acddae4/rabin.go#L11\n  polynomial: 17437180132763653, // eslint-disable-line no-loss-of-precision\n  maxChildrenPerNode: 174,\n  layerRepeat: 4,\n  wrapWithDirectory: false,\n  recursive: false,\n  hidden: false,\n  timeout: undefined,\n  hamtHashFn,\n  hamtHashCode: 0x22,\n  hamtBucketBits: 8\n}\n\n/**\n * @param {UserImporterOptions} options\n * @returns {ImporterOptions}\n */\nmodule.exports = function (options = {}) {\n  return mergeOptions(defaultOptions, options)\n}\n","'use strict'\n\nconst DirFlat = require('./dir-flat')\nconst flatToShard = require('./flat-to-shard')\nconst Dir = require('./dir')\nconst toPathComponents = require('./utils/to-path-components')\n\n/**\n * @typedef {import('./types').ImportResult} ImportResult\n * @typedef {import('./types').InProgressImportResult} InProgressImportResult\n * @typedef {import('./types').ImporterOptions} ImporterOptions\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {(source: AsyncIterable<InProgressImportResult>, blockstore: Blockstore, options: ImporterOptions) => AsyncIterable<ImportResult>} TreeBuilder\n */\n\n/**\n * @param {InProgressImportResult} elem\n * @param {Dir} tree\n * @param {ImporterOptions} options\n */\nasync function addToTree (elem, tree, options) {\n  const pathElems = toPathComponents(elem.path || '')\n  const lastIndex = pathElems.length - 1\n  let parent = tree\n  let currentPath = ''\n\n  for (let i = 0; i < pathElems.length; i++) {\n    const pathElem = pathElems[i]\n\n    currentPath += `${currentPath ? '/' : ''}${pathElem}`\n\n    const last = (i === lastIndex)\n    parent.dirty = true\n    parent.cid = undefined\n    parent.size = undefined\n\n    if (last) {\n      await parent.put(pathElem, elem)\n      tree = await flatToShard(null, parent, options.shardSplitThreshold, options)\n    } else {\n      let dir = await parent.get(pathElem)\n\n      if (!dir || !(dir instanceof Dir)) {\n        dir = new DirFlat({\n          root: false,\n          dir: true,\n          parent: parent,\n          parentKey: pathElem,\n          path: currentPath,\n          dirty: true,\n          flat: true,\n          mtime: dir && dir.unixfs && dir.unixfs.mtime,\n          mode: dir && dir.unixfs && dir.unixfs.mode\n        }, options)\n      }\n\n      await parent.put(pathElem, dir)\n\n      parent = dir\n    }\n  }\n\n  return tree\n}\n\n/**\n * @param {Dir | InProgressImportResult} tree\n * @param {Blockstore} blockstore\n */\nasync function * flushAndYield (tree, blockstore) {\n  if (!(tree instanceof Dir)) {\n    if (tree && tree.unixfs && tree.unixfs.isDirectory()) {\n      yield tree\n    }\n\n    return\n  }\n\n  yield * tree.flush(blockstore)\n}\n\n/**\n * @type {TreeBuilder}\n */\nasync function * treeBuilder (source, block, options) {\n  /** @type {Dir} */\n  let tree = new DirFlat({\n    root: true,\n    dir: true,\n    path: '',\n    dirty: true,\n    flat: true\n  }, options)\n\n  for await (const entry of source) {\n    if (!entry) {\n      continue\n    }\n\n    tree = await addToTree(entry, tree, options)\n\n    if (!entry.unixfs || !entry.unixfs.isDirectory()) {\n      yield entry\n    }\n  }\n\n  if (options.wrapWithDirectory) {\n    yield * flushAndYield(tree, block)\n  } else {\n    for await (const unwrapped of tree.eachChildSeries()) {\n      if (!unwrapped) {\n        continue\n      }\n\n      yield * flushAndYield(unwrapped.child, block)\n    }\n  }\n}\n\nmodule.exports = treeBuilder\n","'use strict'\n\nconst { CID } = require('multiformats/cid')\nconst dagPb = require('@ipld/dag-pb')\nconst { sha256 } = require('multiformats/hashes/sha2')\n\n/**\n * @param {Uint8Array} buffer\n * @param {import('interface-blockstore').Blockstore} blockstore\n * @param {import('../types').PersistOptions} options\n */\nconst persist = async (buffer, blockstore, options) => {\n  if (!options.codec) {\n    options.codec = dagPb\n  }\n\n  if (!options.hasher) {\n    options.hasher = sha256\n  }\n\n  if (options.cidVersion === undefined) {\n    options.cidVersion = 1\n  }\n\n  if (options.codec === dagPb && options.hasher !== sha256) {\n    options.cidVersion = 1\n  }\n\n  const multihash = await options.hasher.digest(buffer)\n  const cid = CID.create(options.cidVersion, options.codec.code, multihash)\n\n  if (!options.onlyHash) {\n    await blockstore.put(cid, buffer, {\n      signal: options.signal\n    })\n  }\n\n  return cid\n}\n\nmodule.exports = persist\n","'use strict'\n\nconst toPathComponents = (path = '') => {\n  // split on / unless escaped with \\\n  return (path\n    .trim()\n    .match(/([^\\\\^/]|\\\\\\/)+/g) || [])\n    .filter(Boolean)\n}\n\nmodule.exports = toPathComponents\n","'use strict'\n\nconst {\n  Data: PBData\n} = require('./unixfs')\nconst errcode = require('err-code')\n\n/**\n * @typedef {import('./types').Mtime} Mtime\n * @typedef {import('./types').MtimeLike} MtimeLike\n */\n\nconst types = [\n  'raw',\n  'directory',\n  'file',\n  'metadata',\n  'symlink',\n  'hamt-sharded-directory'\n]\n\nconst dirTypes = [\n  'directory',\n  'hamt-sharded-directory'\n]\n\nconst DEFAULT_FILE_MODE = parseInt('0644', 8)\nconst DEFAULT_DIRECTORY_MODE = parseInt('0755', 8)\n\n/**\n * @param {string | number | undefined} [mode]\n */\nfunction parseMode (mode) {\n  if (mode == null) {\n    return undefined\n  }\n\n  if (typeof mode === 'number') {\n    return mode & 0xFFF\n  }\n\n  mode = mode.toString()\n\n  if (mode.substring(0, 1) === '0') {\n    // octal string\n    return parseInt(mode, 8) & 0xFFF\n  }\n\n  // decimal string\n  return parseInt(mode, 10) & 0xFFF\n}\n\n/**\n * @param {any} input\n */\nfunction parseMtime (input) {\n  if (input == null) {\n    return undefined\n  }\n\n  /** @type {Mtime | undefined} */\n  let mtime\n\n  // { secs, nsecs }\n  if (input.secs != null) {\n    mtime = {\n      secs: input.secs,\n      nsecs: input.nsecs\n    }\n  }\n\n  // UnixFS TimeSpec\n  if (input.Seconds != null) {\n    mtime = {\n      secs: input.Seconds,\n      nsecs: input.FractionalNanoseconds\n    }\n  }\n\n  // process.hrtime()\n  if (Array.isArray(input)) {\n    mtime = {\n      secs: input[0],\n      nsecs: input[1]\n    }\n  }\n\n  // Javascript Date\n  if (input instanceof Date) {\n    const ms = input.getTime()\n    const secs = Math.floor(ms / 1000)\n\n    mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n  }\n\n  /*\n  TODO: https://github.com/ipfs/aegir/issues/487\n\n  // process.hrtime.bigint()\n  if (input instanceof BigInt) {\n    const secs = input / BigInt(1e9)\n    const nsecs = input - (secs * BigInt(1e9))\n\n    mtime = {\n      secs: parseInt(secs.toString()),\n      nsecs: parseInt(nsecs.toString())\n    }\n  }\n  */\n\n  if (!Object.prototype.hasOwnProperty.call(mtime, 'secs')) {\n    return undefined\n  }\n\n  if (mtime != null && mtime.nsecs != null && (mtime.nsecs < 0 || mtime.nsecs > 999999999)) {\n    throw errcode(new Error('mtime-nsecs must be within the range [0,999999999]'), 'ERR_INVALID_MTIME_NSECS')\n  }\n\n  return mtime\n}\n\nclass Data {\n  /**\n   * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md\n   *\n   * @param {Uint8Array} marshaled\n   */\n  static unmarshal (marshaled) {\n    const message = PBData.decode(marshaled)\n    const decoded = PBData.toObject(message, {\n      defaults: false,\n      arrays: true,\n      longs: Number,\n      objects: false\n    })\n\n    const data = new Data({\n      type: types[decoded.Type],\n      data: decoded.Data,\n      blockSizes: decoded.blocksizes,\n      mode: decoded.mode,\n      mtime: decoded.mtime\n        ? {\n            secs: decoded.mtime.Seconds,\n            nsecs: decoded.mtime.FractionalNanoseconds\n          }\n        : undefined\n    })\n\n    // make sure we honour the original mode\n    data._originalMode = decoded.mode || 0\n\n    return data\n  }\n\n  /**\n   * @param {object} [options]\n   * @param {string} [options.type='file']\n   * @param {Uint8Array} [options.data]\n   * @param {number[]} [options.blockSizes]\n   * @param {number} [options.hashType]\n   * @param {number} [options.fanout]\n   * @param {MtimeLike | null} [options.mtime]\n   * @param {number | string} [options.mode]\n   */\n  constructor (options = {\n    type: 'file'\n  }) {\n    const {\n      type,\n      data,\n      blockSizes,\n      hashType,\n      fanout,\n      mtime,\n      mode\n    } = options\n\n    if (type && !types.includes(type)) {\n      throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    this.type = type || 'file'\n    this.data = data\n    this.hashType = hashType\n    this.fanout = fanout\n\n    /** @type {number[]} */\n    this.blockSizes = blockSizes || []\n    this._originalMode = 0\n    this.mode = parseMode(mode)\n\n    if (mtime) {\n      this.mtime = parseMtime(mtime)\n\n      if (this.mtime && !this.mtime.nsecs) {\n        this.mtime.nsecs = 0\n      }\n    }\n  }\n\n  /**\n   * @param {number | undefined} mode\n   */\n  set mode (mode) {\n    this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE\n\n    const parsedMode = parseMode(mode)\n\n    if (parsedMode !== undefined) {\n      this._mode = parsedMode\n    }\n  }\n\n  /**\n   * @returns {number | undefined}\n   */\n  get mode () {\n    return this._mode\n  }\n\n  isDirectory () {\n    return Boolean(this.type && dirTypes.includes(this.type))\n  }\n\n  /**\n   * @param {number} size\n   */\n  addBlockSize (size) {\n    this.blockSizes.push(size)\n  }\n\n  /**\n   * @param {number} index\n   */\n  removeBlockSize (index) {\n    this.blockSizes.splice(index, 1)\n  }\n\n  /**\n   * Returns `0` for directories or `data.length + sum(blockSizes)` for everything else\n   */\n  fileSize () {\n    if (this.isDirectory()) {\n      // dirs don't have file size\n      return 0\n    }\n\n    let sum = 0\n    this.blockSizes.forEach((size) => {\n      sum += size\n    })\n\n    if (this.data) {\n      sum += this.data.length\n    }\n\n    return sum\n  }\n\n  /**\n   * encode to protobuf Uint8Array\n   */\n  marshal () {\n    let type\n\n    switch (this.type) {\n      case 'raw': type = PBData.DataType.Raw; break\n      case 'directory': type = PBData.DataType.Directory; break\n      case 'file': type = PBData.DataType.File; break\n      case 'metadata': type = PBData.DataType.Metadata; break\n      case 'symlink': type = PBData.DataType.Symlink; break\n      case 'hamt-sharded-directory': type = PBData.DataType.HAMTShard; break\n      default:\n        throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    let data = this.data\n\n    if (!this.data || !this.data.length) {\n      data = undefined\n    }\n\n    let mode\n\n    if (this.mode != null) {\n      mode = (this._originalMode & 0xFFFFF000) | (parseMode(this.mode) || 0)\n\n      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {\n        mode = undefined\n      }\n\n      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {\n        mode = undefined\n      }\n    }\n\n    let mtime\n\n    if (this.mtime != null) {\n      const parsed = parseMtime(this.mtime)\n\n      if (parsed) {\n        mtime = {\n          Seconds: parsed.secs,\n          FractionalNanoseconds: parsed.nsecs\n        }\n\n        if (mtime.FractionalNanoseconds === 0) {\n          delete mtime.FractionalNanoseconds\n        }\n      }\n    }\n\n    const pbData = {\n      Type: type,\n      Data: data,\n      filesize: this.isDirectory() ? undefined : this.fileSize(),\n      blocksizes: this.blockSizes,\n      hashType: this.hashType,\n      fanout: this.fanout,\n      mode,\n      mtime\n    }\n\n    return PBData.encode(pbData).finish()\n  }\n}\n\nmodule.exports = {\n  UnixFS: Data,\n  parseMode,\n  parseMtime\n}\n","/*eslint-disable*/\n\"use strict\";\n\nvar $protobuf = require(\"protobufjs/minimal\");\n\n// Common aliases\nvar $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;\n\n// Exported root namespace\nvar $root = $protobuf.roots[\"ipfs-unixfs\"] || ($protobuf.roots[\"ipfs-unixfs\"] = {});\n\n$root.Data = (function() {\n\n    /**\n     * Properties of a Data.\n     * @exports IData\n     * @interface IData\n     * @property {Data.DataType} Type Data Type\n     * @property {Uint8Array|null} [Data] Data Data\n     * @property {number|null} [filesize] Data filesize\n     * @property {Array.<number>|null} [blocksizes] Data blocksizes\n     * @property {number|null} [hashType] Data hashType\n     * @property {number|null} [fanout] Data fanout\n     * @property {number|null} [mode] Data mode\n     * @property {IUnixTime|null} [mtime] Data mtime\n     */\n\n    /**\n     * Constructs a new Data.\n     * @exports Data\n     * @classdesc Represents a Data.\n     * @implements IData\n     * @constructor\n     * @param {IData=} [p] Properties to set\n     */\n    function Data(p) {\n        this.blocksizes = [];\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Data Type.\n     * @member {Data.DataType} Type\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Type = 0;\n\n    /**\n     * Data Data.\n     * @member {Uint8Array} Data\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Data = $util.newBuffer([]);\n\n    /**\n     * Data filesize.\n     * @member {number} filesize\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.filesize = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data blocksizes.\n     * @member {Array.<number>} blocksizes\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.blocksizes = $util.emptyArray;\n\n    /**\n     * Data hashType.\n     * @member {number} hashType\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.hashType = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data fanout.\n     * @member {number} fanout\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.fanout = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data mode.\n     * @member {number} mode\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mode = 0;\n\n    /**\n     * Data mtime.\n     * @member {IUnixTime|null|undefined} mtime\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mtime = null;\n\n    /**\n     * Encodes the specified Data message. Does not implicitly {@link Data.verify|verify} messages.\n     * @function encode\n     * @memberof Data\n     * @static\n     * @param {IData} m Data message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Data.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int32(m.Type);\n        if (m.Data != null && Object.hasOwnProperty.call(m, \"Data\"))\n            w.uint32(18).bytes(m.Data);\n        if (m.filesize != null && Object.hasOwnProperty.call(m, \"filesize\"))\n            w.uint32(24).uint64(m.filesize);\n        if (m.blocksizes != null && m.blocksizes.length) {\n            for (var i = 0; i < m.blocksizes.length; ++i)\n                w.uint32(32).uint64(m.blocksizes[i]);\n        }\n        if (m.hashType != null && Object.hasOwnProperty.call(m, \"hashType\"))\n            w.uint32(40).uint64(m.hashType);\n        if (m.fanout != null && Object.hasOwnProperty.call(m, \"fanout\"))\n            w.uint32(48).uint64(m.fanout);\n        if (m.mode != null && Object.hasOwnProperty.call(m, \"mode\"))\n            w.uint32(56).uint32(m.mode);\n        if (m.mtime != null && Object.hasOwnProperty.call(m, \"mtime\"))\n            $root.UnixTime.encode(m.mtime, w.uint32(66).fork()).ldelim();\n        return w;\n    };\n\n    /**\n     * Decodes a Data message from the specified reader or buffer.\n     * @function decode\n     * @memberof Data\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Data} Data\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Data.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Data();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Type = r.int32();\n                break;\n            case 2:\n                m.Data = r.bytes();\n                break;\n            case 3:\n                m.filesize = r.uint64();\n                break;\n            case 4:\n                if (!(m.blocksizes && m.blocksizes.length))\n                    m.blocksizes = [];\n                if ((t & 7) === 2) {\n                    var c2 = r.uint32() + r.pos;\n                    while (r.pos < c2)\n                        m.blocksizes.push(r.uint64());\n                } else\n                    m.blocksizes.push(r.uint64());\n                break;\n            case 5:\n                m.hashType = r.uint64();\n                break;\n            case 6:\n                m.fanout = r.uint64();\n                break;\n            case 7:\n                m.mode = r.uint32();\n                break;\n            case 8:\n                m.mtime = $root.UnixTime.decode(r, r.uint32());\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Type\"))\n            throw $util.ProtocolError(\"missing required 'Type'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates a Data message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Data\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Data} Data\n     */\n    Data.fromObject = function fromObject(d) {\n        if (d instanceof $root.Data)\n            return d;\n        var m = new $root.Data();\n        switch (d.Type) {\n        case \"Raw\":\n        case 0:\n            m.Type = 0;\n            break;\n        case \"Directory\":\n        case 1:\n            m.Type = 1;\n            break;\n        case \"File\":\n        case 2:\n            m.Type = 2;\n            break;\n        case \"Metadata\":\n        case 3:\n            m.Type = 3;\n            break;\n        case \"Symlink\":\n        case 4:\n            m.Type = 4;\n            break;\n        case \"HAMTShard\":\n        case 5:\n            m.Type = 5;\n            break;\n        }\n        if (d.Data != null) {\n            if (typeof d.Data === \"string\")\n                $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);\n            else if (d.Data.length)\n                m.Data = d.Data;\n        }\n        if (d.filesize != null) {\n            if ($util.Long)\n                (m.filesize = $util.Long.fromValue(d.filesize)).unsigned = true;\n            else if (typeof d.filesize === \"string\")\n                m.filesize = parseInt(d.filesize, 10);\n            else if (typeof d.filesize === \"number\")\n                m.filesize = d.filesize;\n            else if (typeof d.filesize === \"object\")\n                m.filesize = new $util.LongBits(d.filesize.low >>> 0, d.filesize.high >>> 0).toNumber(true);\n        }\n        if (d.blocksizes) {\n            if (!Array.isArray(d.blocksizes))\n                throw TypeError(\".Data.blocksizes: array expected\");\n            m.blocksizes = [];\n            for (var i = 0; i < d.blocksizes.length; ++i) {\n                if ($util.Long)\n                    (m.blocksizes[i] = $util.Long.fromValue(d.blocksizes[i])).unsigned = true;\n                else if (typeof d.blocksizes[i] === \"string\")\n                    m.blocksizes[i] = parseInt(d.blocksizes[i], 10);\n                else if (typeof d.blocksizes[i] === \"number\")\n                    m.blocksizes[i] = d.blocksizes[i];\n                else if (typeof d.blocksizes[i] === \"object\")\n                    m.blocksizes[i] = new $util.LongBits(d.blocksizes[i].low >>> 0, d.blocksizes[i].high >>> 0).toNumber(true);\n            }\n        }\n        if (d.hashType != null) {\n            if ($util.Long)\n                (m.hashType = $util.Long.fromValue(d.hashType)).unsigned = true;\n            else if (typeof d.hashType === \"string\")\n                m.hashType = parseInt(d.hashType, 10);\n            else if (typeof d.hashType === \"number\")\n                m.hashType = d.hashType;\n            else if (typeof d.hashType === \"object\")\n                m.hashType = new $util.LongBits(d.hashType.low >>> 0, d.hashType.high >>> 0).toNumber(true);\n        }\n        if (d.fanout != null) {\n            if ($util.Long)\n                (m.fanout = $util.Long.fromValue(d.fanout)).unsigned = true;\n            else if (typeof d.fanout === \"string\")\n                m.fanout = parseInt(d.fanout, 10);\n            else if (typeof d.fanout === \"number\")\n                m.fanout = d.fanout;\n            else if (typeof d.fanout === \"object\")\n                m.fanout = new $util.LongBits(d.fanout.low >>> 0, d.fanout.high >>> 0).toNumber(true);\n        }\n        if (d.mode != null) {\n            m.mode = d.mode >>> 0;\n        }\n        if (d.mtime != null) {\n            if (typeof d.mtime !== \"object\")\n                throw TypeError(\".Data.mtime: object expected\");\n            m.mtime = $root.UnixTime.fromObject(d.mtime);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Data message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Data\n     * @static\n     * @param {Data} m Data\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Data.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.arrays || o.defaults) {\n            d.blocksizes = [];\n        }\n        if (o.defaults) {\n            d.Type = o.enums === String ? \"Raw\" : 0;\n            if (o.bytes === String)\n                d.Data = \"\";\n            else {\n                d.Data = [];\n                if (o.bytes !== Array)\n                    d.Data = $util.newBuffer(d.Data);\n            }\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.filesize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.filesize = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.hashType = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.hashType = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.fanout = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.fanout = o.longs === String ? \"0\" : 0;\n            d.mode = 0;\n            d.mtime = null;\n        }\n        if (m.Type != null && m.hasOwnProperty(\"Type\")) {\n            d.Type = o.enums === String ? $root.Data.DataType[m.Type] : m.Type;\n        }\n        if (m.Data != null && m.hasOwnProperty(\"Data\")) {\n            d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;\n        }\n        if (m.filesize != null && m.hasOwnProperty(\"filesize\")) {\n            if (typeof m.filesize === \"number\")\n                d.filesize = o.longs === String ? String(m.filesize) : m.filesize;\n            else\n                d.filesize = o.longs === String ? $util.Long.prototype.toString.call(m.filesize) : o.longs === Number ? new $util.LongBits(m.filesize.low >>> 0, m.filesize.high >>> 0).toNumber(true) : m.filesize;\n        }\n        if (m.blocksizes && m.blocksizes.length) {\n            d.blocksizes = [];\n            for (var j = 0; j < m.blocksizes.length; ++j) {\n                if (typeof m.blocksizes[j] === \"number\")\n                    d.blocksizes[j] = o.longs === String ? String(m.blocksizes[j]) : m.blocksizes[j];\n                else\n                    d.blocksizes[j] = o.longs === String ? $util.Long.prototype.toString.call(m.blocksizes[j]) : o.longs === Number ? new $util.LongBits(m.blocksizes[j].low >>> 0, m.blocksizes[j].high >>> 0).toNumber(true) : m.blocksizes[j];\n            }\n        }\n        if (m.hashType != null && m.hasOwnProperty(\"hashType\")) {\n            if (typeof m.hashType === \"number\")\n                d.hashType = o.longs === String ? String(m.hashType) : m.hashType;\n            else\n                d.hashType = o.longs === String ? $util.Long.prototype.toString.call(m.hashType) : o.longs === Number ? new $util.LongBits(m.hashType.low >>> 0, m.hashType.high >>> 0).toNumber(true) : m.hashType;\n        }\n        if (m.fanout != null && m.hasOwnProperty(\"fanout\")) {\n            if (typeof m.fanout === \"number\")\n                d.fanout = o.longs === String ? String(m.fanout) : m.fanout;\n            else\n                d.fanout = o.longs === String ? $util.Long.prototype.toString.call(m.fanout) : o.longs === Number ? new $util.LongBits(m.fanout.low >>> 0, m.fanout.high >>> 0).toNumber(true) : m.fanout;\n        }\n        if (m.mode != null && m.hasOwnProperty(\"mode\")) {\n            d.mode = m.mode;\n        }\n        if (m.mtime != null && m.hasOwnProperty(\"mtime\")) {\n            d.mtime = $root.UnixTime.toObject(m.mtime, o);\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Data to JSON.\n     * @function toJSON\n     * @memberof Data\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Data.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    /**\n     * DataType enum.\n     * @name Data.DataType\n     * @enum {number}\n     * @property {number} Raw=0 Raw value\n     * @property {number} Directory=1 Directory value\n     * @property {number} File=2 File value\n     * @property {number} Metadata=3 Metadata value\n     * @property {number} Symlink=4 Symlink value\n     * @property {number} HAMTShard=5 HAMTShard value\n     */\n    Data.DataType = (function() {\n        var valuesById = {}, values = Object.create(valuesById);\n        values[valuesById[0] = \"Raw\"] = 0;\n        values[valuesById[1] = \"Directory\"] = 1;\n        values[valuesById[2] = \"File\"] = 2;\n        values[valuesById[3] = \"Metadata\"] = 3;\n        values[valuesById[4] = \"Symlink\"] = 4;\n        values[valuesById[5] = \"HAMTShard\"] = 5;\n        return values;\n    })();\n\n    return Data;\n})();\n\n$root.UnixTime = (function() {\n\n    /**\n     * Properties of an UnixTime.\n     * @exports IUnixTime\n     * @interface IUnixTime\n     * @property {number} Seconds UnixTime Seconds\n     * @property {number|null} [FractionalNanoseconds] UnixTime FractionalNanoseconds\n     */\n\n    /**\n     * Constructs a new UnixTime.\n     * @exports UnixTime\n     * @classdesc Represents an UnixTime.\n     * @implements IUnixTime\n     * @constructor\n     * @param {IUnixTime=} [p] Properties to set\n     */\n    function UnixTime(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * UnixTime Seconds.\n     * @member {number} Seconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.Seconds = $util.Long ? $util.Long.fromBits(0,0,false) : 0;\n\n    /**\n     * UnixTime FractionalNanoseconds.\n     * @member {number} FractionalNanoseconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.FractionalNanoseconds = 0;\n\n    /**\n     * Encodes the specified UnixTime message. Does not implicitly {@link UnixTime.verify|verify} messages.\n     * @function encode\n     * @memberof UnixTime\n     * @static\n     * @param {IUnixTime} m UnixTime message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    UnixTime.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int64(m.Seconds);\n        if (m.FractionalNanoseconds != null && Object.hasOwnProperty.call(m, \"FractionalNanoseconds\"))\n            w.uint32(21).fixed32(m.FractionalNanoseconds);\n        return w;\n    };\n\n    /**\n     * Decodes an UnixTime message from the specified reader or buffer.\n     * @function decode\n     * @memberof UnixTime\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {UnixTime} UnixTime\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    UnixTime.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.UnixTime();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Seconds = r.int64();\n                break;\n            case 2:\n                m.FractionalNanoseconds = r.fixed32();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Seconds\"))\n            throw $util.ProtocolError(\"missing required 'Seconds'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates an UnixTime message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof UnixTime\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {UnixTime} UnixTime\n     */\n    UnixTime.fromObject = function fromObject(d) {\n        if (d instanceof $root.UnixTime)\n            return d;\n        var m = new $root.UnixTime();\n        if (d.Seconds != null) {\n            if ($util.Long)\n                (m.Seconds = $util.Long.fromValue(d.Seconds)).unsigned = false;\n            else if (typeof d.Seconds === \"string\")\n                m.Seconds = parseInt(d.Seconds, 10);\n            else if (typeof d.Seconds === \"number\")\n                m.Seconds = d.Seconds;\n            else if (typeof d.Seconds === \"object\")\n                m.Seconds = new $util.LongBits(d.Seconds.low >>> 0, d.Seconds.high >>> 0).toNumber();\n        }\n        if (d.FractionalNanoseconds != null) {\n            m.FractionalNanoseconds = d.FractionalNanoseconds >>> 0;\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from an UnixTime message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof UnixTime\n     * @static\n     * @param {UnixTime} m UnixTime\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    UnixTime.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, false);\n                d.Seconds = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.Seconds = o.longs === String ? \"0\" : 0;\n            d.FractionalNanoseconds = 0;\n        }\n        if (m.Seconds != null && m.hasOwnProperty(\"Seconds\")) {\n            if (typeof m.Seconds === \"number\")\n                d.Seconds = o.longs === String ? String(m.Seconds) : m.Seconds;\n            else\n                d.Seconds = o.longs === String ? $util.Long.prototype.toString.call(m.Seconds) : o.longs === Number ? new $util.LongBits(m.Seconds.low >>> 0, m.Seconds.high >>> 0).toNumber() : m.Seconds;\n        }\n        if (m.FractionalNanoseconds != null && m.hasOwnProperty(\"FractionalNanoseconds\")) {\n            d.FractionalNanoseconds = m.FractionalNanoseconds;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this UnixTime to JSON.\n     * @function toJSON\n     * @memberof UnixTime\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    UnixTime.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return UnixTime;\n})();\n\n$root.Metadata = (function() {\n\n    /**\n     * Properties of a Metadata.\n     * @exports IMetadata\n     * @interface IMetadata\n     * @property {string|null} [MimeType] Metadata MimeType\n     */\n\n    /**\n     * Constructs a new Metadata.\n     * @exports Metadata\n     * @classdesc Represents a Metadata.\n     * @implements IMetadata\n     * @constructor\n     * @param {IMetadata=} [p] Properties to set\n     */\n    function Metadata(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Metadata MimeType.\n     * @member {string} MimeType\n     * @memberof Metadata\n     * @instance\n     */\n    Metadata.prototype.MimeType = \"\";\n\n    /**\n     * Encodes the specified Metadata message. Does not implicitly {@link Metadata.verify|verify} messages.\n     * @function encode\n     * @memberof Metadata\n     * @static\n     * @param {IMetadata} m Metadata message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Metadata.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        if (m.MimeType != null && Object.hasOwnProperty.call(m, \"MimeType\"))\n            w.uint32(10).string(m.MimeType);\n        return w;\n    };\n\n    /**\n     * Decodes a Metadata message from the specified reader or buffer.\n     * @function decode\n     * @memberof Metadata\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Metadata} Metadata\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Metadata.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Metadata();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.MimeType = r.string();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        return m;\n    };\n\n    /**\n     * Creates a Metadata message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Metadata\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Metadata} Metadata\n     */\n    Metadata.fromObject = function fromObject(d) {\n        if (d instanceof $root.Metadata)\n            return d;\n        var m = new $root.Metadata();\n        if (d.MimeType != null) {\n            m.MimeType = String(d.MimeType);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Metadata message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Metadata\n     * @static\n     * @param {Metadata} m Metadata\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Metadata.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            d.MimeType = \"\";\n        }\n        if (m.MimeType != null && m.hasOwnProperty(\"MimeType\")) {\n            d.MimeType = m.MimeType;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Metadata to JSON.\n     * @function toJSON\n     * @memberof Metadata\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Metadata.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return Metadata;\n})();\n\nmodule.exports = $root;\n","'use strict';\n\nmodule.exports = value => {\n\tif (Object.prototype.toString.call(value) !== '[object Object]') {\n\t\treturn false;\n\t}\n\n\tconst prototype = Object.getPrototypeOf(value);\n\treturn prototype === null || prototype === Object.prototype;\n};\n","'use strict'\n\n/**\n * Collects all values from an (async) iterable into an array and returns it.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n */\nconst all = async (source) => {\n  const arr = []\n\n  for await (const entry of source) {\n    arr.push(entry)\n  }\n\n  return arr\n}\n\nmodule.exports = all\n","'use strict'\n\n/**\n * Takes an (async) iterable that emits things and returns an async iterable that\n * emits those things in fixed-sized batches.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @param {number} [size=1]\n * @returns {AsyncIterable<T[]>}\n */\nasync function * batch (source, size = 1) {\n  /** @type {T[]} */\n  let things = []\n\n  if (size < 1) {\n    size = 1\n  }\n\n  for await (const thing of source) {\n    things.push(thing)\n\n    while (things.length >= size) {\n      yield things.slice(0, size)\n\n      things = things.slice(size)\n    }\n  }\n\n  while (things.length) {\n    yield things.slice(0, size)\n\n    things = things.slice(size)\n  }\n}\n\nmodule.exports = batch\n","'use strict'\n\n/**\n * Drains an (async) iterable discarding its' content and does not return\n * anything.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @returns {Promise<void>}\n */\nconst drain = async (source) => {\n  for await (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty\n}\n\nmodule.exports = drain\n","'use strict'\n\n/**\n * Filters the passed (async) iterable by using the filter function\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @param {function(T):boolean|Promise<boolean>} fn\n */\nconst filter = async function * (source, fn) {\n  for await (const entry of source) {\n    if (await fn(entry)) {\n      yield entry\n    }\n  }\n}\n\nmodule.exports = filter\n","'use strict'\n\nconst fs = require('fs').promises\nconst path = require('path')\nconst minimatch = require('minimatch')\n\n/**\n * @typedef {string} Glob\n * @typedef {Object} OptionsExt\n * @property {Glob[]} [ignore] - Glob patterns to ignore\n * @property {string} [cwd=process.cwd()]\n * @property {boolean} [absolute=false] - If true produces absolute paths\n * @property {boolean} [nodir] - If true yields file paths and skip directories\n *\n * @typedef {OptionsExt & minimatch.IOptions} Options\n */\n\n/**\n * Async iterable filename pattern matcher\n *\n * @param {string} dir\n * @param {string} pattern\n * @param {Options} [options]\n * @returns {AsyncIterable<string>}\n */\nasync function * glob (dir, pattern, options = {}) {\n  const absoluteDir = path.resolve(dir)\n  const relativeDir = path.relative(options.cwd || process.cwd(), dir)\n\n  const stats = await fs.stat(absoluteDir)\n\n  if (stats.isDirectory()) {\n    for await (const entry of _glob(absoluteDir, '', pattern, options)) {\n      yield entry\n    }\n\n    return\n  }\n\n  if (minimatch(relativeDir, pattern, options)) {\n    yield options.absolute ? absoluteDir : relativeDir\n  }\n}\n\n/**\n * @param {string} base\n * @param {string} dir\n * @param {Glob} pattern\n * @param {Options} options\n * @returns {AsyncIterable<string>}\n */\nasync function * _glob (base, dir, pattern, options) {\n  for await (const entry of await fs.readdir(path.join(base, dir))) {\n    const relativeEntryPath = path.join(dir, entry)\n    const absoluteEntryPath = path.join(base, dir, entry)\n    const stats = await fs.stat(absoluteEntryPath)\n    let match = minimatch(relativeEntryPath, pattern, options)\n\n    if (options.ignore && match && options.ignore.reduce((acc, curr) => {\n      return acc || minimatch(relativeEntryPath, curr, options)\n    }, false)) {\n      match = false\n    }\n\n    if (match && !(stats.isDirectory() && options.nodir)) {\n      yield options.absolute ? absoluteEntryPath : relativeEntryPath\n    }\n\n    if (stats.isDirectory()) {\n      yield * _glob(base, relativeEntryPath, pattern, options)\n    }\n  }\n}\n\nmodule.exports = glob\n","'use strict'\n\n/**\n * Returns the last item of an (async) iterable, unless empty, in which case\n * return `undefined`.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n */\nconst last = async (source) => {\n  let res\n\n  for await (const entry of source) {\n    res = entry\n  }\n\n  return res\n}\n\nmodule.exports = last\n","'use strict'\n\n/**\n * Takes an (async) iterable and returns one with each item mapped by the passed\n * function.\n *\n * @template I,O\n * @param {AsyncIterable<I>|Iterable<I>} source\n * @param {function(I):O|Promise<O>} func\n * @returns {AsyncIterable<O>}\n */\nconst map = async function * (source, func) {\n  for await (const val of source) {\n    yield func(val)\n  }\n}\n\nmodule.exports = map\n","'use strict'\n\nconst batch = require('it-batch')\n\n/**\n * @template T\n * @typedef {{ok:true, value:T}} Success\n */\n\n/**\n * @typedef {{ok:false, err:Error}} Failure\n */\n\n/**\n * Takes an (async) iterator that emits promise-returning functions,\n * invokes them in parallel and emits the results as they become available but\n * in the same order as the input\n *\n * @template T\n * @param {AsyncIterable<() => Promise<T>>} source\n * @param {number} [size=1]\n * @returns {AsyncIterable<T>}\n */\nasync function * parallelBatch (source, size = 1) {\n  for await (const tasks of batch(source, size)) {\n    /** @type {Promise<Success<T>|Failure>[]} */\n    const things = tasks.map(\n      /**\n       * @param {() => Promise<T>} p\n       */\n      p => {\n        return p().then(value => ({ ok: true, value }), err => ({ ok: false, err }))\n      })\n\n    for (let i = 0; i < things.length; i++) {\n      const result = await things[i]\n\n      if (result.ok) {\n        yield result.value\n      } else {\n        throw result.err\n      }\n    }\n  }\n}\n\nmodule.exports = parallelBatch\n","'use strict'\n\n/**\n * @template T\n * @typedef {Object} Peek\n * @property {() => IteratorResult<T, void>} peek\n */\n\n/**\n * @template T\n * @typedef {Object} AsyncPeek\n * @property {() => Promise<IteratorResult<T, void>>} peek\n */\n\n/**\n * @template T\n * @typedef {Object} Push\n * @property {(value:T) => void} push\n */\n\n/**\n * @template T\n * @typedef {Iterable<T> & Peek<T> & Push<T> & Iterator<T>} Peekable<T>\n */\n\n/**\n * @template T\n * @typedef {AsyncIterable<T> & AsyncPeek<T> & Push<T> & AsyncIterator<T>} AsyncPeekable<T>\n */\n\n/**\n * @template {Iterable<any> | AsyncIterable<any>} I\n * @param {I} iterable\n * @returns {I extends Iterable<infer T>\n *  ? Peekable<T>\n *  : I extends AsyncIterable<infer T>\n *  ? AsyncPeekable<T>\n *  : never\n * }\n */\nfunction peekableIterator (iterable) {\n  // @ts-ignore\n  const [iterator, symbol] = iterable[Symbol.asyncIterator]\n    // @ts-ignore\n    ? [iterable[Symbol.asyncIterator](), Symbol.asyncIterator]\n    // @ts-ignore\n    : [iterable[Symbol.iterator](), Symbol.iterator]\n\n  /** @type {any[]} */\n  const queue = []\n\n  // @ts-ignore\n  return {\n    peek: () => {\n      return iterator.next()\n    },\n    push: (value) => {\n      queue.push(value)\n    },\n    next: () => {\n      if (queue.length) {\n        return {\n          done: false,\n          value: queue.shift()\n        }\n      }\n\n      return iterator.next()\n    },\n    [symbol] () {\n      return this\n    }\n  }\n}\n\nmodule.exports = peekableIterator\n","const rawPipe = (...fns) => {\n  let res\n  while (fns.length) {\n    res = fns.shift()(res)\n  }\n  return res\n}\n\nconst isIterable = obj => obj && (\n  typeof obj[Symbol.asyncIterator] === 'function' ||\n  typeof obj[Symbol.iterator] === 'function' ||\n  typeof obj.next === 'function' // Probably, right?\n)\n\nconst isDuplex = obj => obj && typeof obj.sink === 'function' && isIterable(obj.source)\n\nconst duplexPipelineFn = duplex => source => {\n  duplex.sink(source) // TODO: error on sink side is unhandled rejection - this is the same as pull streams\n  return duplex.source\n}\n\nconst pipe = (...fns) => {\n  // Duplex at start: wrap in function and return duplex source\n  if (isDuplex(fns[0])) {\n    const duplex = fns[0]\n    fns[0] = () => duplex.source\n  // Iterable at start: wrap in function\n  } else if (isIterable(fns[0])) {\n    const source = fns[0]\n    fns[0] = () => source\n  }\n\n  if (fns.length > 1) {\n    // Duplex at end: use duplex sink\n    if (isDuplex(fns[fns.length - 1])) {\n      fns[fns.length - 1] = fns[fns.length - 1].sink\n    }\n  }\n\n  if (fns.length > 2) {\n    // Duplex in the middle, consume source with duplex sink and return duplex source\n    for (let i = 1; i < fns.length - 1; i++) {\n      if (isDuplex(fns[i])) {\n        fns[i] = duplexPipelineFn(fns[i])\n      }\n    }\n  }\n\n  return rawPipe(...fns)\n}\n\nmodule.exports = pipe\nmodule.exports.pipe = pipe\nmodule.exports.rawPipe = rawPipe\nmodule.exports.isIterable = isIterable\nmodule.exports.isDuplex = isDuplex\n","'use strict'\n\n/**\n * Stop iteration after n items have been received.\n *\n * @template T\n * @param {AsyncIterable<T>|Iterable<T>} source\n * @param {number} limit\n * @returns {AsyncIterable<T>}\n */\nconst take = async function * (source, limit) {\n  let items = 0\n\n  if (limit < 1) {\n    return\n  }\n\n  for await (const entry of source) {\n    yield entry\n\n    items++\n\n    if (items === limit) {\n      return\n    }\n  }\n}\n\nmodule.exports = take\n","'use strict';\nconst isOptionObject = require('is-plain-obj');\n\nconst {hasOwnProperty} = Object.prototype;\nconst {propertyIsEnumerable} = Object;\nconst defineProperty = (object, name, value) => Object.defineProperty(object, name, {\n\tvalue,\n\twritable: true,\n\tenumerable: true,\n\tconfigurable: true\n});\n\nconst globalThis = this;\nconst defaultMergeOptions = {\n\tconcatArrays: false,\n\tignoreUndefined: false\n};\n\nconst getEnumerableOwnPropertyKeys = value => {\n\tconst keys = [];\n\n\tfor (const key in value) {\n\t\tif (hasOwnProperty.call(value, key)) {\n\t\t\tkeys.push(key);\n\t\t}\n\t}\n\n\t/* istanbul ignore else  */\n\tif (Object.getOwnPropertySymbols) {\n\t\tconst symbols = Object.getOwnPropertySymbols(value);\n\n\t\tfor (const symbol of symbols) {\n\t\t\tif (propertyIsEnumerable.call(value, symbol)) {\n\t\t\t\tkeys.push(symbol);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn keys;\n};\n\nfunction clone(value) {\n\tif (Array.isArray(value)) {\n\t\treturn cloneArray(value);\n\t}\n\n\tif (isOptionObject(value)) {\n\t\treturn cloneOptionObject(value);\n\t}\n\n\treturn value;\n}\n\nfunction cloneArray(array) {\n\tconst result = array.slice(0, 0);\n\n\tgetEnumerableOwnPropertyKeys(array).forEach(key => {\n\t\tdefineProperty(result, key, clone(array[key]));\n\t});\n\n\treturn result;\n}\n\nfunction cloneOptionObject(object) {\n\tconst result = Object.getPrototypeOf(object) === null ? Object.create(null) : {};\n\n\tgetEnumerableOwnPropertyKeys(object).forEach(key => {\n\t\tdefineProperty(result, key, clone(object[key]));\n\t});\n\n\treturn result;\n}\n\n/**\n * @param {*} merged already cloned\n * @param {*} source something to merge\n * @param {string[]} keys keys to merge\n * @param {Object} config Config Object\n * @returns {*} cloned Object\n */\nconst mergeKeys = (merged, source, keys, config) => {\n\tkeys.forEach(key => {\n\t\tif (typeof source[key] === 'undefined' && config.ignoreUndefined) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Do not recurse into prototype chain of merged\n\t\tif (key in merged && merged[key] !== Object.getPrototypeOf(merged)) {\n\t\t\tdefineProperty(merged, key, merge(merged[key], source[key], config));\n\t\t} else {\n\t\t\tdefineProperty(merged, key, clone(source[key]));\n\t\t}\n\t});\n\n\treturn merged;\n};\n\n/**\n * @param {*} merged already cloned\n * @param {*} source something to merge\n * @param {Object} config Config Object\n * @returns {*} cloned Object\n *\n * see [Array.prototype.concat ( ...arguments )](http://www.ecma-international.org/ecma-262/6.0/#sec-array.prototype.concat)\n */\nconst concatArrays = (merged, source, config) => {\n\tlet result = merged.slice(0, 0);\n\tlet resultIndex = 0;\n\n\t[merged, source].forEach(array => {\n\t\tconst indices = [];\n\n\t\t// `result.concat(array)` with cloning\n\t\tfor (let k = 0; k < array.length; k++) {\n\t\t\tif (!hasOwnProperty.call(array, k)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tindices.push(String(k));\n\n\t\t\tif (array === merged) {\n\t\t\t\t// Already cloned\n\t\t\t\tdefineProperty(result, resultIndex++, array[k]);\n\t\t\t} else {\n\t\t\t\tdefineProperty(result, resultIndex++, clone(array[k]));\n\t\t\t}\n\t\t}\n\n\t\t// Merge non-index keys\n\t\tresult = mergeKeys(result, array, getEnumerableOwnPropertyKeys(array).filter(key => !indices.includes(key)), config);\n\t});\n\n\treturn result;\n};\n\n/**\n * @param {*} merged already cloned\n * @param {*} source something to merge\n * @param {Object} config Config Object\n * @returns {*} cloned Object\n */\nfunction merge(merged, source, config) {\n\tif (config.concatArrays && Array.isArray(merged) && Array.isArray(source)) {\n\t\treturn concatArrays(merged, source, config);\n\t}\n\n\tif (!isOptionObject(source) || !isOptionObject(merged)) {\n\t\treturn clone(source);\n\t}\n\n\treturn mergeKeys(merged, source, getEnumerableOwnPropertyKeys(source), config);\n}\n\nmodule.exports = function (...options) {\n\tconst config = merge(clone(defaultMergeOptions), (this !== globalThis && this) || {}, defaultMergeOptions);\n\tlet merged = {_: {}};\n\n\tfor (const option of options) {\n\t\tif (option === undefined) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!isOptionObject(option)) {\n\t\t\tthrow new TypeError('`' + option + '` is not an Option Object');\n\t\t}\n\n\t\tmerged = merge(merged, {_: option}, config);\n\t}\n\n\treturn merged._;\n};\n","module.exports = minimatch\nminimatch.Minimatch = Minimatch\n\nvar path = { sep: '/' }\ntry {\n  path = require('path')\n} catch (er) {}\n\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}\nvar expand = require('brace-expansion')\n\nvar plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nvar qmark = '[^/]'\n\n// * => any number of characters\nvar star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// characters that need to be escaped in RegExp.\nvar reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// \"abc\" -> { a:true, b:true, c:true }\nfunction charSet (s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true\n    return set\n  }, {})\n}\n\n// normalizes slashes.\nvar slashSplit = /\\/+/\n\nminimatch.filter = filter\nfunction filter (pattern, options) {\n  options = options || {}\n  return function (p, i, list) {\n    return minimatch(p, pattern, options)\n  }\n}\n\nfunction ext (a, b) {\n  a = a || {}\n  b = b || {}\n  var t = {}\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k]\n  })\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k]\n  })\n  return t\n}\n\nminimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return minimatch\n\n  var orig = minimatch\n\n  var m = function minimatch (p, pattern, options) {\n    return orig.minimatch(p, pattern, ext(def, options))\n  }\n\n  m.Minimatch = function Minimatch (pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options))\n  }\n\n  return m\n}\n\nMinimatch.defaults = function (def) {\n  if (!def || !Object.keys(def).length) return Minimatch\n  return minimatch.defaults(def).Minimatch\n}\n\nfunction minimatch (p, pattern, options) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  // \"\" only matches \"\"\n  if (pattern.trim() === '') return p === ''\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nfunction Minimatch (pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options)\n  }\n\n  if (typeof pattern !== 'string') {\n    throw new TypeError('glob pattern string required')\n  }\n\n  if (!options) options = {}\n  pattern = pattern.trim()\n\n  // windows support: need to use /, not \\\n  if (path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/')\n  }\n\n  this.options = options\n  this.set = []\n  this.pattern = pattern\n  this.regexp = null\n  this.negate = false\n  this.comment = false\n  this.empty = false\n\n  // make the set of regexps etc.\n  this.make()\n}\n\nMinimatch.prototype.debug = function () {}\n\nMinimatch.prototype.make = make\nfunction make () {\n  // don't do it more than once.\n  if (this._made) return\n\n  var pattern = this.pattern\n  var options = this.options\n\n  // empty patterns and comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true\n    return\n  }\n  if (!pattern) {\n    this.empty = true\n    return\n  }\n\n  // step 1: figure out negation, etc.\n  this.parseNegate()\n\n  // step 2: expand braces\n  var set = this.globSet = this.braceExpand()\n\n  if (options.debug) this.debug = console.error\n\n  this.debug(this.pattern, set)\n\n  // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit)\n  })\n\n  this.debug(this.pattern, set)\n\n  // glob --> regexps\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this)\n  }, this)\n\n  this.debug(this.pattern, set)\n\n  // filter out everything that didn't compile properly.\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1\n  })\n\n  this.debug(this.pattern, set)\n\n  this.set = set\n}\n\nMinimatch.prototype.parseNegate = parseNegate\nfunction parseNegate () {\n  var pattern = this.pattern\n  var negate = false\n  var options = this.options\n  var negateOffset = 0\n\n  if (options.nonegate) return\n\n  for (var i = 0, l = pattern.length\n    ; i < l && pattern.charAt(i) === '!'\n    ; i++) {\n    negate = !negate\n    negateOffset++\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset)\n  this.negate = negate\n}\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options)\n}\n\nMinimatch.prototype.braceExpand = braceExpand\n\nfunction braceExpand (pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options\n    } else {\n      options = {}\n    }\n  }\n\n  pattern = typeof pattern === 'undefined'\n    ? this.pattern : pattern\n\n  if (typeof pattern === 'undefined') {\n    throw new TypeError('undefined pattern')\n  }\n\n  if (options.nobrace ||\n    !pattern.match(/\\{.*\\}/)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nMinimatch.prototype.parse = parse\nvar SUBPARSE = {}\nfunction parse (pattern, isSub) {\n  if (pattern.length > 1024 * 64) {\n    throw new TypeError('pattern is too long')\n  }\n\n  var options = this.options\n\n  // shortcuts\n  if (!options.noglobstar && pattern === '**') return GLOBSTAR\n  if (pattern === '') return ''\n\n  var re = ''\n  var hasMagic = !!options.nocase\n  var escaping = false\n  // ? => one single character\n  var patternListStack = []\n  var negativeLists = []\n  var stateChar\n  var inClass = false\n  var reClassStart = -1\n  var classStart = -1\n  // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n  : '(?!\\\\.)'\n  var self = this\n\n  function clearStateChar () {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star\n          hasMagic = true\n        break\n        case '?':\n          re += qmark\n          hasMagic = true\n        break\n        default:\n          re += '\\\\' + stateChar\n        break\n      }\n      self.debug('clearStateChar %j %j', stateChar, re)\n      stateChar = false\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c\n    ; (i < len) && (c = pattern.charAt(i))\n    ; i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n    // skip over any that are escaped.\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c\n      escaping = false\n      continue\n    }\n\n    switch (c) {\n      case '/':\n        // completely not allowed, even escaped.\n        // Should already be path-split by now.\n        return false\n\n      case '\\\\':\n        clearStateChar()\n        escaping = true\n      continue\n\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n        // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n        if (inClass) {\n          this.debug('  in class')\n          if (c === '!' && i === classStart + 1) c = '^'\n          re += c\n          continue\n        }\n\n        // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n        self.debug('call clearStateChar %j', stateChar)\n        clearStateChar()\n        stateChar = c\n        // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n        if (options.noext) clearStateChar()\n      continue\n\n      case '(':\n        if (inClass) {\n          re += '('\n          continue\n        }\n\n        if (!stateChar) {\n          re += '\\\\('\n          continue\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        })\n        // negation is (?:(?!js)[^/]*)\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'\n        this.debug('plType %j %j', stateChar, re)\n        stateChar = false\n      continue\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)'\n          continue\n        }\n\n        clearStateChar()\n        hasMagic = true\n        var pl = patternListStack.pop()\n        // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n        re += pl.close\n        if (pl.type === '!') {\n          negativeLists.push(pl)\n        }\n        pl.reEnd = re.length\n      continue\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|'\n          escaping = false\n          continue\n        }\n\n        clearStateChar()\n        re += '|'\n      continue\n\n      // these are mostly the same in regexp and glob\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar()\n\n        if (inClass) {\n          re += '\\\\' + c\n          continue\n        }\n\n        inClass = true\n        classStart = i\n        reClassStart = re.length\n        re += c\n      continue\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c\n          escaping = false\n          continue\n        }\n\n        // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        if (inClass) {\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          var cs = pattern.substring(classStart + 1, i)\n          try {\n            RegExp('[' + cs + ']')\n          } catch (er) {\n            // not a valid class!\n            var sp = this.parse(cs, SUBPARSE)\n            re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]'\n            hasMagic = hasMagic || sp[1]\n            inClass = false\n            continue\n          }\n        }\n\n        // finish up the class.\n        hasMagic = true\n        inClass = false\n        re += c\n      continue\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar()\n\n        if (escaping) {\n          // no need\n          escaping = false\n        } else if (reSpecials[c]\n          && !(c === '^' && inClass)) {\n          re += '\\\\'\n        }\n\n        re += c\n\n    } // switch\n  } // for\n\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1)\n    sp = this.parse(cs, SUBPARSE)\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0]\n    hasMagic = hasMagic || sp[1]\n  }\n\n  // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length)\n    this.debug('setting tail', re, pl)\n    // maybe some even number of \\, then maybe 1 \\, followed by a |\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\'\n      }\n\n      // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n      return $1 + $1 + $2 + '|'\n    })\n\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n    var t = pl.type === '*' ? star\n      : pl.type === '?' ? qmark\n      : '\\\\' + pl.type\n\n    hasMagic = true\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n  }\n\n  // handle trailing things that only matter at the very end.\n  clearStateChar()\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\'\n  }\n\n  // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n  var addPatternStart = false\n  switch (re.charAt(0)) {\n    case '.':\n    case '[':\n    case '(': addPatternStart = true\n  }\n\n  // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n]\n\n    var nlBefore = re.slice(0, nl.reStart)\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)\n    var nlAfter = re.slice(nl.reEnd)\n\n    nlLast += nlAfter\n\n    // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n    var openParensBefore = nlBefore.split('(').length - 1\n    var cleanAfter = nlAfter\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n    }\n    nlAfter = cleanAfter\n\n    var dollar = ''\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$'\n    }\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    re = newRe\n  }\n\n  // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re\n  }\n\n  // parsing just a piece of a larger pattern.\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic]\n  }\n\n  // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n  if (!hasMagic) {\n    return globUnescape(pattern)\n  }\n\n  var flags = options.nocase ? 'i' : ''\n  try {\n    var regExp = new RegExp('^' + re + '$', flags)\n  } catch (er) {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.')\n  }\n\n  regExp._glob = pattern\n  regExp._src = re\n\n  return regExp\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe()\n}\n\nMinimatch.prototype.makeRe = makeRe\nfunction makeRe () {\n  if (this.regexp || this.regexp === false) return this.regexp\n\n  // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n  var set = this.set\n\n  if (!set.length) {\n    this.regexp = false\n    return this.regexp\n  }\n  var options = this.options\n\n  var twoStar = options.noglobstar ? star\n    : options.dot ? twoStarDot\n    : twoStarNoDot\n  var flags = options.nocase ? 'i' : ''\n\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return (p === GLOBSTAR) ? twoStar\n      : (typeof p === 'string') ? regExpEscape(p)\n      : p._src\n    }).join('\\\\\\/')\n  }).join('|')\n\n  // must match entire pattern\n  // ending in a * or ** will make it less strict.\n  re = '^(?:' + re + ')$'\n\n  // can match anything, as long as it's not this.\n  if (this.negate) re = '^(?!' + re + ').*$'\n\n  try {\n    this.regexp = new RegExp(re, flags)\n  } catch (ex) {\n    this.regexp = false\n  }\n  return this.regexp\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {}\n  var mm = new Minimatch(pattern, options)\n  list = list.filter(function (f) {\n    return mm.match(f)\n  })\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\nMinimatch.prototype.match = match\nfunction match (f, partial) {\n  this.debug('match', f, this.pattern)\n  // short-circuit in the case of busted things.\n  // comments, etc.\n  if (this.comment) return false\n  if (this.empty) return f === ''\n\n  if (f === '/' && partial) return true\n\n  var options = this.options\n\n  // windows: need to use /, not \\\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/')\n  }\n\n  // treat the test path as a set of pathparts.\n  f = f.split(slashSplit)\n  this.debug(this.pattern, 'split', f)\n\n  // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set\n  this.debug(this.pattern, 'set', set)\n\n  // Find the basename of the path by looking for the last non-empty segment\n  var filename\n  var i\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i]\n    if (filename) break\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i]\n    var file = f\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename]\n    }\n    var hit = this.matchOne(file, pattern, partial)\n    if (hit) {\n      if (options.flipNegate) return true\n      return !this.negate\n    }\n  }\n\n  // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n  if (options.flipNegate) return false\n  return this.negate\n}\n\n// set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options\n\n  this.debug('matchOne',\n    { 'this': this, file: file, pattern: pattern })\n\n  this.debug('matchOne', file.length, pattern.length)\n\n  for (var fi = 0,\n      pi = 0,\n      fl = file.length,\n      pl = pattern.length\n      ; (fi < fl) && (pi < pl)\n      ; fi++, pi++) {\n    this.debug('matchOne loop')\n    var p = pattern[pi]\n    var f = file[fi]\n\n    this.debug(pattern, p, f)\n\n    // should be impossible.\n    // some invalid regexp stuff in the set.\n    if (p === false) return false\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f])\n\n      // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n      var fr = fi\n      var pr = pi + 1\n      if (pr === pl) {\n        this.debug('** at the end')\n        // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' ||\n            (!options.dot && file[fi].charAt(0) === '.')) return false\n        }\n        return true\n      }\n\n      // ok, let's see if we can swallow whatever we can.\n      while (fr < fl) {\n        var swallowee = file[fr]\n\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n        // XXX remove this slice.  Just pass the start index.\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee)\n          // found a match.\n          return true\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' ||\n            (!options.dot && swallowee.charAt(0) === '.')) {\n            this.debug('dot detected!', file, fr, pattern, pr)\n            break\n          }\n\n          // ** swallows a segment, and continue.\n          this.debug('globstar swallow a segment, and continue')\n          fr++\n        }\n      }\n\n      // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n        if (fr === fl) return true\n      }\n      return false\n    }\n\n    // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n    var hit\n    if (typeof p === 'string') {\n      if (options.nocase) {\n        hit = f.toLowerCase() === p.toLowerCase()\n      } else {\n        hit = f === p\n      }\n      this.debug('string match', p, f, hit)\n    } else {\n      hit = f.match(p)\n      this.debug('pattern match', p, f, hit)\n    }\n\n    if (!hit) return false\n  }\n\n  // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n\n  // now either we fell off the end of the pattern, or we're done.\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial\n  } else if (pi === pl) {\n    // ran out of pattern, still have file left.\n    // this is only acceptable if we're on the very last\n    // empty segment of a file with a trailing slash.\n    // a/* should match a/b/\n    var emptyFileEnd = (fi === fl - 1) && (file[fi] === '')\n    return emptyFileEnd\n  }\n\n  // should be unreachable.\n  throw new Error('wtf?')\n}\n\n// replace stuff like \\* with *\nfunction globUnescape (s) {\n  return s.replace(/\\\\(.)/g, '$1')\n}\n\nfunction regExpEscape (s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar baseX$1 = require('../../vendor/base-x.js');\nvar bytes = require('../bytes.js');\n\nclass Encoder {\n  constructor(name, prefix, baseEncode) {\n    this.name = name;\n    this.prefix = prefix;\n    this.baseEncode = baseEncode;\n  }\n  encode(bytes) {\n    if (bytes instanceof Uint8Array) {\n      return `${ this.prefix }${ this.baseEncode(bytes) }`;\n    } else {\n      throw Error('Unknown type, must be binary type');\n    }\n  }\n}\nclass Decoder {\n  constructor(name, prefix, baseDecode) {\n    this.name = name;\n    this.prefix = prefix;\n    this.baseDecode = baseDecode;\n  }\n  decode(text) {\n    if (typeof text === 'string') {\n      switch (text[0]) {\n      case this.prefix: {\n          return this.baseDecode(text.slice(1));\n        }\n      default: {\n          throw Error(`Unable to decode multibase string ${ JSON.stringify(text) }, ${ this.name } decoder only supports inputs prefixed with ${ this.prefix }`);\n        }\n      }\n    } else {\n      throw Error('Can only multibase decode strings');\n    }\n  }\n  or(decoder) {\n    const decoders = {\n      [this.prefix]: this,\n      ...decoder.decoders || { [decoder.prefix]: decoder }\n    };\n    return new ComposedDecoder(decoders);\n  }\n}\nclass ComposedDecoder {\n  constructor(decoders) {\n    this.decoders = decoders;\n  }\n  or(decoder) {\n    const other = decoder.decoders || { [decoder.prefix]: decoder };\n    return new ComposedDecoder({\n      ...this.decoders,\n      ...other\n    });\n  }\n  decode(input) {\n    const prefix = input[0];\n    const decoder = this.decoders[prefix];\n    if (decoder) {\n      return decoder.decode(input);\n    } else {\n      throw RangeError(`Unable to decode multibase string ${ JSON.stringify(input) }, only inputs prefixed with ${ Object.keys(this.decoders) } are supported`);\n    }\n  }\n}\nclass Codec {\n  constructor(name, prefix, baseEncode, baseDecode) {\n    this.name = name;\n    this.prefix = prefix;\n    this.baseEncode = baseEncode;\n    this.baseDecode = baseDecode;\n    this.encoder = new Encoder(name, prefix, baseEncode);\n    this.decoder = new Decoder(name, prefix, baseDecode);\n  }\n  encode(input) {\n    return this.encoder.encode(input);\n  }\n  decode(input) {\n    return this.decoder.decode(input);\n  }\n}\nconst from = ({name, prefix, encode, decode}) => new Codec(name, prefix, encode, decode);\nconst baseX = ({prefix, name, alphabet}) => {\n  const {encode, decode} = baseX$1(alphabet, name);\n  return from({\n    prefix,\n    name,\n    encode,\n    decode: text => bytes.coerce(decode(text))\n  });\n};\nconst decode = (string, alphabet, bitsPerChar, name) => {\n  const codes = {};\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i;\n  }\n  let end = string.length;\n  while (string[end - 1] === '=') {\n    --end;\n  }\n  const out = new Uint8Array(end * bitsPerChar / 8 | 0);\n  let bits = 0;\n  let buffer = 0;\n  let written = 0;\n  for (let i = 0; i < end; ++i) {\n    const value = codes[string[i]];\n    if (value === undefined) {\n      throw new SyntaxError(`Non-${ name } character`);\n    }\n    buffer = buffer << bitsPerChar | value;\n    bits += bitsPerChar;\n    if (bits >= 8) {\n      bits -= 8;\n      out[written++] = 255 & buffer >> bits;\n    }\n  }\n  if (bits >= bitsPerChar || 255 & buffer << 8 - bits) {\n    throw new SyntaxError('Unexpected end of data');\n  }\n  return out;\n};\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '=';\n  const mask = (1 << bitsPerChar) - 1;\n  let out = '';\n  let bits = 0;\n  let buffer = 0;\n  for (let i = 0; i < data.length; ++i) {\n    buffer = buffer << 8 | data[i];\n    bits += 8;\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar;\n      out += alphabet[mask & buffer >> bits];\n    }\n  }\n  if (bits) {\n    out += alphabet[mask & buffer << bitsPerChar - bits];\n  }\n  if (pad) {\n    while (out.length * bitsPerChar & 7) {\n      out += '=';\n    }\n  }\n  return out;\n};\nconst rfc4648 = ({name, prefix, bitsPerChar, alphabet}) => {\n  return from({\n    prefix,\n    name,\n    encode(input) {\n      return encode(input, alphabet, bitsPerChar);\n    },\n    decode(input) {\n      return decode(input, alphabet, bitsPerChar, name);\n    }\n  });\n};\n\nexports.Codec = Codec;\nexports.baseX = baseX;\nexports.from = from;\nexports.rfc4648 = rfc4648;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base10 = base.baseX({\n  prefix: '9',\n  name: 'base10',\n  alphabet: '0123456789'\n});\n\nexports.base10 = base10;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base16 = base.rfc4648({\n  prefix: 'f',\n  name: 'base16',\n  alphabet: '0123456789abcdef',\n  bitsPerChar: 4\n});\nconst base16upper = base.rfc4648({\n  prefix: 'F',\n  name: 'base16upper',\n  alphabet: '0123456789ABCDEF',\n  bitsPerChar: 4\n});\n\nexports.base16 = base16;\nexports.base16upper = base16upper;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base2 = base.rfc4648({\n  prefix: '0',\n  name: 'base2',\n  alphabet: '01',\n  bitsPerChar: 1\n});\n\nexports.base2 = base2;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base32 = base.rfc4648({\n  prefix: 'b',\n  name: 'base32',\n  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',\n  bitsPerChar: 5\n});\nconst base32upper = base.rfc4648({\n  prefix: 'B',\n  name: 'base32upper',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',\n  bitsPerChar: 5\n});\nconst base32pad = base.rfc4648({\n  prefix: 'c',\n  name: 'base32pad',\n  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',\n  bitsPerChar: 5\n});\nconst base32padupper = base.rfc4648({\n  prefix: 'C',\n  name: 'base32padupper',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',\n  bitsPerChar: 5\n});\nconst base32hex = base.rfc4648({\n  prefix: 'v',\n  name: 'base32hex',\n  alphabet: '0123456789abcdefghijklmnopqrstuv',\n  bitsPerChar: 5\n});\nconst base32hexupper = base.rfc4648({\n  prefix: 'V',\n  name: 'base32hexupper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',\n  bitsPerChar: 5\n});\nconst base32hexpad = base.rfc4648({\n  prefix: 't',\n  name: 'base32hexpad',\n  alphabet: '0123456789abcdefghijklmnopqrstuv=',\n  bitsPerChar: 5\n});\nconst base32hexpadupper = base.rfc4648({\n  prefix: 'T',\n  name: 'base32hexpadupper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',\n  bitsPerChar: 5\n});\nconst base32z = base.rfc4648({\n  prefix: 'h',\n  name: 'base32z',\n  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',\n  bitsPerChar: 5\n});\n\nexports.base32 = base32;\nexports.base32hex = base32hex;\nexports.base32hexpad = base32hexpad;\nexports.base32hexpadupper = base32hexpadupper;\nexports.base32hexupper = base32hexupper;\nexports.base32pad = base32pad;\nexports.base32padupper = base32padupper;\nexports.base32upper = base32upper;\nexports.base32z = base32z;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base36 = base.baseX({\n  prefix: 'k',\n  name: 'base36',\n  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'\n});\nconst base36upper = base.baseX({\n  prefix: 'K',\n  name: 'base36upper',\n  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n});\n\nexports.base36 = base36;\nexports.base36upper = base36upper;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base58btc = base.baseX({\n  name: 'base58btc',\n  prefix: 'z',\n  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'\n});\nconst base58flickr = base.baseX({\n  name: 'base58flickr',\n  prefix: 'Z',\n  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'\n});\n\nexports.base58btc = base58btc;\nexports.base58flickr = base58flickr;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base64 = base.rfc4648({\n  prefix: 'm',\n  name: 'base64',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',\n  bitsPerChar: 6\n});\nconst base64pad = base.rfc4648({\n  prefix: 'M',\n  name: 'base64pad',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',\n  bitsPerChar: 6\n});\nconst base64url = base.rfc4648({\n  prefix: 'u',\n  name: 'base64url',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',\n  bitsPerChar: 6\n});\nconst base64urlpad = base.rfc4648({\n  prefix: 'U',\n  name: 'base64urlpad',\n  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',\n  bitsPerChar: 6\n});\n\nexports.base64 = base64;\nexports.base64pad = base64pad;\nexports.base64url = base64url;\nexports.base64urlpad = base64urlpad;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\n\nconst base8 = base.rfc4648({\n  prefix: '7',\n  name: 'base8',\n  alphabet: '01234567',\n  bitsPerChar: 3\n});\n\nexports.base8 = base8;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar base = require('./base.js');\nvar bytes = require('../bytes.js');\n\nconst identity = base.from({\n  prefix: '\\0',\n  name: 'identity',\n  encode: buf => bytes.toString(buf),\n  decode: str => bytes.fromString(str)\n});\n\nexports.identity = identity;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar identity = require('./bases/identity.js');\nvar base2 = require('./bases/base2.js');\nvar base8 = require('./bases/base8.js');\nvar base10 = require('./bases/base10.js');\nvar base16 = require('./bases/base16.js');\nvar base32 = require('./bases/base32.js');\nvar base36 = require('./bases/base36.js');\nvar base58 = require('./bases/base58.js');\nvar base64 = require('./bases/base64.js');\nvar sha2 = require('./hashes/sha2.js');\nvar identity$1 = require('./hashes/identity.js');\nvar raw = require('./codecs/raw.js');\nvar json = require('./codecs/json.js');\nrequire('./index.js');\nvar cid = require('./cid.js');\nvar hasher = require('./hashes/hasher.js');\nvar digest = require('./hashes/digest.js');\nvar varint = require('./varint.js');\nvar bytes = require('./bytes.js');\n\nconst bases = {\n  ...identity,\n  ...base2,\n  ...base8,\n  ...base10,\n  ...base16,\n  ...base32,\n  ...base36,\n  ...base58,\n  ...base64\n};\nconst hashes = {\n  ...sha2,\n  ...identity$1\n};\nconst codecs = {\n  raw,\n  json\n};\n\nexports.CID = cid.CID;\nexports.hasher = hasher;\nexports.digest = digest;\nexports.varint = varint;\nexports.bytes = bytes;\nexports.bases = bases;\nexports.codecs = codecs;\nexports.hashes = hashes;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nrequire('./index.js');\nvar cid = require('./cid.js');\nvar bytes = require('./bytes.js');\n\nconst readonly = ({enumerable = true, configurable = false} = {}) => ({\n  enumerable,\n  configurable,\n  writable: false\n});\nconst links = function* (source, base) {\n  if (source == null)\n    return;\n  if (source instanceof Uint8Array)\n    return;\n  for (const [key, value] of Object.entries(source)) {\n    const path = [\n      ...base,\n      key\n    ];\n    if (value != null && typeof value === 'object') {\n      if (Array.isArray(value)) {\n        for (const [index, element] of value.entries()) {\n          const elementPath = [\n            ...path,\n            index\n          ];\n          const cid$1 = cid.CID.asCID(element);\n          if (cid$1) {\n            yield [\n              elementPath.join('/'),\n              cid$1\n            ];\n          } else if (typeof element === 'object') {\n            yield* links(element, elementPath);\n          }\n        }\n      } else {\n        const cid$1 = cid.CID.asCID(value);\n        if (cid$1) {\n          yield [\n            path.join('/'),\n            cid$1\n          ];\n        } else {\n          yield* links(value, path);\n        }\n      }\n    }\n  }\n};\nconst tree = function* (source, base) {\n  if (source == null)\n    return;\n  for (const [key, value] of Object.entries(source)) {\n    const path = [\n      ...base,\n      key\n    ];\n    yield path.join('/');\n    if (value != null && !(value instanceof Uint8Array) && typeof value === 'object' && !cid.CID.asCID(value)) {\n      if (Array.isArray(value)) {\n        for (const [index, element] of value.entries()) {\n          const elementPath = [\n            ...path,\n            index\n          ];\n          yield elementPath.join('/');\n          if (typeof element === 'object' && !cid.CID.asCID(element)) {\n            yield* tree(element, elementPath);\n          }\n        }\n      } else {\n        yield* tree(value, path);\n      }\n    }\n  }\n};\nconst get = (source, path) => {\n  let node = source;\n  for (const [index, key] of path.entries()) {\n    node = node[key];\n    if (node == null) {\n      throw new Error(`Object has no property at ${ path.slice(0, index + 1).map(part => `[${ JSON.stringify(part) }]`).join('') }`);\n    }\n    const cid$1 = cid.CID.asCID(node);\n    if (cid$1) {\n      return {\n        value: cid$1,\n        remaining: path.slice(index + 1).join('/')\n      };\n    }\n  }\n  return { value: node };\n};\nclass Block {\n  constructor({cid, bytes, value}) {\n    if (!cid || !bytes || typeof value === 'undefined')\n      throw new Error('Missing required argument');\n    this.cid = cid;\n    this.bytes = bytes;\n    this.value = value;\n    this.asBlock = this;\n    Object.defineProperties(this, {\n      cid: readonly(),\n      bytes: readonly(),\n      value: readonly(),\n      asBlock: readonly()\n    });\n  }\n  links() {\n    return links(this.value, []);\n  }\n  tree() {\n    return tree(this.value, []);\n  }\n  get(path = '/') {\n    return get(this.value, path.split('/').filter(Boolean));\n  }\n}\nconst encode = async ({value, codec, hasher}) => {\n  if (typeof value === 'undefined')\n    throw new Error('Missing required argument \"value\"');\n  if (!codec || !hasher)\n    throw new Error('Missing required argument: codec or hasher');\n  const bytes = codec.encode(value);\n  const hash = await hasher.digest(bytes);\n  const cid$1 = cid.CID.create(1, codec.code, hash);\n  return new Block({\n    value,\n    bytes,\n    cid: cid$1\n  });\n};\nconst decode = async ({bytes, codec, hasher}) => {\n  if (!bytes)\n    throw new Error('Missing required argument \"bytes\"');\n  if (!codec || !hasher)\n    throw new Error('Missing required argument: codec or hasher');\n  const value = codec.decode(bytes);\n  const hash = await hasher.digest(bytes);\n  const cid$1 = cid.CID.create(1, codec.code, hash);\n  return new Block({\n    value,\n    bytes,\n    cid: cid$1\n  });\n};\nconst createUnsafe = ({\n  bytes,\n  cid,\n  value: maybeValue,\n  codec\n}) => {\n  const value = maybeValue !== undefined ? maybeValue : codec && codec.decode(bytes);\n  if (value === undefined)\n    throw new Error('Missing required argument, must either provide \"value\" or \"codec\"');\n  return new Block({\n    cid,\n    bytes,\n    value\n  });\n};\nconst create = async ({bytes: bytes$1, cid, hasher, codec}) => {\n  if (!bytes$1)\n    throw new Error('Missing required argument \"bytes\"');\n  if (!hasher)\n    throw new Error('Missing required argument \"hasher\"');\n  const value = codec.decode(bytes$1);\n  const hash = await hasher.digest(bytes$1);\n  if (!bytes.equals(cid.multihash.bytes, hash.bytes)) {\n    throw new Error('CID hash does not match bytes');\n  }\n  return createUnsafe({\n    bytes: bytes$1,\n    cid,\n    value,\n    codec\n  });\n};\n\nexports.Block = Block;\nexports.create = create;\nexports.createUnsafe = createUnsafe;\nexports.decode = decode;\nexports.encode = encode;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst empty = new Uint8Array(0);\nconst toHex = d => d.reduce((hex, byte) => hex + byte.toString(16).padStart(2, '0'), '');\nconst fromHex = hex => {\n  const hexes = hex.match(/../g);\n  return hexes ? new Uint8Array(hexes.map(b => parseInt(b, 16))) : empty;\n};\nconst equals = (aa, bb) => {\n  if (aa === bb)\n    return true;\n  if (aa.byteLength !== bb.byteLength) {\n    return false;\n  }\n  for (let ii = 0; ii < aa.byteLength; ii++) {\n    if (aa[ii] !== bb[ii]) {\n      return false;\n    }\n  }\n  return true;\n};\nconst coerce = o => {\n  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array')\n    return o;\n  if (o instanceof ArrayBuffer)\n    return new Uint8Array(o);\n  if (ArrayBuffer.isView(o)) {\n    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);\n  }\n  throw new Error('Unknown type, must be binary type');\n};\nconst isBinary = o => o instanceof ArrayBuffer || ArrayBuffer.isView(o);\nconst fromString = str => new TextEncoder().encode(str);\nconst toString = b => new TextDecoder().decode(b);\n\nexports.coerce = coerce;\nexports.empty = empty;\nexports.equals = equals;\nexports.fromHex = fromHex;\nexports.fromString = fromString;\nexports.isBinary = isBinary;\nexports.toHex = toHex;\nexports.toString = toString;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar varint = require('./varint.js');\nvar digest = require('./hashes/digest.js');\nvar base58 = require('./bases/base58.js');\nvar base32 = require('./bases/base32.js');\nvar bytes = require('./bytes.js');\n\nclass CID {\n  constructor(version, code, multihash, bytes) {\n    this.code = code;\n    this.version = version;\n    this.multihash = multihash;\n    this.bytes = bytes;\n    this.byteOffset = bytes.byteOffset;\n    this.byteLength = bytes.byteLength;\n    this.asCID = this;\n    this._baseCache = new Map();\n    Object.defineProperties(this, {\n      byteOffset: hidden,\n      byteLength: hidden,\n      code: readonly,\n      version: readonly,\n      multihash: readonly,\n      bytes: readonly,\n      _baseCache: hidden,\n      asCID: hidden\n    });\n  }\n  toV0() {\n    switch (this.version) {\n    case 0: {\n        return this;\n      }\n    default: {\n        const {code, multihash} = this;\n        if (code !== DAG_PB_CODE) {\n          throw new Error('Cannot convert a non dag-pb CID to CIDv0');\n        }\n        if (multihash.code !== SHA_256_CODE) {\n          throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0');\n        }\n        return CID.createV0(multihash);\n      }\n    }\n  }\n  toV1() {\n    switch (this.version) {\n    case 0: {\n        const {code, digest: digest$1} = this.multihash;\n        const multihash = digest.create(code, digest$1);\n        return CID.createV1(this.code, multihash);\n      }\n    case 1: {\n        return this;\n      }\n    default: {\n        throw Error(`Can not convert CID version ${ this.version } to version 0. This is a bug please report`);\n      }\n    }\n  }\n  equals(other) {\n    return other && this.code === other.code && this.version === other.version && digest.equals(this.multihash, other.multihash);\n  }\n  toString(base) {\n    const {bytes, version, _baseCache} = this;\n    switch (version) {\n    case 0:\n      return toStringV0(bytes, _baseCache, base || base58.base58btc.encoder);\n    default:\n      return toStringV1(bytes, _baseCache, base || base32.base32.encoder);\n    }\n  }\n  toJSON() {\n    return {\n      code: this.code,\n      version: this.version,\n      hash: this.multihash.bytes\n    };\n  }\n  get [Symbol.toStringTag]() {\n    return 'CID';\n  }\n  [Symbol.for('nodejs.util.inspect.custom')]() {\n    return 'CID(' + this.toString() + ')';\n  }\n  static isCID(value) {\n    deprecate(/^0\\.0/, IS_CID_DEPRECATION);\n    return !!(value && (value[cidSymbol] || value.asCID === value));\n  }\n  get toBaseEncodedString() {\n    throw new Error('Deprecated, use .toString()');\n  }\n  get codec() {\n    throw new Error('\"codec\" property is deprecated, use integer \"code\" property instead');\n  }\n  get buffer() {\n    throw new Error('Deprecated .buffer property, use .bytes to get Uint8Array instead');\n  }\n  get multibaseName() {\n    throw new Error('\"multibaseName\" property is deprecated');\n  }\n  get prefix() {\n    throw new Error('\"prefix\" property is deprecated');\n  }\n  static asCID(value) {\n    if (value instanceof CID) {\n      return value;\n    } else if (value != null && value.asCID === value) {\n      const {version, code, multihash, bytes} = value;\n      return new CID(version, code, multihash, bytes || encodeCID(version, code, multihash.bytes));\n    } else if (value != null && value[cidSymbol] === true) {\n      const {version, multihash, code} = value;\n      const digest$1 = digest.decode(multihash);\n      return CID.create(version, code, digest$1);\n    } else {\n      return null;\n    }\n  }\n  static create(version, code, digest) {\n    if (typeof code !== 'number') {\n      throw new Error('String codecs are no longer supported');\n    }\n    switch (version) {\n    case 0: {\n        if (code !== DAG_PB_CODE) {\n          throw new Error(`Version 0 CID must use dag-pb (code: ${ DAG_PB_CODE }) block encoding`);\n        } else {\n          return new CID(version, code, digest, digest.bytes);\n        }\n      }\n    case 1: {\n        const bytes = encodeCID(version, code, digest.bytes);\n        return new CID(version, code, digest, bytes);\n      }\n    default: {\n        throw new Error('Invalid version');\n      }\n    }\n  }\n  static createV0(digest) {\n    return CID.create(0, DAG_PB_CODE, digest);\n  }\n  static createV1(code, digest) {\n    return CID.create(1, code, digest);\n  }\n  static decode(bytes) {\n    const [cid, remainder] = CID.decodeFirst(bytes);\n    if (remainder.length) {\n      throw new Error('Incorrect length');\n    }\n    return cid;\n  }\n  static decodeFirst(bytes$1) {\n    const specs = CID.inspectBytes(bytes$1);\n    const prefixSize = specs.size - specs.multihashSize;\n    const multihashBytes = bytes.coerce(bytes$1.subarray(prefixSize, prefixSize + specs.multihashSize));\n    if (multihashBytes.byteLength !== specs.multihashSize) {\n      throw new Error('Incorrect length');\n    }\n    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);\n    const digest$1 = new digest.Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);\n    const cid = specs.version === 0 ? CID.createV0(digest$1) : CID.createV1(specs.codec, digest$1);\n    return [\n      cid,\n      bytes$1.subarray(specs.size)\n    ];\n  }\n  static inspectBytes(initialBytes) {\n    let offset = 0;\n    const next = () => {\n      const [i, length] = varint.decode(initialBytes.subarray(offset));\n      offset += length;\n      return i;\n    };\n    let version = next();\n    let codec = DAG_PB_CODE;\n    if (version === 18) {\n      version = 0;\n      offset = 0;\n    } else if (version === 1) {\n      codec = next();\n    }\n    if (version !== 0 && version !== 1) {\n      throw new RangeError(`Invalid CID version ${ version }`);\n    }\n    const prefixSize = offset;\n    const multihashCode = next();\n    const digestSize = next();\n    const size = offset + digestSize;\n    const multihashSize = size - prefixSize;\n    return {\n      version,\n      codec,\n      multihashCode,\n      digestSize,\n      multihashSize,\n      size\n    };\n  }\n  static parse(source, base) {\n    const [prefix, bytes] = parseCIDtoBytes(source, base);\n    const cid = CID.decode(bytes);\n    cid._baseCache.set(prefix, source);\n    return cid;\n  }\n}\nconst parseCIDtoBytes = (source, base) => {\n  switch (source[0]) {\n  case 'Q': {\n      const decoder = base || base58.base58btc;\n      return [\n        base58.base58btc.prefix,\n        decoder.decode(`${ base58.base58btc.prefix }${ source }`)\n      ];\n    }\n  case base58.base58btc.prefix: {\n      const decoder = base || base58.base58btc;\n      return [\n        base58.base58btc.prefix,\n        decoder.decode(source)\n      ];\n    }\n  case base32.base32.prefix: {\n      const decoder = base || base32.base32;\n      return [\n        base32.base32.prefix,\n        decoder.decode(source)\n      ];\n    }\n  default: {\n      if (base == null) {\n        throw Error('To parse non base32 or base58btc encoded CID multibase decoder must be provided');\n      }\n      return [\n        source[0],\n        base.decode(source)\n      ];\n    }\n  }\n};\nconst toStringV0 = (bytes, cache, base) => {\n  const {prefix} = base;\n  if (prefix !== base58.base58btc.prefix) {\n    throw Error(`Cannot string encode V0 in ${ base.name } encoding`);\n  }\n  const cid = cache.get(prefix);\n  if (cid == null) {\n    const cid = base.encode(bytes).slice(1);\n    cache.set(prefix, cid);\n    return cid;\n  } else {\n    return cid;\n  }\n};\nconst toStringV1 = (bytes, cache, base) => {\n  const {prefix} = base;\n  const cid = cache.get(prefix);\n  if (cid == null) {\n    const cid = base.encode(bytes);\n    cache.set(prefix, cid);\n    return cid;\n  } else {\n    return cid;\n  }\n};\nconst DAG_PB_CODE = 112;\nconst SHA_256_CODE = 18;\nconst encodeCID = (version, code, multihash) => {\n  const codeOffset = varint.encodingLength(version);\n  const hashOffset = codeOffset + varint.encodingLength(code);\n  const bytes = new Uint8Array(hashOffset + multihash.byteLength);\n  varint.encodeTo(version, bytes, 0);\n  varint.encodeTo(code, bytes, codeOffset);\n  bytes.set(multihash, hashOffset);\n  return bytes;\n};\nconst cidSymbol = Symbol.for('@ipld/js-cid/CID');\nconst readonly = {\n  writable: false,\n  configurable: false,\n  enumerable: true\n};\nconst hidden = {\n  writable: false,\n  enumerable: false,\n  configurable: false\n};\nconst version = '0.0.0-dev';\nconst deprecate = (range, message) => {\n  if (range.test(version)) {\n    console.warn(message);\n  } else {\n    throw new Error(message);\n  }\n};\nconst IS_CID_DEPRECATION = `CID.isCID(v) is deprecated and will be removed in the next major release.\nFollowing code pattern:\n\nif (CID.isCID(value)) {\n  doSomethingWithCID(value)\n}\n\nIs replaced with:\n\nconst cid = CID.asCID(value)\nif (cid) {\n  // Make sure to use cid instead of value\n  doSomethingWithCID(cid)\n}\n`;\n\nexports.CID = CID;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nconst {name, code, encode, decode} = {\n  name: 'json',\n  code: 512,\n  encode: json => new TextEncoder().encode(JSON.stringify(json)),\n  decode: bytes => JSON.parse(new TextDecoder().decode(bytes))\n};\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar bytes = require('../bytes.js');\n\nconst raw = bytes$1 => bytes.coerce(bytes$1);\nconst {name, code, encode, decode} = {\n  name: 'raw',\n  code: 85,\n  decode: raw,\n  encode: raw\n};\n\nexports.code = code;\nexports.decode = decode;\nexports.encode = encode;\nexports.name = name;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar bytes = require('../bytes.js');\nvar varint = require('../varint.js');\n\nconst create = (code, digest) => {\n  const size = digest.byteLength;\n  const sizeOffset = varint.encodingLength(code);\n  const digestOffset = sizeOffset + varint.encodingLength(size);\n  const bytes = new Uint8Array(digestOffset + size);\n  varint.encodeTo(code, bytes, 0);\n  varint.encodeTo(size, bytes, sizeOffset);\n  bytes.set(digest, digestOffset);\n  return new Digest(code, size, digest, bytes);\n};\nconst decode = multihash => {\n  const bytes$1 = bytes.coerce(multihash);\n  const [code, sizeOffset] = varint.decode(bytes$1);\n  const [size, digestOffset] = varint.decode(bytes$1.subarray(sizeOffset));\n  const digest = bytes$1.subarray(sizeOffset + digestOffset);\n  if (digest.byteLength !== size) {\n    throw new Error('Incorrect length');\n  }\n  return new Digest(code, size, digest, bytes$1);\n};\nconst equals = (a, b) => {\n  if (a === b) {\n    return true;\n  } else {\n    return a.code === b.code && a.size === b.size && bytes.equals(a.bytes, b.bytes);\n  }\n};\nclass Digest {\n  constructor(code, size, digest, bytes) {\n    this.code = code;\n    this.size = size;\n    this.digest = digest;\n    this.bytes = bytes;\n  }\n}\n\nexports.Digest = Digest;\nexports.create = create;\nexports.decode = decode;\nexports.equals = equals;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar digest = require('./digest.js');\n\nconst from = ({name, code, encode}) => new Hasher(name, code, encode);\nclass Hasher {\n  constructor(name, code, encode) {\n    this.name = name;\n    this.code = code;\n    this.encode = encode;\n  }\n  async digest(input) {\n    if (input instanceof Uint8Array) {\n      const digest$1 = await this.encode(input);\n      return digest.create(this.code, digest$1);\n    } else {\n      throw Error('Unknown type, must be binary type');\n    }\n  }\n}\n\nexports.Hasher = Hasher;\nexports.from = from;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar hasher = require('./hasher.js');\nvar bytes = require('../bytes.js');\n\nconst identity = hasher.from({\n  name: 'identity',\n  code: 0,\n  encode: input => bytes.coerce(input)\n});\n\nexports.identity = identity;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar crypto = require('crypto');\nvar hasher = require('./hasher.js');\nvar bytes = require('../bytes.js');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar crypto__default = /*#__PURE__*/_interopDefaultLegacy(crypto);\n\nconst sha256 = hasher.from({\n  name: 'sha2-256',\n  code: 18,\n  encode: input => bytes.coerce(crypto__default['default'].createHash('sha256').update(input).digest())\n});\nconst sha512 = hasher.from({\n  name: 'sha2-512',\n  code: 19,\n  encode: input => bytes.coerce(crypto__default['default'].createHash('sha512').update(input).digest())\n});\n\nexports.sha256 = sha256;\nexports.sha512 = sha512;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar cid = require('./cid.js');\nvar varint = require('./varint.js');\nvar bytes = require('./bytes.js');\nvar hasher = require('./hashes/hasher.js');\nvar digest = require('./hashes/digest.js');\n\n\n\nexports.CID = cid.CID;\nexports.varint = varint;\nexports.bytes = bytes;\nexports.hasher = hasher;\nexports.digest = digest;\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar varint$1 = require('../vendor/varint.js');\n\nconst decode = data => {\n  const code = varint$1.decode(data);\n  return [\n    code,\n    varint$1.decode.bytes\n  ];\n};\nconst encodeTo = (int, target, offset = 0) => {\n  varint$1.encode(int, target, offset);\n  return target;\n};\nconst encodingLength = int => {\n  return varint$1.encodingLength(int);\n};\n\nexports.decode = decode;\nexports.encodeTo = encodeTo;\nexports.encodingLength = encodingLength;\n","'use strict';\n\nfunction base(ALPHABET, name) {\n  if (ALPHABET.length >= 255) {\n    throw new TypeError('Alphabet too long');\n  }\n  var BASE_MAP = new Uint8Array(256);\n  for (var j = 0; j < BASE_MAP.length; j++) {\n    BASE_MAP[j] = 255;\n  }\n  for (var i = 0; i < ALPHABET.length; i++) {\n    var x = ALPHABET.charAt(i);\n    var xc = x.charCodeAt(0);\n    if (BASE_MAP[xc] !== 255) {\n      throw new TypeError(x + ' is ambiguous');\n    }\n    BASE_MAP[xc] = i;\n  }\n  var BASE = ALPHABET.length;\n  var LEADER = ALPHABET.charAt(0);\n  var FACTOR = Math.log(BASE) / Math.log(256);\n  var iFACTOR = Math.log(256) / Math.log(BASE);\n  function encode(source) {\n    if (source instanceof Uint8Array);\n    else if (ArrayBuffer.isView(source)) {\n      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);\n    } else if (Array.isArray(source)) {\n      source = Uint8Array.from(source);\n    }\n    if (!(source instanceof Uint8Array)) {\n      throw new TypeError('Expected Uint8Array');\n    }\n    if (source.length === 0) {\n      return '';\n    }\n    var zeroes = 0;\n    var length = 0;\n    var pbegin = 0;\n    var pend = source.length;\n    while (pbegin !== pend && source[pbegin] === 0) {\n      pbegin++;\n      zeroes++;\n    }\n    var size = (pend - pbegin) * iFACTOR + 1 >>> 0;\n    var b58 = new Uint8Array(size);\n    while (pbegin !== pend) {\n      var carry = source[pbegin];\n      var i = 0;\n      for (var it1 = size - 1; (carry !== 0 || i < length) && it1 !== -1; it1--, i++) {\n        carry += 256 * b58[it1] >>> 0;\n        b58[it1] = carry % BASE >>> 0;\n        carry = carry / BASE >>> 0;\n      }\n      if (carry !== 0) {\n        throw new Error('Non-zero carry');\n      }\n      length = i;\n      pbegin++;\n    }\n    var it2 = size - length;\n    while (it2 !== size && b58[it2] === 0) {\n      it2++;\n    }\n    var str = LEADER.repeat(zeroes);\n    for (; it2 < size; ++it2) {\n      str += ALPHABET.charAt(b58[it2]);\n    }\n    return str;\n  }\n  function decodeUnsafe(source) {\n    if (typeof source !== 'string') {\n      throw new TypeError('Expected String');\n    }\n    if (source.length === 0) {\n      return new Uint8Array();\n    }\n    var psz = 0;\n    if (source[psz] === ' ') {\n      return;\n    }\n    var zeroes = 0;\n    var length = 0;\n    while (source[psz] === LEADER) {\n      zeroes++;\n      psz++;\n    }\n    var size = (source.length - psz) * FACTOR + 1 >>> 0;\n    var b256 = new Uint8Array(size);\n    while (source[psz]) {\n      var carry = BASE_MAP[source.charCodeAt(psz)];\n      if (carry === 255) {\n        return;\n      }\n      var i = 0;\n      for (var it3 = size - 1; (carry !== 0 || i < length) && it3 !== -1; it3--, i++) {\n        carry += BASE * b256[it3] >>> 0;\n        b256[it3] = carry % 256 >>> 0;\n        carry = carry / 256 >>> 0;\n      }\n      if (carry !== 0) {\n        throw new Error('Non-zero carry');\n      }\n      length = i;\n      psz++;\n    }\n    if (source[psz] === ' ') {\n      return;\n    }\n    var it4 = size - length;\n    while (it4 !== size && b256[it4] === 0) {\n      it4++;\n    }\n    var vch = new Uint8Array(zeroes + (size - it4));\n    var j = zeroes;\n    while (it4 !== size) {\n      vch[j++] = b256[it4++];\n    }\n    return vch;\n  }\n  function decode(string) {\n    var buffer = decodeUnsafe(string);\n    if (buffer) {\n      return buffer;\n    }\n    throw new Error(`Non-${ name } character`);\n  }\n  return {\n    encode: encode,\n    decodeUnsafe: decodeUnsafe,\n    decode: decode\n  };\n}\nvar src = base;\nvar _brrp__multiformats_scope_baseX = src;\n\nmodule.exports = _brrp__multiformats_scope_baseX;\n","'use strict';\n\nvar encode_1 = encode;\nvar MSB = 128, REST = 127, MSBALL = ~REST, INT = Math.pow(2, 31);\nfunction encode(num, out, offset) {\n  out = out || [];\n  offset = offset || 0;\n  var oldOffset = offset;\n  while (num >= INT) {\n    out[offset++] = num & 255 | MSB;\n    num /= 128;\n  }\n  while (num & MSBALL) {\n    out[offset++] = num & 255 | MSB;\n    num >>>= 7;\n  }\n  out[offset] = num | 0;\n  encode.bytes = offset - oldOffset + 1;\n  return out;\n}\nvar decode = read;\nvar MSB$1 = 128, REST$1 = 127;\nfunction read(buf, offset) {\n  var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;\n  do {\n    if (counter >= l) {\n      read.bytes = 0;\n      throw new RangeError('Could not decode varint');\n    }\n    b = buf[counter++];\n    res += shift < 28 ? (b & REST$1) << shift : (b & REST$1) * Math.pow(2, shift);\n    shift += 7;\n  } while (b >= MSB$1);\n  read.bytes = counter - offset;\n  return res;\n}\nvar N1 = Math.pow(2, 7);\nvar N2 = Math.pow(2, 14);\nvar N3 = Math.pow(2, 21);\nvar N4 = Math.pow(2, 28);\nvar N5 = Math.pow(2, 35);\nvar N6 = Math.pow(2, 42);\nvar N7 = Math.pow(2, 49);\nvar N8 = Math.pow(2, 56);\nvar N9 = Math.pow(2, 63);\nvar length = function (value) {\n  return value < N1 ? 1 : value < N2 ? 2 : value < N3 ? 3 : value < N4 ? 4 : value < N5 ? 5 : value < N6 ? 6 : value < N7 ? 7 : value < N8 ? 8 : value < N9 ? 9 : 10;\n};\nvar varint = {\n  encode: encode_1,\n  decode: decode,\n  encodingLength: length\n};\nvar _brrp_varint = varint;\n\nmodule.exports = _brrp_varint;\n","module.exports = require('./lib/murmurHash3js');\n","/* jshint -W086: true */\n// +----------------------------------------------------------------------+\n// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js\n// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |\n// |----------------------------------------------------------------------|\n// | Copyright (c) 2012-2015 Karan Lyons                                       |\n// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |\n// | Freely distributable under the MIT license.                          |\n// +----------------------------------------------------------------------+\n\n;(function (root, undefined) {\n    'use strict';\n\n    // Create a local object that'll be exported or referenced globally.\n    var library = {\n        'version': '3.0.0',\n        'x86': {},\n        'x64': {},\n        'inputValidation': true\n    };\n\n    // PRIVATE FUNCTIONS\n    // -----------------\n\n    function _validBytes(bytes) {\n        // check the input is an array or a typed array\n        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {\n            return false;\n        }\n\n        // check all bytes are actually bytes\n        for (var i = 0; i < bytes.length; i++) {\n            if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    function _x86Multiply(m, n) {\n        //\n        // Given two 32bit ints, returns the two multiplied together as a\n        // 32bit int.\n        //\n\n        return ((m & 0xffff) * n) + ((((m >>> 16) * n) & 0xffff) << 16);\n    }\n\n    function _x86Rotl(m, n) {\n        //\n        // Given a 32bit int and an int representing a number of bit positions,\n        // returns the 32bit int rotated left by that number of positions.\n        //\n\n        return (m << n) | (m >>> (32 - n));\n    }\n\n    function _x86Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x86 mix of that block.\n        //\n\n        h ^= h >>> 16;\n        h = _x86Multiply(h, 0x85ebca6b);\n        h ^= h >>> 13;\n        h = _x86Multiply(h, 0xc2b2ae35);\n        h ^= h >>> 16;\n\n        return h;\n    }\n\n    function _x64Add(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // added together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] + n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] + n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] + n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += m[0] + n[0];\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Multiply(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // multiplied together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] * n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] * n[3];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[2] += m[3] * n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] * n[3];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[2] * n[2];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[3] * n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += (m[0] * n[3]) + (m[1] * n[2]) + (m[2] * n[1]) + (m[3] * n[0]);\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Rotl(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) rotated left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 32) {\n            return [m[1], m[0]];\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];\n        } else {\n            n -= 32;\n            return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];\n        }\n    }\n\n    function _x64LeftShift(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) shifted left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 0) {\n            return m;\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];\n        } else {\n            return [m[1] << (n - 32), 0];\n        }\n    }\n\n    function _x64Xor(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // xored together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        return [m[0] ^ n[0], m[1] ^ n[1]];\n    }\n\n    function _x64Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x64 mix of that block.\n        // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n        // only place where we need to right shift 64bit ints.)\n        //\n\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n\n        return h;\n    }\n\n    // PUBLIC FUNCTIONS\n    // ----------------\n\n    library.x86.hash32 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 32 bit hash\n        // using the x86 flavor of MurmurHash3, as an unsigned int.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 4;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n\n        var k1 = 0;\n\n        var c1 = 0xcc9e2d51;\n        var c2 = 0x1b873593;\n\n        for (var i = 0; i < blocks; i = i + 4) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n\n            h1 ^= k1;\n            h1 = _x86Rotl(h1, 13);\n            h1 = _x86Multiply(h1, 5) + 0xe6546b64;\n        }\n\n        k1 = 0;\n\n        switch (remainder) {\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h1 = _x86Fmix(h1);\n\n        return h1 >>> 0;\n    };\n\n    library.x86.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x86 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n\n        seed = seed || 0;\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n        var h2 = seed;\n        var h3 = seed;\n        var h4 = seed;\n\n        var k1 = 0;\n        var k2 = 0;\n        var k3 = 0;\n        var k4 = 0;\n\n        var c1 = 0x239b961b;\n        var c2 = 0xab0e9789;\n        var c3 = 0x38b34ae5;\n        var c4 = 0xa1e38b93;\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n            k2 = (bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24);\n            k3 = (bytes[i + 8]) | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24);\n            k4 = (bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n            h1 ^= k1;\n\n            h1 = _x86Rotl(h1, 19);\n            h1 += h2;\n            h1 = _x86Multiply(h1, 5) + 0x561ccd1b;\n\n            k2 = _x86Multiply(k2, c2);\n            k2 = _x86Rotl(k2, 16);\n            k2 = _x86Multiply(k2, c3);\n            h2 ^= k2;\n\n            h2 = _x86Rotl(h2, 17);\n            h2 += h3;\n            h2 = _x86Multiply(h2, 5) + 0x0bcaa747;\n\n            k3 = _x86Multiply(k3, c3);\n            k3 = _x86Rotl(k3, 17);\n            k3 = _x86Multiply(k3, c4);\n            h3 ^= k3;\n\n            h3 = _x86Rotl(h3, 15);\n            h3 += h4;\n            h3 = _x86Multiply(h3, 5) + 0x96cd1c35;\n\n            k4 = _x86Multiply(k4, c4);\n            k4 = _x86Rotl(k4, 18);\n            k4 = _x86Multiply(k4, c1);\n            h4 ^= k4;\n\n            h4 = _x86Rotl(h4, 13);\n            h4 += h1;\n            h4 = _x86Multiply(h4, 5) + 0x32ac3b17;\n        }\n\n        k1 = 0;\n        k2 = 0;\n        k3 = 0;\n        k4 = 0;\n\n        switch (remainder) {\n            case 15:\n                k4 ^= bytes[i + 14] << 16;\n\n            case 14:\n                k4 ^= bytes[i + 13] << 8;\n\n            case 13:\n                k4 ^= bytes[i + 12];\n                k4 = _x86Multiply(k4, c4);\n                k4 = _x86Rotl(k4, 18);\n                k4 = _x86Multiply(k4, c1);\n                h4 ^= k4;\n\n            case 12:\n                k3 ^= bytes[i + 11] << 24;\n\n            case 11:\n                k3 ^= bytes[i + 10] << 16;\n\n            case 10:\n                k3 ^= bytes[i + 9] << 8;\n\n            case 9:\n                k3 ^= bytes[i + 8];\n                k3 = _x86Multiply(k3, c3);\n                k3 = _x86Rotl(k3, 17);\n                k3 = _x86Multiply(k3, c4);\n                h3 ^= k3;\n\n            case 8:\n                k2 ^= bytes[i + 7] << 24;\n\n            case 7:\n                k2 ^= bytes[i + 6] << 16;\n\n            case 6:\n                k2 ^= bytes[i + 5] << 8;\n\n            case 5:\n                k2 ^= bytes[i + 4];\n                k2 = _x86Multiply(k2, c2);\n                k2 = _x86Rotl(k2, 16);\n                k2 = _x86Multiply(k2, c3);\n                h2 ^= k2;\n\n            case 4:\n                k1 ^= bytes[i + 3] << 24;\n\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h2 ^= bytes.length;\n        h3 ^= bytes.length;\n        h4 ^= bytes.length;\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        h1 = _x86Fmix(h1);\n        h2 = _x86Fmix(h2);\n        h3 = _x86Fmix(h3);\n        h4 = _x86Fmix(h4);\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        return (\"00000000\" + (h1 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h3 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h4 >>> 0).toString(16)).slice(-8);\n    };\n\n    library.x64.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = [0, seed];\n        var h2 = [0, seed];\n\n        var k1 = [0, 0];\n        var k2 = [0, 0];\n\n        var c1 = [0x87c37b91, 0x114253d5];\n        var c2 = [0x4cf5ad43, 0x2745937f];\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = [(bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24), (bytes[i]) |\n                (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24)];\n            k2 = [(bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24), (bytes[i + 8]) |\n                (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24)];\n\n            k1 = _x64Multiply(k1, c1);\n            k1 = _x64Rotl(k1, 31);\n            k1 = _x64Multiply(k1, c2);\n            h1 = _x64Xor(h1, k1);\n\n            h1 = _x64Rotl(h1, 27);\n            h1 = _x64Add(h1, h2);\n            h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n\n            k2 = _x64Multiply(k2, c2);\n            k2 = _x64Rotl(k2, 33);\n            k2 = _x64Multiply(k2, c1);\n            h2 = _x64Xor(h2, k2);\n\n            h2 = _x64Rotl(h2, 31);\n            h2 = _x64Add(h2, h1);\n            h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n        }\n\n        k1 = [0, 0];\n        k2 = [0, 0];\n\n        switch (remainder) {\n            case 15:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));\n\n            case 14:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));\n\n            case 13:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));\n\n            case 12:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));\n\n            case 11:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));\n\n            case 10:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));\n\n            case 9:\n                k2 = _x64Xor(k2, [0, bytes[i + 8]]);\n                k2 = _x64Multiply(k2, c2);\n                k2 = _x64Rotl(k2, 33);\n                k2 = _x64Multiply(k2, c1);\n                h2 = _x64Xor(h2, k2);\n\n            case 8:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));\n\n            case 7:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));\n\n            case 6:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));\n\n            case 5:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));\n\n            case 4:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));\n\n            case 3:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));\n\n            case 2:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));\n\n            case 1:\n                k1 = _x64Xor(k1, [0, bytes[i]]);\n                k1 = _x64Multiply(k1, c1);\n                k1 = _x64Rotl(k1, 31);\n                k1 = _x64Multiply(k1, c2);\n                h1 = _x64Xor(h1, k1);\n        }\n\n        h1 = _x64Xor(h1, [0, bytes.length]);\n        h2 = _x64Xor(h2, [0, bytes.length]);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        h1 = _x64Fmix(h1);\n        h2 = _x64Fmix(h2);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        return (\"00000000\" + (h1[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h1[1] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[1] >>> 0).toString(16)).slice(-8);\n    };\n\n    // INITIALIZATION\n    // --------------\n\n    // Export murmurHash3 for CommonJS, either as an AMD module or just as part\n    // of the global object.\n    if (typeof exports !== 'undefined') {\n\n        if (typeof module !== 'undefined' && module.exports) {\n            exports = module.exports = library;\n        }\n\n        exports.murmurHash3 = library;\n\n    } else if (typeof define === 'function' && define.amd) {\n\n        define([], function () {\n            return library;\n        });\n    } else {\n\n        // Use murmurHash3.noConflict to restore `murmurHash3` back to its\n        // original value. Returns a reference to the library object, to allow\n        // it to be used under a different name.\n        library._murmurHash3 = root.murmurHash3;\n\n        library.noConflict = function () {\n            root.murmurHash3 = library._murmurHash3;\n            library._murmurHash3 = undefined;\n            library.noConflict = undefined;\n\n            return library;\n        };\n\n        root.murmurHash3 = library;\n    }\n})(this);\n","'use strict';\nconst retry = require('retry');\n\nconst networkErrorMsgs = [\n\t'Failed to fetch', // Chrome\n\t'NetworkError when attempting to fetch resource.', // Firefox\n\t'The Internet connection appears to be offline.', // Safari\n\t'Network request failed' // `cross-fetch`\n];\n\nclass AbortError extends Error {\n\tconstructor(message) {\n\t\tsuper();\n\n\t\tif (message instanceof Error) {\n\t\t\tthis.originalError = message;\n\t\t\t({message} = message);\n\t\t} else {\n\t\t\tthis.originalError = new Error(message);\n\t\t\tthis.originalError.stack = this.stack;\n\t\t}\n\n\t\tthis.name = 'AbortError';\n\t\tthis.message = message;\n\t}\n}\n\nconst decorateErrorWithCounts = (error, attemptNumber, options) => {\n\t// Minus 1 from attemptNumber because the first attempt does not count as a retry\n\tconst retriesLeft = options.retries - (attemptNumber - 1);\n\n\terror.attemptNumber = attemptNumber;\n\terror.retriesLeft = retriesLeft;\n\treturn error;\n};\n\nconst isNetworkError = errorMessage => networkErrorMsgs.includes(errorMessage);\n\nconst pRetry = (input, options) => new Promise((resolve, reject) => {\n\toptions = {\n\t\tonFailedAttempt: () => {},\n\t\tretries: 10,\n\t\t...options\n\t};\n\n\tconst operation = retry.operation(options);\n\n\toperation.attempt(async attemptNumber => {\n\t\ttry {\n\t\t\tresolve(await input(attemptNumber));\n\t\t} catch (error) {\n\t\t\tif (!(error instanceof Error)) {\n\t\t\t\treject(new TypeError(`Non-error was thrown: \"${error}\". You should only throw errors.`));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (error instanceof AbortError) {\n\t\t\t\toperation.stop();\n\t\t\t\treject(error.originalError);\n\t\t\t} else if (error instanceof TypeError && !isNetworkError(error.message)) {\n\t\t\t\toperation.stop();\n\t\t\t\treject(error);\n\t\t\t} else {\n\t\t\t\tdecorateErrorWithCounts(error, attemptNumber, options);\n\n\t\t\t\ttry {\n\t\t\t\t\tawait options.onFailedAttempt(error);\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (!operation.retry(error)) {\n\t\t\t\t\treject(operation.mainError());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n});\n\nmodule.exports = pRetry;\n// TODO: remove this in the next major version\nmodule.exports.default = pRetry;\n\nmodule.exports.AbortError = AbortError;\n","// minimal library entry point.\n\n\"use strict\";\nmodule.exports = require(\"./src/index-minimal\");\n","\"use strict\";\nvar protobuf = exports;\n\n/**\n * Build type, one of `\"full\"`, `\"light\"` or `\"minimal\"`.\n * @name build\n * @type {string}\n * @const\n */\nprotobuf.build = \"minimal\";\n\n// Serialization\nprotobuf.Writer       = require(\"./writer\");\nprotobuf.BufferWriter = require(\"./writer_buffer\");\nprotobuf.Reader       = require(\"./reader\");\nprotobuf.BufferReader = require(\"./reader_buffer\");\n\n// Utility\nprotobuf.util         = require(\"./util/minimal\");\nprotobuf.rpc          = require(\"./rpc\");\nprotobuf.roots        = require(\"./roots\");\nprotobuf.configure    = configure;\n\n/* istanbul ignore next */\n/**\n * Reconfigures the library according to the environment.\n * @returns {undefined}\n */\nfunction configure() {\n    protobuf.util._configure();\n    protobuf.Writer._configure(protobuf.BufferWriter);\n    protobuf.Reader._configure(protobuf.BufferReader);\n}\n\n// Set up buffer utility according to the environment\nconfigure();\n","\"use strict\";\nmodule.exports = Reader;\n\nvar util      = require(\"./util/minimal\");\n\nvar BufferReader; // cyclic\n\nvar LongBits  = util.LongBits,\n    utf8      = util.utf8;\n\n/* istanbul ignore next */\nfunction indexOutOfRange(reader, writeLength) {\n    return RangeError(\"index out of range: \" + reader.pos + \" + \" + (writeLength || 1) + \" > \" + reader.len);\n}\n\n/**\n * Constructs a new reader instance using the specified buffer.\n * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.\n * @constructor\n * @param {Uint8Array} buffer Buffer to read from\n */\nfunction Reader(buffer) {\n\n    /**\n     * Read buffer.\n     * @type {Uint8Array}\n     */\n    this.buf = buffer;\n\n    /**\n     * Read buffer position.\n     * @type {number}\n     */\n    this.pos = 0;\n\n    /**\n     * Read buffer length.\n     * @type {number}\n     */\n    this.len = buffer.length;\n}\n\nvar create_array = typeof Uint8Array !== \"undefined\"\n    ? function create_typed_array(buffer) {\n        if (buffer instanceof Uint8Array || Array.isArray(buffer))\n            return new Reader(buffer);\n        throw Error(\"illegal buffer\");\n    }\n    /* istanbul ignore next */\n    : function create_array(buffer) {\n        if (Array.isArray(buffer))\n            return new Reader(buffer);\n        throw Error(\"illegal buffer\");\n    };\n\nvar create = function create() {\n    return util.Buffer\n        ? function create_buffer_setup(buffer) {\n            return (Reader.create = function create_buffer(buffer) {\n                return util.Buffer.isBuffer(buffer)\n                    ? new BufferReader(buffer)\n                    /* istanbul ignore next */\n                    : create_array(buffer);\n            })(buffer);\n        }\n        /* istanbul ignore next */\n        : create_array;\n};\n\n/**\n * Creates a new reader using the specified buffer.\n * @function\n * @param {Uint8Array|Buffer} buffer Buffer to read from\n * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}\n * @throws {Error} If `buffer` is not a valid buffer\n */\nReader.create = create();\n\nReader.prototype._slice = util.Array.prototype.subarray || /* istanbul ignore next */ util.Array.prototype.slice;\n\n/**\n * Reads a varint as an unsigned 32 bit value.\n * @function\n * @returns {number} Value read\n */\nReader.prototype.uint32 = (function read_uint32_setup() {\n    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)\n    return function read_uint32() {\n        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;\n        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;\n\n        /* istanbul ignore if */\n        if ((this.pos += 5) > this.len) {\n            this.pos = this.len;\n            throw indexOutOfRange(this, 10);\n        }\n        return value;\n    };\n})();\n\n/**\n * Reads a varint as a signed 32 bit value.\n * @returns {number} Value read\n */\nReader.prototype.int32 = function read_int32() {\n    return this.uint32() | 0;\n};\n\n/**\n * Reads a zig-zag encoded varint as a signed 32 bit value.\n * @returns {number} Value read\n */\nReader.prototype.sint32 = function read_sint32() {\n    var value = this.uint32();\n    return value >>> 1 ^ -(value & 1) | 0;\n};\n\n/* eslint-disable no-invalid-this */\n\nfunction readLongVarint() {\n    // tends to deopt with local vars for octet etc.\n    var bits = new LongBits(0, 0);\n    var i = 0;\n    if (this.len - this.pos > 4) { // fast route (lo)\n        for (; i < 4; ++i) {\n            // 1st..4th\n            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n        // 5th\n        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;\n        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return bits;\n        i = 0;\n    } else {\n        for (; i < 3; ++i) {\n            /* istanbul ignore if */\n            if (this.pos >= this.len)\n                throw indexOutOfRange(this);\n            // 1st..3th\n            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n        // 4th\n        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;\n        return bits;\n    }\n    if (this.len - this.pos > 4) { // fast route (hi)\n        for (; i < 5; ++i) {\n            // 6th..10th\n            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n    } else {\n        for (; i < 5; ++i) {\n            /* istanbul ignore if */\n            if (this.pos >= this.len)\n                throw indexOutOfRange(this);\n            // 6th..10th\n            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n            if (this.buf[this.pos++] < 128)\n                return bits;\n        }\n    }\n    /* istanbul ignore next */\n    throw Error(\"invalid varint encoding\");\n}\n\n/* eslint-enable no-invalid-this */\n\n/**\n * Reads a varint as a signed 64 bit value.\n * @name Reader#int64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a varint as an unsigned 64 bit value.\n * @name Reader#uint64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a zig-zag encoded varint as a signed 64 bit value.\n * @name Reader#sint64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a varint as a boolean.\n * @returns {boolean} Value read\n */\nReader.prototype.bool = function read_bool() {\n    return this.uint32() !== 0;\n};\n\nfunction readFixed32_end(buf, end) { // note that this uses `end`, not `pos`\n    return (buf[end - 4]\n          | buf[end - 3] << 8\n          | buf[end - 2] << 16\n          | buf[end - 1] << 24) >>> 0;\n}\n\n/**\n * Reads fixed 32 bits as an unsigned 32 bit integer.\n * @returns {number} Value read\n */\nReader.prototype.fixed32 = function read_fixed32() {\n\n    /* istanbul ignore if */\n    if (this.pos + 4 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    return readFixed32_end(this.buf, this.pos += 4);\n};\n\n/**\n * Reads fixed 32 bits as a signed 32 bit integer.\n * @returns {number} Value read\n */\nReader.prototype.sfixed32 = function read_sfixed32() {\n\n    /* istanbul ignore if */\n    if (this.pos + 4 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    return readFixed32_end(this.buf, this.pos += 4) | 0;\n};\n\n/* eslint-disable no-invalid-this */\n\nfunction readFixed64(/* this: Reader */) {\n\n    /* istanbul ignore if */\n    if (this.pos + 8 > this.len)\n        throw indexOutOfRange(this, 8);\n\n    return new LongBits(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));\n}\n\n/* eslint-enable no-invalid-this */\n\n/**\n * Reads fixed 64 bits.\n * @name Reader#fixed64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads zig-zag encoded fixed 64 bits.\n * @name Reader#sfixed64\n * @function\n * @returns {Long} Value read\n */\n\n/**\n * Reads a float (32 bit) as a number.\n * @function\n * @returns {number} Value read\n */\nReader.prototype.float = function read_float() {\n\n    /* istanbul ignore if */\n    if (this.pos + 4 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    var value = util.float.readFloatLE(this.buf, this.pos);\n    this.pos += 4;\n    return value;\n};\n\n/**\n * Reads a double (64 bit float) as a number.\n * @function\n * @returns {number} Value read\n */\nReader.prototype.double = function read_double() {\n\n    /* istanbul ignore if */\n    if (this.pos + 8 > this.len)\n        throw indexOutOfRange(this, 4);\n\n    var value = util.float.readDoubleLE(this.buf, this.pos);\n    this.pos += 8;\n    return value;\n};\n\n/**\n * Reads a sequence of bytes preceeded by its length as a varint.\n * @returns {Uint8Array} Value read\n */\nReader.prototype.bytes = function read_bytes() {\n    var length = this.uint32(),\n        start  = this.pos,\n        end    = this.pos + length;\n\n    /* istanbul ignore if */\n    if (end > this.len)\n        throw indexOutOfRange(this, length);\n\n    this.pos += length;\n    if (Array.isArray(this.buf)) // plain array\n        return this.buf.slice(start, end);\n    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1\n        ? new this.buf.constructor(0)\n        : this._slice.call(this.buf, start, end);\n};\n\n/**\n * Reads a string preceeded by its byte length as a varint.\n * @returns {string} Value read\n */\nReader.prototype.string = function read_string() {\n    var bytes = this.bytes();\n    return utf8.read(bytes, 0, bytes.length);\n};\n\n/**\n * Skips the specified number of bytes if specified, otherwise skips a varint.\n * @param {number} [length] Length if known, otherwise a varint is assumed\n * @returns {Reader} `this`\n */\nReader.prototype.skip = function skip(length) {\n    if (typeof length === \"number\") {\n        /* istanbul ignore if */\n        if (this.pos + length > this.len)\n            throw indexOutOfRange(this, length);\n        this.pos += length;\n    } else {\n        do {\n            /* istanbul ignore if */\n            if (this.pos >= this.len)\n                throw indexOutOfRange(this);\n        } while (this.buf[this.pos++] & 128);\n    }\n    return this;\n};\n\n/**\n * Skips the next element of the specified wire type.\n * @param {number} wireType Wire type received\n * @returns {Reader} `this`\n */\nReader.prototype.skipType = function(wireType) {\n    switch (wireType) {\n        case 0:\n            this.skip();\n            break;\n        case 1:\n            this.skip(8);\n            break;\n        case 2:\n            this.skip(this.uint32());\n            break;\n        case 3:\n            while ((wireType = this.uint32() & 7) !== 4) {\n                this.skipType(wireType);\n            }\n            break;\n        case 5:\n            this.skip(4);\n            break;\n\n        /* istanbul ignore next */\n        default:\n            throw Error(\"invalid wire type \" + wireType + \" at offset \" + this.pos);\n    }\n    return this;\n};\n\nReader._configure = function(BufferReader_) {\n    BufferReader = BufferReader_;\n    Reader.create = create();\n    BufferReader._configure();\n\n    var fn = util.Long ? \"toLong\" : /* istanbul ignore next */ \"toNumber\";\n    util.merge(Reader.prototype, {\n\n        int64: function read_int64() {\n            return readLongVarint.call(this)[fn](false);\n        },\n\n        uint64: function read_uint64() {\n            return readLongVarint.call(this)[fn](true);\n        },\n\n        sint64: function read_sint64() {\n            return readLongVarint.call(this).zzDecode()[fn](false);\n        },\n\n        fixed64: function read_fixed64() {\n            return readFixed64.call(this)[fn](true);\n        },\n\n        sfixed64: function read_sfixed64() {\n            return readFixed64.call(this)[fn](false);\n        }\n\n    });\n};\n","\"use strict\";\nmodule.exports = BufferReader;\n\n// extends Reader\nvar Reader = require(\"./reader\");\n(BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;\n\nvar util = require(\"./util/minimal\");\n\n/**\n * Constructs a new buffer reader instance.\n * @classdesc Wire format reader using node buffers.\n * @extends Reader\n * @constructor\n * @param {Buffer} buffer Buffer to read from\n */\nfunction BufferReader(buffer) {\n    Reader.call(this, buffer);\n\n    /**\n     * Read buffer.\n     * @name BufferReader#buf\n     * @type {Buffer}\n     */\n}\n\nBufferReader._configure = function () {\n    /* istanbul ignore else */\n    if (util.Buffer)\n        BufferReader.prototype._slice = util.Buffer.prototype.slice;\n};\n\n\n/**\n * @override\n */\nBufferReader.prototype.string = function read_string_buffer() {\n    var len = this.uint32(); // modifies pos\n    return this.buf.utf8Slice\n        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))\n        : this.buf.toString(\"utf-8\", this.pos, this.pos = Math.min(this.pos + len, this.len));\n};\n\n/**\n * Reads a sequence of bytes preceeded by its length as a varint.\n * @name BufferReader#bytes\n * @function\n * @returns {Buffer} Value read\n */\n\nBufferReader._configure();\n","\"use strict\";\nmodule.exports = {};\n\n/**\n * Named roots.\n * This is where pbjs stores generated structures (the option `-r, --root` specifies a name).\n * Can also be used manually to make roots available accross modules.\n * @name roots\n * @type {Object.<string,Root>}\n * @example\n * // pbjs -r myroot -o compiled.js ...\n *\n * // in another module:\n * require(\"./compiled.js\");\n *\n * // in any subsequent module:\n * var root = protobuf.roots[\"myroot\"];\n */\n","\"use strict\";\n\n/**\n * Streaming RPC helpers.\n * @namespace\n */\nvar rpc = exports;\n\n/**\n * RPC implementation passed to {@link Service#create} performing a service request on network level, i.e. by utilizing http requests or websockets.\n * @typedef RPCImpl\n * @type {function}\n * @param {Method|rpc.ServiceMethod<Message<{}>,Message<{}>>} method Reflected or static method being called\n * @param {Uint8Array} requestData Request data\n * @param {RPCImplCallback} callback Callback function\n * @returns {undefined}\n * @example\n * function rpcImpl(method, requestData, callback) {\n *     if (protobuf.util.lcFirst(method.name) !== \"myMethod\") // compatible with static code\n *         throw Error(\"no such method\");\n *     asynchronouslyObtainAResponse(requestData, function(err, responseData) {\n *         callback(err, responseData);\n *     });\n * }\n */\n\n/**\n * Node-style callback as used by {@link RPCImpl}.\n * @typedef RPCImplCallback\n * @type {function}\n * @param {Error|null} error Error, if any, otherwise `null`\n * @param {Uint8Array|null} [response] Response data or `null` to signal end of stream, if there hasn't been an error\n * @returns {undefined}\n */\n\nrpc.Service = require(\"./rpc/service\");\n","\"use strict\";\nmodule.exports = Service;\n\nvar util = require(\"../util/minimal\");\n\n// Extends EventEmitter\n(Service.prototype = Object.create(util.EventEmitter.prototype)).constructor = Service;\n\n/**\n * A service method callback as used by {@link rpc.ServiceMethod|ServiceMethod}.\n *\n * Differs from {@link RPCImplCallback} in that it is an actual callback of a service method which may not return `response = null`.\n * @typedef rpc.ServiceMethodCallback\n * @template TRes extends Message<TRes>\n * @type {function}\n * @param {Error|null} error Error, if any\n * @param {TRes} [response] Response message\n * @returns {undefined}\n */\n\n/**\n * A service method part of a {@link rpc.Service} as created by {@link Service.create}.\n * @typedef rpc.ServiceMethod\n * @template TReq extends Message<TReq>\n * @template TRes extends Message<TRes>\n * @type {function}\n * @param {TReq|Properties<TReq>} request Request message or plain object\n * @param {rpc.ServiceMethodCallback<TRes>} [callback] Node-style callback called with the error, if any, and the response message\n * @returns {Promise<Message<TRes>>} Promise if `callback` has been omitted, otherwise `undefined`\n */\n\n/**\n * Constructs a new RPC service instance.\n * @classdesc An RPC service as returned by {@link Service#create}.\n * @exports rpc.Service\n * @extends util.EventEmitter\n * @constructor\n * @param {RPCImpl} rpcImpl RPC implementation\n * @param {boolean} [requestDelimited=false] Whether requests are length-delimited\n * @param {boolean} [responseDelimited=false] Whether responses are length-delimited\n */\nfunction Service(rpcImpl, requestDelimited, responseDelimited) {\n\n    if (typeof rpcImpl !== \"function\")\n        throw TypeError(\"rpcImpl must be a function\");\n\n    util.EventEmitter.call(this);\n\n    /**\n     * RPC implementation. Becomes `null` once the service is ended.\n     * @type {RPCImpl|null}\n     */\n    this.rpcImpl = rpcImpl;\n\n    /**\n     * Whether requests are length-delimited.\n     * @type {boolean}\n     */\n    this.requestDelimited = Boolean(requestDelimited);\n\n    /**\n     * Whether responses are length-delimited.\n     * @type {boolean}\n     */\n    this.responseDelimited = Boolean(responseDelimited);\n}\n\n/**\n * Calls a service method through {@link rpc.Service#rpcImpl|rpcImpl}.\n * @param {Method|rpc.ServiceMethod<TReq,TRes>} method Reflected or static method\n * @param {Constructor<TReq>} requestCtor Request constructor\n * @param {Constructor<TRes>} responseCtor Response constructor\n * @param {TReq|Properties<TReq>} request Request message or plain object\n * @param {rpc.ServiceMethodCallback<TRes>} callback Service callback\n * @returns {undefined}\n * @template TReq extends Message<TReq>\n * @template TRes extends Message<TRes>\n */\nService.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {\n\n    if (!request)\n        throw TypeError(\"request must be specified\");\n\n    var self = this;\n    if (!callback)\n        return util.asPromise(rpcCall, self, method, requestCtor, responseCtor, request);\n\n    if (!self.rpcImpl) {\n        setTimeout(function() { callback(Error(\"already ended\")); }, 0);\n        return undefined;\n    }\n\n    try {\n        return self.rpcImpl(\n            method,\n            requestCtor[self.requestDelimited ? \"encodeDelimited\" : \"encode\"](request).finish(),\n            function rpcCallback(err, response) {\n\n                if (err) {\n                    self.emit(\"error\", err, method);\n                    return callback(err);\n                }\n\n                if (response === null) {\n                    self.end(/* endedByRPC */ true);\n                    return undefined;\n                }\n\n                if (!(response instanceof responseCtor)) {\n                    try {\n                        response = responseCtor[self.responseDelimited ? \"decodeDelimited\" : \"decode\"](response);\n                    } catch (err) {\n                        self.emit(\"error\", err, method);\n                        return callback(err);\n                    }\n                }\n\n                self.emit(\"data\", response, method);\n                return callback(null, response);\n            }\n        );\n    } catch (err) {\n        self.emit(\"error\", err, method);\n        setTimeout(function() { callback(err); }, 0);\n        return undefined;\n    }\n};\n\n/**\n * Ends this service and emits the `end` event.\n * @param {boolean} [endedByRPC=false] Whether the service has been ended by the RPC implementation.\n * @returns {rpc.Service} `this`\n */\nService.prototype.end = function end(endedByRPC) {\n    if (this.rpcImpl) {\n        if (!endedByRPC) // signal end to rpcImpl\n            this.rpcImpl(null, null, null);\n        this.rpcImpl = null;\n        this.emit(\"end\").off();\n    }\n    return this;\n};\n","\"use strict\";\nmodule.exports = LongBits;\n\nvar util = require(\"../util/minimal\");\n\n/**\n * Constructs new long bits.\n * @classdesc Helper class for working with the low and high bits of a 64 bit value.\n * @memberof util\n * @constructor\n * @param {number} lo Low 32 bits, unsigned\n * @param {number} hi High 32 bits, unsigned\n */\nfunction LongBits(lo, hi) {\n\n    // note that the casts below are theoretically unnecessary as of today, but older statically\n    // generated converter code might still call the ctor with signed 32bits. kept for compat.\n\n    /**\n     * Low bits.\n     * @type {number}\n     */\n    this.lo = lo >>> 0;\n\n    /**\n     * High bits.\n     * @type {number}\n     */\n    this.hi = hi >>> 0;\n}\n\n/**\n * Zero bits.\n * @memberof util.LongBits\n * @type {util.LongBits}\n */\nvar zero = LongBits.zero = new LongBits(0, 0);\n\nzero.toNumber = function() { return 0; };\nzero.zzEncode = zero.zzDecode = function() { return this; };\nzero.length = function() { return 1; };\n\n/**\n * Zero hash.\n * @memberof util.LongBits\n * @type {string}\n */\nvar zeroHash = LongBits.zeroHash = \"\\0\\0\\0\\0\\0\\0\\0\\0\";\n\n/**\n * Constructs new long bits from the specified number.\n * @param {number} value Value\n * @returns {util.LongBits} Instance\n */\nLongBits.fromNumber = function fromNumber(value) {\n    if (value === 0)\n        return zero;\n    var sign = value < 0;\n    if (sign)\n        value = -value;\n    var lo = value >>> 0,\n        hi = (value - lo) / 4294967296 >>> 0;\n    if (sign) {\n        hi = ~hi >>> 0;\n        lo = ~lo >>> 0;\n        if (++lo > 4294967295) {\n            lo = 0;\n            if (++hi > 4294967295)\n                hi = 0;\n        }\n    }\n    return new LongBits(lo, hi);\n};\n\n/**\n * Constructs new long bits from a number, long or string.\n * @param {Long|number|string} value Value\n * @returns {util.LongBits} Instance\n */\nLongBits.from = function from(value) {\n    if (typeof value === \"number\")\n        return LongBits.fromNumber(value);\n    if (util.isString(value)) {\n        /* istanbul ignore else */\n        if (util.Long)\n            value = util.Long.fromString(value);\n        else\n            return LongBits.fromNumber(parseInt(value, 10));\n    }\n    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;\n};\n\n/**\n * Converts this long bits to a possibly unsafe JavaScript number.\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {number} Possibly unsafe number\n */\nLongBits.prototype.toNumber = function toNumber(unsigned) {\n    if (!unsigned && this.hi >>> 31) {\n        var lo = ~this.lo + 1 >>> 0,\n            hi = ~this.hi     >>> 0;\n        if (!lo)\n            hi = hi + 1 >>> 0;\n        return -(lo + hi * 4294967296);\n    }\n    return this.lo + this.hi * 4294967296;\n};\n\n/**\n * Converts this long bits to a long.\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {Long} Long\n */\nLongBits.prototype.toLong = function toLong(unsigned) {\n    return util.Long\n        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))\n        /* istanbul ignore next */\n        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };\n};\n\nvar charCodeAt = String.prototype.charCodeAt;\n\n/**\n * Constructs new long bits from the specified 8 characters long hash.\n * @param {string} hash Hash\n * @returns {util.LongBits} Bits\n */\nLongBits.fromHash = function fromHash(hash) {\n    if (hash === zeroHash)\n        return zero;\n    return new LongBits(\n        ( charCodeAt.call(hash, 0)\n        | charCodeAt.call(hash, 1) << 8\n        | charCodeAt.call(hash, 2) << 16\n        | charCodeAt.call(hash, 3) << 24) >>> 0\n    ,\n        ( charCodeAt.call(hash, 4)\n        | charCodeAt.call(hash, 5) << 8\n        | charCodeAt.call(hash, 6) << 16\n        | charCodeAt.call(hash, 7) << 24) >>> 0\n    );\n};\n\n/**\n * Converts this long bits to a 8 characters long hash.\n * @returns {string} Hash\n */\nLongBits.prototype.toHash = function toHash() {\n    return String.fromCharCode(\n        this.lo        & 255,\n        this.lo >>> 8  & 255,\n        this.lo >>> 16 & 255,\n        this.lo >>> 24      ,\n        this.hi        & 255,\n        this.hi >>> 8  & 255,\n        this.hi >>> 16 & 255,\n        this.hi >>> 24\n    );\n};\n\n/**\n * Zig-zag encodes this long bits.\n * @returns {util.LongBits} `this`\n */\nLongBits.prototype.zzEncode = function zzEncode() {\n    var mask =   this.hi >> 31;\n    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;\n    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;\n    return this;\n};\n\n/**\n * Zig-zag decodes this long bits.\n * @returns {util.LongBits} `this`\n */\nLongBits.prototype.zzDecode = function zzDecode() {\n    var mask = -(this.lo & 1);\n    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;\n    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;\n    return this;\n};\n\n/**\n * Calculates the length of this longbits when encoded as a varint.\n * @returns {number} Length\n */\nLongBits.prototype.length = function length() {\n    var part0 =  this.lo,\n        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,\n        part2 =  this.hi >>> 24;\n    return part2 === 0\n         ? part1 === 0\n           ? part0 < 16384\n             ? part0 < 128 ? 1 : 2\n             : part0 < 2097152 ? 3 : 4\n           : part1 < 16384\n             ? part1 < 128 ? 5 : 6\n             : part1 < 2097152 ? 7 : 8\n         : part2 < 128 ? 9 : 10;\n};\n","\"use strict\";\nvar util = exports;\n\n// used to return a Promise where callback is omitted\nutil.asPromise = require(\"@protobufjs/aspromise\");\n\n// converts to / from base64 encoded strings\nutil.base64 = require(\"@protobufjs/base64\");\n\n// base class of rpc.Service\nutil.EventEmitter = require(\"@protobufjs/eventemitter\");\n\n// float handling accross browsers\nutil.float = require(\"@protobufjs/float\");\n\n// requires modules optionally and hides the call from bundlers\nutil.inquire = require(\"@protobufjs/inquire\");\n\n// converts to / from utf8 encoded strings\nutil.utf8 = require(\"@protobufjs/utf8\");\n\n// provides a node-like buffer pool in the browser\nutil.pool = require(\"@protobufjs/pool\");\n\n// utility to work with the low and high bits of a 64 bit value\nutil.LongBits = require(\"./longbits\");\n\n/**\n * Whether running within node or not.\n * @memberof util\n * @type {boolean}\n */\nutil.isNode = Boolean(typeof global !== \"undefined\"\n                   && global\n                   && global.process\n                   && global.process.versions\n                   && global.process.versions.node);\n\n/**\n * Global object reference.\n * @memberof util\n * @type {Object}\n */\nutil.global = util.isNode && global\n           || typeof window !== \"undefined\" && window\n           || typeof self   !== \"undefined\" && self\n           || this; // eslint-disable-line no-invalid-this\n\n/**\n * An immuable empty array.\n * @memberof util\n * @type {Array.<*>}\n * @const\n */\nutil.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes\n\n/**\n * An immutable empty object.\n * @type {Object}\n * @const\n */\nutil.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes\n\n/**\n * Tests if the specified value is an integer.\n * @function\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is an integer\n */\nutil.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {\n    return typeof value === \"number\" && isFinite(value) && Math.floor(value) === value;\n};\n\n/**\n * Tests if the specified value is a string.\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is a string\n */\nutil.isString = function isString(value) {\n    return typeof value === \"string\" || value instanceof String;\n};\n\n/**\n * Tests if the specified value is a non-null object.\n * @param {*} value Value to test\n * @returns {boolean} `true` if the value is a non-null object\n */\nutil.isObject = function isObject(value) {\n    return value && typeof value === \"object\";\n};\n\n/**\n * Checks if a property on a message is considered to be present.\n * This is an alias of {@link util.isSet}.\n * @function\n * @param {Object} obj Plain object or message instance\n * @param {string} prop Property name\n * @returns {boolean} `true` if considered to be present, otherwise `false`\n */\nutil.isset =\n\n/**\n * Checks if a property on a message is considered to be present.\n * @param {Object} obj Plain object or message instance\n * @param {string} prop Property name\n * @returns {boolean} `true` if considered to be present, otherwise `false`\n */\nutil.isSet = function isSet(obj, prop) {\n    var value = obj[prop];\n    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins\n        return typeof value !== \"object\" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;\n    return false;\n};\n\n/**\n * Any compatible Buffer instance.\n * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.\n * @interface Buffer\n * @extends Uint8Array\n */\n\n/**\n * Node's Buffer class if available.\n * @type {Constructor<Buffer>}\n */\nutil.Buffer = (function() {\n    try {\n        var Buffer = util.inquire(\"buffer\").Buffer;\n        // refuse to use non-node buffers if not explicitly assigned (perf reasons):\n        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;\n    } catch (e) {\n        /* istanbul ignore next */\n        return null;\n    }\n})();\n\n// Internal alias of or polyfull for Buffer.from.\nutil._Buffer_from = null;\n\n// Internal alias of or polyfill for Buffer.allocUnsafe.\nutil._Buffer_allocUnsafe = null;\n\n/**\n * Creates a new buffer of whatever type supported by the environment.\n * @param {number|number[]} [sizeOrArray=0] Buffer size or number array\n * @returns {Uint8Array|Buffer} Buffer\n */\nutil.newBuffer = function newBuffer(sizeOrArray) {\n    /* istanbul ignore next */\n    return typeof sizeOrArray === \"number\"\n        ? util.Buffer\n            ? util._Buffer_allocUnsafe(sizeOrArray)\n            : new util.Array(sizeOrArray)\n        : util.Buffer\n            ? util._Buffer_from(sizeOrArray)\n            : typeof Uint8Array === \"undefined\"\n                ? sizeOrArray\n                : new Uint8Array(sizeOrArray);\n};\n\n/**\n * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.\n * @type {Constructor<Uint8Array>}\n */\nutil.Array = typeof Uint8Array !== \"undefined\" ? Uint8Array /* istanbul ignore next */ : Array;\n\n/**\n * Any compatible Long instance.\n * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.\n * @interface Long\n * @property {number} low Low bits\n * @property {number} high High bits\n * @property {boolean} unsigned Whether unsigned or not\n */\n\n/**\n * Long.js's Long class if available.\n * @type {Constructor<Long>}\n */\nutil.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long\n         || /* istanbul ignore next */ util.global.Long\n         || util.inquire(\"long\");\n\n/**\n * Regular expression used to verify 2 bit (`bool`) map keys.\n * @type {RegExp}\n * @const\n */\nutil.key2Re = /^true|false|0|1$/;\n\n/**\n * Regular expression used to verify 32 bit (`int32` etc.) map keys.\n * @type {RegExp}\n * @const\n */\nutil.key32Re = /^-?(?:0|[1-9][0-9]*)$/;\n\n/**\n * Regular expression used to verify 64 bit (`int64` etc.) map keys.\n * @type {RegExp}\n * @const\n */\nutil.key64Re = /^(?:[\\\\x00-\\\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;\n\n/**\n * Converts a number or long to an 8 characters long hash string.\n * @param {Long|number} value Value to convert\n * @returns {string} Hash\n */\nutil.longToHash = function longToHash(value) {\n    return value\n        ? util.LongBits.from(value).toHash()\n        : util.LongBits.zeroHash;\n};\n\n/**\n * Converts an 8 characters long hash string to a long or number.\n * @param {string} hash Hash\n * @param {boolean} [unsigned=false] Whether unsigned or not\n * @returns {Long|number} Original value\n */\nutil.longFromHash = function longFromHash(hash, unsigned) {\n    var bits = util.LongBits.fromHash(hash);\n    if (util.Long)\n        return util.Long.fromBits(bits.lo, bits.hi, unsigned);\n    return bits.toNumber(Boolean(unsigned));\n};\n\n/**\n * Merges the properties of the source object into the destination object.\n * @memberof util\n * @param {Object.<string,*>} dst Destination object\n * @param {Object.<string,*>} src Source object\n * @param {boolean} [ifNotSet=false] Merges only if the key is not already set\n * @returns {Object.<string,*>} Destination object\n */\nfunction merge(dst, src, ifNotSet) { // used by converters\n    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)\n        if (dst[keys[i]] === undefined || !ifNotSet)\n            dst[keys[i]] = src[keys[i]];\n    return dst;\n}\n\nutil.merge = merge;\n\n/**\n * Converts the first character of a string to lower case.\n * @param {string} str String to convert\n * @returns {string} Converted string\n */\nutil.lcFirst = function lcFirst(str) {\n    return str.charAt(0).toLowerCase() + str.substring(1);\n};\n\n/**\n * Creates a custom error constructor.\n * @memberof util\n * @param {string} name Error name\n * @returns {Constructor<Error>} Custom error constructor\n */\nfunction newError(name) {\n\n    function CustomError(message, properties) {\n\n        if (!(this instanceof CustomError))\n            return new CustomError(message, properties);\n\n        // Error.call(this, message);\n        // ^ just returns a new error instance because the ctor can be called as a function\n\n        Object.defineProperty(this, \"message\", { get: function() { return message; } });\n\n        /* istanbul ignore next */\n        if (Error.captureStackTrace) // node\n            Error.captureStackTrace(this, CustomError);\n        else\n            Object.defineProperty(this, \"stack\", { value: new Error().stack || \"\" });\n\n        if (properties)\n            merge(this, properties);\n    }\n\n    (CustomError.prototype = Object.create(Error.prototype)).constructor = CustomError;\n\n    Object.defineProperty(CustomError.prototype, \"name\", { get: function() { return name; } });\n\n    CustomError.prototype.toString = function toString() {\n        return this.name + \": \" + this.message;\n    };\n\n    return CustomError;\n}\n\nutil.newError = newError;\n\n/**\n * Constructs a new protocol error.\n * @classdesc Error subclass indicating a protocol specifc error.\n * @memberof util\n * @extends Error\n * @template T extends Message<T>\n * @constructor\n * @param {string} message Error message\n * @param {Object.<string,*>} [properties] Additional properties\n * @example\n * try {\n *     MyMessage.decode(someBuffer); // throws if required fields are missing\n * } catch (e) {\n *     if (e instanceof ProtocolError && e.instance)\n *         console.log(\"decoded so far: \" + JSON.stringify(e.instance));\n * }\n */\nutil.ProtocolError = newError(\"ProtocolError\");\n\n/**\n * So far decoded message instance.\n * @name util.ProtocolError#instance\n * @type {Message<T>}\n */\n\n/**\n * A OneOf getter as returned by {@link util.oneOfGetter}.\n * @typedef OneOfGetter\n * @type {function}\n * @returns {string|undefined} Set field name, if any\n */\n\n/**\n * Builds a getter for a oneof's present field name.\n * @param {string[]} fieldNames Field names\n * @returns {OneOfGetter} Unbound getter\n */\nutil.oneOfGetter = function getOneOf(fieldNames) {\n    var fieldMap = {};\n    for (var i = 0; i < fieldNames.length; ++i)\n        fieldMap[fieldNames[i]] = 1;\n\n    /**\n     * @returns {string|undefined} Set field name, if any\n     * @this Object\n     * @ignore\n     */\n    return function() { // eslint-disable-line consistent-return\n        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)\n            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)\n                return keys[i];\n    };\n};\n\n/**\n * A OneOf setter as returned by {@link util.oneOfSetter}.\n * @typedef OneOfSetter\n * @type {function}\n * @param {string|undefined} value Field name\n * @returns {undefined}\n */\n\n/**\n * Builds a setter for a oneof's present field name.\n * @param {string[]} fieldNames Field names\n * @returns {OneOfSetter} Unbound setter\n */\nutil.oneOfSetter = function setOneOf(fieldNames) {\n\n    /**\n     * @param {string} name Field name\n     * @returns {undefined}\n     * @this Object\n     * @ignore\n     */\n    return function(name) {\n        for (var i = 0; i < fieldNames.length; ++i)\n            if (fieldNames[i] !== name)\n                delete this[fieldNames[i]];\n    };\n};\n\n/**\n * Default conversion options used for {@link Message#toJSON} implementations.\n *\n * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:\n *\n * - Longs become strings\n * - Enums become string keys\n * - Bytes become base64 encoded strings\n * - (Sub-)Messages become plain objects\n * - Maps become plain objects with all string keys\n * - Repeated fields become arrays\n * - NaN and Infinity for float and double fields become strings\n *\n * @type {IConversionOptions}\n * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json\n */\nutil.toJSONOptions = {\n    longs: String,\n    enums: String,\n    bytes: String,\n    json: true\n};\n\n// Sets up buffer utility according to the environment (called in index-minimal)\nutil._configure = function() {\n    var Buffer = util.Buffer;\n    /* istanbul ignore if */\n    if (!Buffer) {\n        util._Buffer_from = util._Buffer_allocUnsafe = null;\n        return;\n    }\n    // because node 4.x buffers are incompatible & immutable\n    // see: https://github.com/dcodeIO/protobuf.js/pull/665\n    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||\n        /* istanbul ignore next */\n        function Buffer_from(value, encoding) {\n            return new Buffer(value, encoding);\n        };\n    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||\n        /* istanbul ignore next */\n        function Buffer_allocUnsafe(size) {\n            return new Buffer(size);\n        };\n};\n","\"use strict\";\nmodule.exports = Writer;\n\nvar util      = require(\"./util/minimal\");\n\nvar BufferWriter; // cyclic\n\nvar LongBits  = util.LongBits,\n    base64    = util.base64,\n    utf8      = util.utf8;\n\n/**\n * Constructs a new writer operation instance.\n * @classdesc Scheduled writer operation.\n * @constructor\n * @param {function(*, Uint8Array, number)} fn Function to call\n * @param {number} len Value byte length\n * @param {*} val Value to write\n * @ignore\n */\nfunction Op(fn, len, val) {\n\n    /**\n     * Function to call.\n     * @type {function(Uint8Array, number, *)}\n     */\n    this.fn = fn;\n\n    /**\n     * Value byte length.\n     * @type {number}\n     */\n    this.len = len;\n\n    /**\n     * Next operation.\n     * @type {Writer.Op|undefined}\n     */\n    this.next = undefined;\n\n    /**\n     * Value to write.\n     * @type {*}\n     */\n    this.val = val; // type varies\n}\n\n/* istanbul ignore next */\nfunction noop() {} // eslint-disable-line no-empty-function\n\n/**\n * Constructs a new writer state instance.\n * @classdesc Copied writer state.\n * @memberof Writer\n * @constructor\n * @param {Writer} writer Writer to copy state from\n * @ignore\n */\nfunction State(writer) {\n\n    /**\n     * Current head.\n     * @type {Writer.Op}\n     */\n    this.head = writer.head;\n\n    /**\n     * Current tail.\n     * @type {Writer.Op}\n     */\n    this.tail = writer.tail;\n\n    /**\n     * Current buffer length.\n     * @type {number}\n     */\n    this.len = writer.len;\n\n    /**\n     * Next state.\n     * @type {State|null}\n     */\n    this.next = writer.states;\n}\n\n/**\n * Constructs a new writer instance.\n * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.\n * @constructor\n */\nfunction Writer() {\n\n    /**\n     * Current length.\n     * @type {number}\n     */\n    this.len = 0;\n\n    /**\n     * Operations head.\n     * @type {Object}\n     */\n    this.head = new Op(noop, 0, 0);\n\n    /**\n     * Operations tail\n     * @type {Object}\n     */\n    this.tail = this.head;\n\n    /**\n     * Linked forked states.\n     * @type {Object|null}\n     */\n    this.states = null;\n\n    // When a value is written, the writer calculates its byte length and puts it into a linked\n    // list of operations to perform when finish() is called. This both allows us to allocate\n    // buffers of the exact required size and reduces the amount of work we have to do compared\n    // to first calculating over objects and then encoding over objects. In our case, the encoding\n    // part is just a linked list walk calling operations with already prepared values.\n}\n\nvar create = function create() {\n    return util.Buffer\n        ? function create_buffer_setup() {\n            return (Writer.create = function create_buffer() {\n                return new BufferWriter();\n            })();\n        }\n        /* istanbul ignore next */\n        : function create_array() {\n            return new Writer();\n        };\n};\n\n/**\n * Creates a new writer.\n * @function\n * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}\n */\nWriter.create = create();\n\n/**\n * Allocates a buffer of the specified size.\n * @param {number} size Buffer size\n * @returns {Uint8Array} Buffer\n */\nWriter.alloc = function alloc(size) {\n    return new util.Array(size);\n};\n\n// Use Uint8Array buffer pool in the browser, just like node does with buffers\n/* istanbul ignore else */\nif (util.Array !== Array)\n    Writer.alloc = util.pool(Writer.alloc, util.Array.prototype.subarray);\n\n/**\n * Pushes a new operation to the queue.\n * @param {function(Uint8Array, number, *)} fn Function to call\n * @param {number} len Value byte length\n * @param {number} val Value to write\n * @returns {Writer} `this`\n * @private\n */\nWriter.prototype._push = function push(fn, len, val) {\n    this.tail = this.tail.next = new Op(fn, len, val);\n    this.len += len;\n    return this;\n};\n\nfunction writeByte(val, buf, pos) {\n    buf[pos] = val & 255;\n}\n\nfunction writeVarint32(val, buf, pos) {\n    while (val > 127) {\n        buf[pos++] = val & 127 | 128;\n        val >>>= 7;\n    }\n    buf[pos] = val;\n}\n\n/**\n * Constructs a new varint writer operation instance.\n * @classdesc Scheduled varint writer operation.\n * @extends Op\n * @constructor\n * @param {number} len Value byte length\n * @param {number} val Value to write\n * @ignore\n */\nfunction VarintOp(len, val) {\n    this.len = len;\n    this.next = undefined;\n    this.val = val;\n}\n\nVarintOp.prototype = Object.create(Op.prototype);\nVarintOp.prototype.fn = writeVarint32;\n\n/**\n * Writes an unsigned 32 bit value as a varint.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.uint32 = function write_uint32(value) {\n    // here, the call to this.push has been inlined and a varint specific Op subclass is used.\n    // uint32 is by far the most frequently used operation and benefits significantly from this.\n    this.len += (this.tail = this.tail.next = new VarintOp(\n        (value = value >>> 0)\n                < 128       ? 1\n        : value < 16384     ? 2\n        : value < 2097152   ? 3\n        : value < 268435456 ? 4\n        :                     5,\n    value)).len;\n    return this;\n};\n\n/**\n * Writes a signed 32 bit value as a varint.\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.int32 = function write_int32(value) {\n    return value < 0\n        ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec\n        : this.uint32(value);\n};\n\n/**\n * Writes a 32 bit value as a varint, zig-zag encoded.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.sint32 = function write_sint32(value) {\n    return this.uint32((value << 1 ^ value >> 31) >>> 0);\n};\n\nfunction writeVarint64(val, buf, pos) {\n    while (val.hi) {\n        buf[pos++] = val.lo & 127 | 128;\n        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;\n        val.hi >>>= 7;\n    }\n    while (val.lo > 127) {\n        buf[pos++] = val.lo & 127 | 128;\n        val.lo = val.lo >>> 7;\n    }\n    buf[pos++] = val.lo;\n}\n\n/**\n * Writes an unsigned 64 bit value as a varint.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.uint64 = function write_uint64(value) {\n    var bits = LongBits.from(value);\n    return this._push(writeVarint64, bits.length(), bits);\n};\n\n/**\n * Writes a signed 64 bit value as a varint.\n * @function\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.int64 = Writer.prototype.uint64;\n\n/**\n * Writes a signed 64 bit value as a varint, zig-zag encoded.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.sint64 = function write_sint64(value) {\n    var bits = LongBits.from(value).zzEncode();\n    return this._push(writeVarint64, bits.length(), bits);\n};\n\n/**\n * Writes a boolish value as a varint.\n * @param {boolean} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.bool = function write_bool(value) {\n    return this._push(writeByte, 1, value ? 1 : 0);\n};\n\nfunction writeFixed32(val, buf, pos) {\n    buf[pos    ] =  val         & 255;\n    buf[pos + 1] =  val >>> 8   & 255;\n    buf[pos + 2] =  val >>> 16  & 255;\n    buf[pos + 3] =  val >>> 24;\n}\n\n/**\n * Writes an unsigned 32 bit value as fixed 32 bits.\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.fixed32 = function write_fixed32(value) {\n    return this._push(writeFixed32, 4, value >>> 0);\n};\n\n/**\n * Writes a signed 32 bit value as fixed 32 bits.\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.sfixed32 = Writer.prototype.fixed32;\n\n/**\n * Writes an unsigned 64 bit value as fixed 64 bits.\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.fixed64 = function write_fixed64(value) {\n    var bits = LongBits.from(value);\n    return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);\n};\n\n/**\n * Writes a signed 64 bit value as fixed 64 bits.\n * @function\n * @param {Long|number|string} value Value to write\n * @returns {Writer} `this`\n * @throws {TypeError} If `value` is a string and no long library is present.\n */\nWriter.prototype.sfixed64 = Writer.prototype.fixed64;\n\n/**\n * Writes a float (32 bit).\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.float = function write_float(value) {\n    return this._push(util.float.writeFloatLE, 4, value);\n};\n\n/**\n * Writes a double (64 bit float).\n * @function\n * @param {number} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.double = function write_double(value) {\n    return this._push(util.float.writeDoubleLE, 8, value);\n};\n\nvar writeBytes = util.Array.prototype.set\n    ? function writeBytes_set(val, buf, pos) {\n        buf.set(val, pos); // also works for plain array values\n    }\n    /* istanbul ignore next */\n    : function writeBytes_for(val, buf, pos) {\n        for (var i = 0; i < val.length; ++i)\n            buf[pos + i] = val[i];\n    };\n\n/**\n * Writes a sequence of bytes.\n * @param {Uint8Array|string} value Buffer or base64 encoded string to write\n * @returns {Writer} `this`\n */\nWriter.prototype.bytes = function write_bytes(value) {\n    var len = value.length >>> 0;\n    if (!len)\n        return this._push(writeByte, 1, 0);\n    if (util.isString(value)) {\n        var buf = Writer.alloc(len = base64.length(value));\n        base64.decode(value, buf, 0);\n        value = buf;\n    }\n    return this.uint32(len)._push(writeBytes, len, value);\n};\n\n/**\n * Writes a string.\n * @param {string} value Value to write\n * @returns {Writer} `this`\n */\nWriter.prototype.string = function write_string(value) {\n    var len = utf8.length(value);\n    return len\n        ? this.uint32(len)._push(utf8.write, len, value)\n        : this._push(writeByte, 1, 0);\n};\n\n/**\n * Forks this writer's state by pushing it to a stack.\n * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.\n * @returns {Writer} `this`\n */\nWriter.prototype.fork = function fork() {\n    this.states = new State(this);\n    this.head = this.tail = new Op(noop, 0, 0);\n    this.len = 0;\n    return this;\n};\n\n/**\n * Resets this instance to the last state.\n * @returns {Writer} `this`\n */\nWriter.prototype.reset = function reset() {\n    if (this.states) {\n        this.head   = this.states.head;\n        this.tail   = this.states.tail;\n        this.len    = this.states.len;\n        this.states = this.states.next;\n    } else {\n        this.head = this.tail = new Op(noop, 0, 0);\n        this.len  = 0;\n    }\n    return this;\n};\n\n/**\n * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.\n * @returns {Writer} `this`\n */\nWriter.prototype.ldelim = function ldelim() {\n    var head = this.head,\n        tail = this.tail,\n        len  = this.len;\n    this.reset().uint32(len);\n    if (len) {\n        this.tail.next = head.next; // skip noop\n        this.tail = tail;\n        this.len += len;\n    }\n    return this;\n};\n\n/**\n * Finishes the write operation.\n * @returns {Uint8Array} Finished buffer\n */\nWriter.prototype.finish = function finish() {\n    var head = this.head.next, // skip noop\n        buf  = this.constructor.alloc(this.len),\n        pos  = 0;\n    while (head) {\n        head.fn(head.val, buf, pos);\n        pos += head.len;\n        head = head.next;\n    }\n    // this.head = this.tail = null;\n    return buf;\n};\n\nWriter._configure = function(BufferWriter_) {\n    BufferWriter = BufferWriter_;\n    Writer.create = create();\n    BufferWriter._configure();\n};\n","\"use strict\";\nmodule.exports = BufferWriter;\n\n// extends Writer\nvar Writer = require(\"./writer\");\n(BufferWriter.prototype = Object.create(Writer.prototype)).constructor = BufferWriter;\n\nvar util = require(\"./util/minimal\");\n\n/**\n * Constructs a new buffer writer instance.\n * @classdesc Wire format writer using node buffers.\n * @extends Writer\n * @constructor\n */\nfunction BufferWriter() {\n    Writer.call(this);\n}\n\nBufferWriter._configure = function () {\n    /**\n     * Allocates a buffer of the specified size.\n     * @function\n     * @param {number} size Buffer size\n     * @returns {Buffer} Buffer\n     */\n    BufferWriter.alloc = util._Buffer_allocUnsafe;\n\n    BufferWriter.writeBytesBuffer = util.Buffer && util.Buffer.prototype instanceof Uint8Array && util.Buffer.prototype.set.name === \"set\"\n        ? function writeBytesBuffer_set(val, buf, pos) {\n          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)\n          // also works for plain array values\n        }\n        /* istanbul ignore next */\n        : function writeBytesBuffer_copy(val, buf, pos) {\n          if (val.copy) // Buffer values\n            val.copy(buf, pos, 0, val.length);\n          else for (var i = 0; i < val.length;) // plain array values\n            buf[pos++] = val[i++];\n        };\n};\n\n\n/**\n * @override\n */\nBufferWriter.prototype.bytes = function write_bytes_buffer(value) {\n    if (util.isString(value))\n        value = util._Buffer_from(value, \"base64\");\n    var len = value.length >>> 0;\n    this.uint32(len);\n    if (len)\n        this._push(BufferWriter.writeBytesBuffer, len, value);\n    return this;\n};\n\nfunction writeStringBuffer(val, buf, pos) {\n    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)\n        util.utf8.write(val, buf, pos);\n    else if (buf.utf8Write)\n        buf.utf8Write(val, pos);\n    else\n        buf.write(val, pos);\n}\n\n/**\n * @override\n */\nBufferWriter.prototype.string = function write_string_buffer(value) {\n    var len = util.Buffer.byteLength(value);\n    this.uint32(len);\n    if (len)\n        this._push(writeStringBuffer, len, value);\n    return this;\n};\n\n\n/**\n * Finishes the write operation.\n * @name BufferWriter#finish\n * @function\n * @returns {Buffer} Finished buffer\n */\n\nBufferWriter._configure();\n",null,"const Rabin = require('./rabin')\nconst getRabin = require('../dist/rabin-wasm.node.js')\n\nconst create = async (avg, min, max, windowSize, polynomial) => {\n    const compiled = await getRabin()\n    return new Rabin(compiled, avg, min, max, windowSize, polynomial)\n}\n\nmodule.exports = {\n    Rabin,\n    create\n}\n","/**\n * Rabin fingerprinting\n *\n * @class Rabin\n */\nclass Rabin {\n    /**\n     * Creates an instance of Rabin.\n     * @param { import(\"./../dist/rabin-wasm\") } asModule\n     * @param {number} [bits=12]\n     * @param {number} [min=8 * 1024]\n     * @param {number} [max=32 * 1024]\n     * @param {number} polynomial\n     * @memberof Rabin\n     */\n    constructor(asModule, bits = 12, min = 8 * 1024, max = 32 * 1024, windowSize = 64, polynomial) {\n        this.bits = bits\n        this.min = min\n        this.max = max\n        this.asModule = asModule\n        this.rabin = new asModule.Rabin(bits, min, max, windowSize, polynomial)\n        this.polynomial = polynomial\n    }\n\n    /**\n     * Fingerprints the buffer\n     *\n     * @param {Uint8Array} buf\n     * @returns {Array<number>}\n     * @memberof Rabin\n     */\n    fingerprint(buf) {\n        const {\n            __retain,\n            __release,\n            __allocArray,\n            __getInt32Array,\n            Int32Array_ID,\n            Uint8Array_ID\n        } = this.asModule\n\n        const lengths = new Int32Array(Math.ceil(buf.length/this.min))\n        const lengthsPtr = __retain(__allocArray(Int32Array_ID, lengths))\n        const pointer = __retain(__allocArray(Uint8Array_ID, buf))\n\n        const out = this.rabin.fingerprint(pointer, lengthsPtr)\n        const processed = __getInt32Array(out)\n\n        __release(pointer)\n        __release(lengthsPtr)\n\n        const end = processed.indexOf(0);\n        return end >= 0 ? processed.subarray(0, end) : processed;\n    }\n}\n\nmodule.exports = Rabin","module.exports = require('./lib/retry');","var RetryOperation = require('./retry_operation');\n\nexports.operation = function(options) {\n  var timeouts = exports.timeouts(options);\n  return new RetryOperation(timeouts, {\n      forever: options && (options.forever || options.retries === Infinity),\n      unref: options && options.unref,\n      maxRetryTime: options && options.maxRetryTime\n  });\n};\n\nexports.timeouts = function(options) {\n  if (options instanceof Array) {\n    return [].concat(options);\n  }\n\n  var opts = {\n    retries: 10,\n    factor: 2,\n    minTimeout: 1 * 1000,\n    maxTimeout: Infinity,\n    randomize: false\n  };\n  for (var key in options) {\n    opts[key] = options[key];\n  }\n\n  if (opts.minTimeout > opts.maxTimeout) {\n    throw new Error('minTimeout is greater than maxTimeout');\n  }\n\n  var timeouts = [];\n  for (var i = 0; i < opts.retries; i++) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  if (options && options.forever && !timeouts.length) {\n    timeouts.push(this.createTimeout(i, opts));\n  }\n\n  // sort the array numerically ascending\n  timeouts.sort(function(a,b) {\n    return a - b;\n  });\n\n  return timeouts;\n};\n\nexports.createTimeout = function(attempt, opts) {\n  var random = (opts.randomize)\n    ? (Math.random() + 1)\n    : 1;\n\n  var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));\n  timeout = Math.min(timeout, opts.maxTimeout);\n\n  return timeout;\n};\n\nexports.wrap = function(obj, options, methods) {\n  if (options instanceof Array) {\n    methods = options;\n    options = null;\n  }\n\n  if (!methods) {\n    methods = [];\n    for (var key in obj) {\n      if (typeof obj[key] === 'function') {\n        methods.push(key);\n      }\n    }\n  }\n\n  for (var i = 0; i < methods.length; i++) {\n    var method   = methods[i];\n    var original = obj[method];\n\n    obj[method] = function retryWrapper(original) {\n      var op       = exports.operation(options);\n      var args     = Array.prototype.slice.call(arguments, 1);\n      var callback = args.pop();\n\n      args.push(function(err) {\n        if (op.retry(err)) {\n          return;\n        }\n        if (err) {\n          arguments[0] = op.mainError();\n        }\n        callback.apply(this, arguments);\n      });\n\n      op.attempt(function() {\n        original.apply(obj, args);\n      });\n    }.bind(obj, original);\n    obj[method].options = options;\n  }\n};\n","function RetryOperation(timeouts, options) {\n  // Compatibility for the old (timeouts, retryForever) signature\n  if (typeof options === 'boolean') {\n    options = { forever: options };\n  }\n\n  this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));\n  this._timeouts = timeouts;\n  this._options = options || {};\n  this._maxRetryTime = options && options.maxRetryTime || Infinity;\n  this._fn = null;\n  this._errors = [];\n  this._attempts = 1;\n  this._operationTimeout = null;\n  this._operationTimeoutCb = null;\n  this._timeout = null;\n  this._operationStart = null;\n  this._timer = null;\n\n  if (this._options.forever) {\n    this._cachedTimeouts = this._timeouts.slice(0);\n  }\n}\nmodule.exports = RetryOperation;\n\nRetryOperation.prototype.reset = function() {\n  this._attempts = 1;\n  this._timeouts = this._originalTimeouts.slice(0);\n}\n\nRetryOperation.prototype.stop = function() {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n  if (this._timer) {\n    clearTimeout(this._timer);\n  }\n\n  this._timeouts       = [];\n  this._cachedTimeouts = null;\n};\n\nRetryOperation.prototype.retry = function(err) {\n  if (this._timeout) {\n    clearTimeout(this._timeout);\n  }\n\n  if (!err) {\n    return false;\n  }\n  var currentTime = new Date().getTime();\n  if (err && currentTime - this._operationStart >= this._maxRetryTime) {\n    this._errors.push(err);\n    this._errors.unshift(new Error('RetryOperation timeout occurred'));\n    return false;\n  }\n\n  this._errors.push(err);\n\n  var timeout = this._timeouts.shift();\n  if (timeout === undefined) {\n    if (this._cachedTimeouts) {\n      // retry forever, only keep last error\n      this._errors.splice(0, this._errors.length - 1);\n      timeout = this._cachedTimeouts.slice(-1);\n    } else {\n      return false;\n    }\n  }\n\n  var self = this;\n  this._timer = setTimeout(function() {\n    self._attempts++;\n\n    if (self._operationTimeoutCb) {\n      self._timeout = setTimeout(function() {\n        self._operationTimeoutCb(self._attempts);\n      }, self._operationTimeout);\n\n      if (self._options.unref) {\n          self._timeout.unref();\n      }\n    }\n\n    self._fn(self._attempts);\n  }, timeout);\n\n  if (this._options.unref) {\n      this._timer.unref();\n  }\n\n  return true;\n};\n\nRetryOperation.prototype.attempt = function(fn, timeoutOps) {\n  this._fn = fn;\n\n  if (timeoutOps) {\n    if (timeoutOps.timeout) {\n      this._operationTimeout = timeoutOps.timeout;\n    }\n    if (timeoutOps.cb) {\n      this._operationTimeoutCb = timeoutOps.cb;\n    }\n  }\n\n  var self = this;\n  if (this._operationTimeoutCb) {\n    this._timeout = setTimeout(function() {\n      self._operationTimeoutCb();\n    }, self._operationTimeout);\n  }\n\n  this._operationStart = new Date().getTime();\n\n  this._fn(this._attempts);\n};\n\nRetryOperation.prototype.try = function(fn) {\n  console.log('Using RetryOperation.try() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = function(fn) {\n  console.log('Using RetryOperation.start() is deprecated');\n  this.attempt(fn);\n};\n\nRetryOperation.prototype.start = RetryOperation.prototype.try;\n\nRetryOperation.prototype.errors = function() {\n  return this._errors;\n};\n\nRetryOperation.prototype.attempts = function() {\n  return this._attempts;\n};\n\nRetryOperation.prototype.mainError = function() {\n  if (this._errors.length === 0) {\n    return null;\n  }\n\n  var counts = {};\n  var mainError = null;\n  var mainErrorCount = 0;\n\n  for (var i = 0; i < this._errors.length; i++) {\n    var error = this._errors[i];\n    var message = error.message;\n    var count = (counts[message] || 0) + 1;\n\n    counts[message] = count;\n\n    if (count >= mainErrorCount) {\n      mainError = error;\n      mainErrorCount = count;\n    }\n  }\n\n  return mainError;\n};\n","'use strict'\n\n// JS treats subjects of bitwise operators as SIGNED 32 bit numbers,\n// which means the maximum amount of bits we can store inside each byte\n// is 7..\nconst BITS_PER_BYTE = 7\n\nmodule.exports = class SparseArray {\n  constructor () {\n    this._bitArrays = []\n    this._data = []\n    this._length = 0\n    this._changedLength = false\n    this._changedData = false\n  }\n\n  set (index, value) {\n    let pos = this._internalPositionFor(index, false)\n    if (value === undefined) {\n      // unsetting\n      if (pos !== -1) {\n        // remove item from bit array and array itself\n        this._unsetInternalPos(pos)\n        this._unsetBit(index)\n        this._changedLength = true\n        this._changedData = true\n      }\n    } else {\n      let needsSort = false\n      if (pos === -1) {\n        pos = this._data.length\n        this._setBit(index)\n        this._changedData = true\n      } else {\n        needsSort = true\n      }\n      this._setInternalPos(pos, index, value, needsSort)\n      this._changedLength = true\n    }\n  }\n\n  unset (index) {\n    this.set(index, undefined)\n  }\n\n  get (index) {\n    this._sortData()\n    const pos = this._internalPositionFor(index, true)\n    if (pos === -1) {\n      return undefined\n    }\n    return this._data[pos][1]\n  }\n\n  push (value) {\n    this.set(this.length, value)\n    return this.length\n  }\n\n  get length () {\n    this._sortData()\n    if (this._changedLength) {\n      const last = this._data[this._data.length - 1]\n      this._length = last ? last[0] + 1 : 0\n      this._changedLength = false\n    }\n    return this._length\n  }\n\n  forEach (iterator) {\n    let i = 0\n    while(i < this.length) {\n      iterator(this.get(i), i, this)\n      i++\n    }\n  }\n\n  map (iterator) {\n    let i = 0\n    let mapped = new Array(this.length)\n    while(i < this.length) {\n      mapped[i] = iterator(this.get(i), i, this)\n      i++\n    }\n    return mapped\n  }\n\n  reduce (reducer, initialValue) {\n    let i = 0\n    let acc = initialValue\n    while(i < this.length) {\n      const value = this.get(i)\n      acc = reducer(acc, value, i)\n      i++\n    }\n    return acc\n  }\n\n  find (finder) {\n    let i = 0, found, last\n    while ((i < this.length) && !found) {\n      last = this.get(i)\n      found = finder(last)\n      i++\n    }\n    return found ? last : undefined\n  }\n\n  _internalPositionFor (index, noCreate) {\n    const bytePos = this._bytePosFor(index, noCreate)\n    if (bytePos >= this._bitArrays.length) {\n      return -1\n    }\n    const byte = this._bitArrays[bytePos]\n    const bitPos = index - bytePos * BITS_PER_BYTE\n    const exists = (byte & (1 << bitPos)) > 0\n    if (!exists) {\n      return -1\n    }\n    const previousPopCount = this._bitArrays.slice(0, bytePos).reduce(popCountReduce, 0)\n\n    const mask = ~(0xffffffff << (bitPos + 1))\n    const bytePopCount = popCount(byte & mask)\n    const arrayPos = previousPopCount + bytePopCount - 1\n    return arrayPos\n  }\n\n  _bytePosFor (index, noCreate) {\n    const bytePos = Math.floor(index / BITS_PER_BYTE)\n    const targetLength = bytePos + 1\n    while (!noCreate && this._bitArrays.length < targetLength) {\n      this._bitArrays.push(0)\n    }\n    return bytePos\n  }\n\n  _setBit (index) {\n    const bytePos = this._bytePosFor(index, false)\n    this._bitArrays[bytePos] |= (1 << (index - (bytePos * BITS_PER_BYTE)))\n  }\n\n  _unsetBit(index) {\n    const bytePos = this._bytePosFor(index, false)\n    this._bitArrays[bytePos] &= ~(1 << (index - (bytePos * BITS_PER_BYTE)))\n  }\n\n  _setInternalPos(pos, index, value, needsSort) {\n    const data =this._data\n    const elem = [index, value]\n    if (needsSort) {\n      this._sortData()\n      data[pos] = elem\n    } else {\n      // new element. just shove it into the array\n      // but be nice about where we shove it\n      // in order to make sorting it later easier\n      if (data.length) {\n        if (data[data.length - 1][0] >= index) {\n          data.push(elem)\n        } else if (data[0][0] <= index) {\n          data.unshift(elem)\n        } else {\n          const randomIndex = Math.round(data.length / 2)\n          this._data = data.slice(0, randomIndex).concat(elem).concat(data.slice(randomIndex))\n        }\n      } else {\n        this._data.push(elem)\n      }\n      this._changedData = true\n      this._changedLength = true\n    }\n  }\n\n  _unsetInternalPos (pos) {\n    this._data.splice(pos, 1)\n  }\n\n  _sortData () {\n    if (this._changedData) {\n      this._data.sort(sortInternal)\n    }\n\n    this._changedData = false\n  }\n\n  bitField () {\n    const bytes = []\n    let pendingBitsForResultingByte = 8\n    let pendingBitsForNewByte = 0\n    let resultingByte = 0\n    let newByte\n    const pending = this._bitArrays.slice()\n    while (pending.length || pendingBitsForNewByte) {\n      if (pendingBitsForNewByte === 0) {\n        newByte = pending.shift()\n        pendingBitsForNewByte = 7\n      }\n\n      const usingBits = Math.min(pendingBitsForNewByte, pendingBitsForResultingByte)\n      const mask = ~(0b11111111 << usingBits)\n      const masked = newByte & mask\n      resultingByte |= masked << (8 - pendingBitsForResultingByte)\n      newByte = newByte >>> usingBits\n      pendingBitsForNewByte -= usingBits\n      pendingBitsForResultingByte -= usingBits\n\n      if (!pendingBitsForResultingByte || (!pendingBitsForNewByte && !pending.length)) {\n        bytes.push(resultingByte)\n        resultingByte = 0\n        pendingBitsForResultingByte = 8\n      }\n    }\n\n    // remove trailing zeroes\n    for(var i = bytes.length - 1; i > 0; i--) {\n      const value = bytes[i]\n      if (value === 0) {\n        bytes.pop()\n      } else {\n        break\n      }\n    }\n\n    return bytes\n  }\n\n  compactArray () {\n    this._sortData()\n    return this._data.map(valueOnly)\n  }\n}\n\nfunction popCountReduce (count, byte) {\n  return count + popCount(byte)\n}\n\nfunction popCount(_v) {\n  let v = _v\n  v = v - ((v >> 1) & 0x55555555)                    // reuse input as temporary\n  v = (v & 0x33333333) + ((v >> 2) & 0x33333333)     // temp\n  return ((v + (v >> 4) & 0xF0F0F0F) * 0x1010101) >> 24\n}\n\nfunction sortInternal (a, b) {\n  return a[0] - b[0]\n}\n\nfunction valueOnly (elem) {\n  return elem[1]\n}","(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n    typeof define === 'function' && define.amd ? define(['exports'], factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.streamingIterables = {}));\n}(this, (function (exports) { 'use strict';\n\n    async function* _batch(size, iterable) {\n        let dataBatch = [];\n        for await (const data of iterable) {\n            dataBatch.push(data);\n            if (dataBatch.length === size) {\n                yield dataBatch;\n                dataBatch = [];\n            }\n        }\n        if (dataBatch.length > 0) {\n            yield dataBatch;\n        }\n    }\n    function* _syncBatch(size, iterable) {\n        let dataBatch = [];\n        for (const data of iterable) {\n            dataBatch.push(data);\n            if (dataBatch.length === size) {\n                yield dataBatch;\n                dataBatch = [];\n            }\n        }\n        if (dataBatch.length > 0) {\n            yield dataBatch;\n        }\n    }\n    function batch(size, iterable) {\n        if (iterable === undefined) {\n            return curriedIterable => batch(size, curriedIterable);\n        }\n        if (iterable[Symbol.asyncIterator]) {\n            return _batch(size, iterable);\n        }\n        return _syncBatch(size, iterable);\n    }\n\n    function getIterator(iterable) {\n        if (typeof iterable.next === 'function') {\n            return iterable;\n        }\n        if (typeof iterable[Symbol.iterator] === 'function') {\n            return iterable[Symbol.iterator]();\n        }\n        if (typeof iterable[Symbol.asyncIterator] === 'function') {\n            return iterable[Symbol.asyncIterator]();\n        }\n        throw new TypeError('\"values\" does not to conform to any of the iterator or iterable protocols');\n    }\n\n    function defer() {\n        let reject;\n        let resolve;\n        const promise = new Promise((resolveFunc, rejectFunc) => {\n            resolve = resolveFunc;\n            reject = rejectFunc;\n        });\n        return {\n            promise,\n            reject,\n            resolve,\n        };\n    }\n\n    /// <reference lib=\"esnext.asynciterable\" />\n    function _buffer(size, iterable) {\n        const iterator = getIterator(iterable);\n        const resultQueue = [];\n        const readQueue = [];\n        let reading = false;\n        let ended = false;\n        function fulfillReadQueue() {\n            while (readQueue.length > 0 && resultQueue.length > 0) {\n                const readDeferred = readQueue.shift();\n                const { error, value } = resultQueue.shift();\n                if (error) {\n                    readDeferred.reject(error);\n                }\n                else {\n                    readDeferred.resolve({ done: false, value });\n                }\n            }\n            while (readQueue.length > 0 && ended) {\n                const { resolve } = readQueue.shift();\n                resolve({ done: true, value: undefined });\n            }\n        }\n        async function fillQueue() {\n            if (ended) {\n                return;\n            }\n            if (reading) {\n                return;\n            }\n            if (resultQueue.length >= size) {\n                return;\n            }\n            reading = true;\n            try {\n                const { done, value } = await iterator.next();\n                if (done) {\n                    ended = true;\n                }\n                else {\n                    resultQueue.push({ value });\n                }\n            }\n            catch (error) {\n                ended = true;\n                resultQueue.push({ error });\n            }\n            fulfillReadQueue();\n            reading = false;\n            fillQueue();\n        }\n        async function next() {\n            if (resultQueue.length > 0) {\n                const { error, value } = resultQueue.shift();\n                if (error) {\n                    throw error;\n                }\n                fillQueue();\n                return { done: false, value };\n            }\n            if (ended) {\n                return { done: true, value: undefined }; // stupid ts\n            }\n            const deferred = defer();\n            readQueue.push(deferred);\n            fillQueue();\n            return deferred.promise;\n        }\n        const asyncIterableIterator = {\n            next,\n            [Symbol.asyncIterator]: () => asyncIterableIterator,\n        };\n        return asyncIterableIterator;\n    }\n    function* syncBuffer(size, iterable) {\n        const valueQueue = [];\n        let e;\n        try {\n            for (const value of iterable) {\n                valueQueue.push(value);\n                if (valueQueue.length <= size) {\n                    continue;\n                }\n                yield valueQueue.shift();\n            }\n        }\n        catch (error) {\n            e = error;\n        }\n        for (const value of valueQueue) {\n            yield value;\n        }\n        if (e) {\n            throw e;\n        }\n    }\n    function buffer(size, iterable) {\n        if (iterable === undefined) {\n            return curriedIterable => buffer(size, curriedIterable);\n        }\n        if (size === 0) {\n            return iterable;\n        }\n        if (iterable[Symbol.asyncIterator]) {\n            return _buffer(size, iterable);\n        }\n        return syncBuffer(size, iterable);\n    }\n\n    async function _collect(iterable) {\n        const values = [];\n        for await (const value of iterable) {\n            values.push(value);\n        }\n        return values;\n    }\n    function collect(iterable) {\n        if (iterable[Symbol.asyncIterator]) {\n            return _collect(iterable);\n        }\n        return Array.from(iterable);\n    }\n\n    async function* _concat(iterables) {\n        for await (const iterable of iterables) {\n            yield* iterable;\n        }\n    }\n    function* _syncConcat(iterables) {\n        for (const iterable of iterables) {\n            yield* iterable;\n        }\n    }\n    function concat(...iterables) {\n        const hasAnyAsync = iterables.find(itr => itr[Symbol.asyncIterator] !== undefined);\n        if (hasAnyAsync) {\n            return _concat(iterables);\n        }\n        else {\n            return _syncConcat(iterables);\n        }\n    }\n\n    async function _consume(iterable) {\n        for await (const val of iterable) {\n            // do nothing\n        }\n    }\n    function consume(iterable) {\n        if (iterable[Symbol.asyncIterator]) {\n            return _consume(iterable);\n        }\n        for (const val of iterable) {\n            // do nothing\n        }\n    }\n\n    async function* _filter(filterFunc, iterable) {\n        for await (const data of iterable) {\n            if (await filterFunc(data)) {\n                yield data;\n            }\n        }\n    }\n    function filter(filterFunc, iterable) {\n        if (iterable === undefined) {\n            return (curriedIterable) => _filter(filterFunc, curriedIterable);\n        }\n        return _filter(filterFunc, iterable);\n    }\n\n    async function* flatten(iterable) {\n        for await (const maybeItr of iterable) {\n            if (maybeItr && typeof maybeItr !== 'string' && (maybeItr[Symbol.iterator] || maybeItr[Symbol.asyncIterator])) {\n                yield* flatten(maybeItr);\n            }\n            else {\n                yield maybeItr;\n            }\n        }\n    }\n\n    async function* _map(func, iterable) {\n        for await (const val of iterable) {\n            yield await func(val);\n        }\n    }\n    function map(func, iterable) {\n        if (iterable === undefined) {\n            return curriedIterable => _map(func, curriedIterable);\n        }\n        return _map(func, iterable);\n    }\n\n    function flatMap(func, iterable) {\n        if (iterable === undefined) {\n            return curriedIterable => flatMap(func, curriedIterable);\n        }\n        return filter(i => i !== undefined && i !== null, flatten(map(func, iterable)));\n    }\n\n    function _flatTransform(concurrency, func, iterable) {\n        const iterator = getIterator(iterable);\n        const resultQueue = [];\n        const readQueue = [];\n        let ended = false;\n        let reading = false;\n        let inflightCount = 0;\n        let lastError = null;\n        function fulfillReadQueue() {\n            while (readQueue.length > 0 && resultQueue.length > 0) {\n                const { resolve } = readQueue.shift();\n                const value = resultQueue.shift();\n                resolve({ done: false, value });\n            }\n            while (readQueue.length > 0 && inflightCount === 0 && ended) {\n                const { resolve, reject } = readQueue.shift();\n                if (lastError) {\n                    reject(lastError);\n                    lastError = null;\n                }\n                else {\n                    resolve({ done: true, value: undefined });\n                }\n            }\n        }\n        async function fillQueue() {\n            if (ended) {\n                fulfillReadQueue();\n                return;\n            }\n            if (reading) {\n                return;\n            }\n            if (inflightCount + resultQueue.length >= concurrency) {\n                return;\n            }\n            reading = true;\n            inflightCount++;\n            try {\n                const { done, value } = await iterator.next();\n                if (done) {\n                    ended = true;\n                    inflightCount--;\n                    fulfillReadQueue();\n                }\n                else {\n                    mapAndQueue(value);\n                }\n            }\n            catch (error) {\n                ended = true;\n                inflightCount--;\n                lastError = error;\n                fulfillReadQueue();\n            }\n            reading = false;\n            fillQueue();\n        }\n        async function mapAndQueue(itrValue) {\n            try {\n                const value = await func(itrValue);\n                if (value && value[Symbol.asyncIterator]) {\n                    for await (const asyncVal of value) {\n                        resultQueue.push(asyncVal);\n                    }\n                }\n                else {\n                    resultQueue.push(value);\n                }\n            }\n            catch (error) {\n                ended = true;\n                lastError = error;\n            }\n            inflightCount--;\n            fulfillReadQueue();\n            fillQueue();\n        }\n        async function next() {\n            if (resultQueue.length === 0) {\n                const deferred = defer();\n                readQueue.push(deferred);\n                fillQueue();\n                return deferred.promise;\n            }\n            const value = resultQueue.shift();\n            fillQueue();\n            return { done: false, value };\n        }\n        const asyncIterableIterator = {\n            next,\n            [Symbol.asyncIterator]: () => asyncIterableIterator,\n        };\n        return asyncIterableIterator;\n    }\n    function flatTransform(concurrency, func, iterable) {\n        if (func === undefined) {\n            return (curriedFunc, curriedIterable) => curriedIterable\n                ? flatTransform(concurrency, curriedFunc, curriedIterable)\n                : flatTransform(concurrency, curriedFunc);\n        }\n        if (iterable === undefined) {\n            return (curriedIterable) => flatTransform(concurrency, func, curriedIterable);\n        }\n        return filter(i => i !== undefined && i !== null, flatten(_flatTransform(concurrency, func, iterable)));\n    }\n\n    async function onceReadable(stream) {\n        return new Promise(resolve => {\n            stream.once('readable', () => {\n                resolve();\n            });\n        });\n    }\n    async function* _fromStream(stream) {\n        while (true) {\n            const data = stream.read();\n            if (data !== null) {\n                yield data;\n                continue;\n            }\n            if (stream._readableState.ended) {\n                break;\n            }\n            await onceReadable(stream);\n        }\n    }\n    function fromStream(stream) {\n        if (typeof stream[Symbol.asyncIterator] === 'function') {\n            return stream;\n        }\n        return _fromStream(stream);\n    }\n\n    async function* merge(...iterables) {\n        const sources = new Set(iterables.map(getIterator));\n        while (sources.size > 0) {\n            for (const iterator of sources) {\n                const nextVal = await iterator.next();\n                if (nextVal.done) {\n                    sources.delete(iterator);\n                }\n                else {\n                    yield nextVal.value;\n                }\n            }\n        }\n    }\n\n    function pipeline(firstFn, ...fns) {\n        let previousFn = firstFn();\n        for (const func of fns) {\n            previousFn = func(previousFn);\n        }\n        return previousFn;\n    }\n\n    async function* _parallelMap(concurrency, func, iterable) {\n        let transformError = null;\n        const wrapFunc = value => ({\n            value: func(value),\n        });\n        const stopOnError = async function* (source) {\n            for await (const value of source) {\n                if (transformError) {\n                    return;\n                }\n                yield value;\n            }\n        };\n        const output = pipeline(() => iterable, buffer(1), stopOnError, map(wrapFunc), buffer(concurrency - 1));\n        const itr = getIterator(output);\n        while (true) {\n            const { value, done } = await itr.next();\n            if (done) {\n                break;\n            }\n            try {\n                const val = await value.value;\n                if (!transformError) {\n                    yield val;\n                }\n            }\n            catch (error) {\n                transformError = error;\n            }\n        }\n        if (transformError) {\n            throw transformError;\n        }\n    }\n    function parallelMap(concurrency, func, iterable) {\n        if (func === undefined) {\n            return (curriedFunc, curriedIterable) => parallelMap(concurrency, curriedFunc, curriedIterable);\n        }\n        if (iterable === undefined) {\n            return curriedIterable => parallelMap(concurrency, func, curriedIterable);\n        }\n        if (concurrency === 1) {\n            return map(func, iterable);\n        }\n        return _parallelMap(concurrency, func, iterable);\n    }\n\n    function parallelFlatMap(concurrency, func, iterable) {\n        if (func === undefined) {\n            return (curriedFunc, curriedIterable) => curriedIterable\n                ? parallelFlatMap(concurrency, curriedFunc, curriedIterable)\n                : parallelFlatMap(concurrency, curriedFunc);\n        }\n        if (iterable === undefined) {\n            return (curriedIterable) => parallelFlatMap(concurrency, func, curriedIterable);\n        }\n        return filter(i => i !== undefined && i !== null, flatten(parallelMap(concurrency, func, iterable)));\n    }\n\n    /// <reference lib=\"esnext.asynciterable\" />\n    async function* parallelMerge(...iterables) {\n        const inputs = iterables.map(getIterator);\n        const concurrentWork = new Set();\n        const values = new Map();\n        let lastError = null;\n        let errCb = null;\n        let valueCb = null;\n        const notifyError = err => {\n            lastError = err;\n            if (errCb) {\n                errCb(err);\n            }\n        };\n        const notifyDone = value => {\n            if (valueCb) {\n                valueCb(value);\n            }\n        };\n        const waitForQueue = () => new Promise((resolve, reject) => {\n            if (lastError) {\n                reject(lastError);\n            }\n            if (values.size > 0) {\n                return resolve();\n            }\n            valueCb = resolve;\n            errCb = reject;\n        });\n        const queueNext = input => {\n            const nextVal = Promise.resolve(input.next()).then(async ({ done, value }) => {\n                if (!done) {\n                    values.set(input, value);\n                }\n                concurrentWork.delete(nextVal);\n            });\n            concurrentWork.add(nextVal);\n            nextVal.then(notifyDone, notifyError);\n        };\n        for (const input of inputs) {\n            queueNext(input);\n        }\n        while (true) {\n            // We technically don't have to check `values.size` as the for loop should have emptied it\n            // However I haven't yet found specs verifying that behavior, only tests\n            // the guard in waitForQueue() checking for values is in place for the same reason\n            if (concurrentWork.size === 0 && values.size === 0) {\n                return;\n            }\n            await waitForQueue();\n            for (const [input, value] of values) {\n                values.delete(input);\n                yield value;\n                queueNext(input);\n            }\n        }\n    }\n\n    async function _reduce(func, start, iterable) {\n        let value = start;\n        for await (const nextItem of iterable) {\n            value = await func(value, nextItem);\n        }\n        return value;\n    }\n    function reduce(func, start, iterable) {\n        if (start === undefined) {\n            return (curriedStart, curriedIterable) => curriedIterable ? _reduce(func, curriedStart, curriedIterable) : reduce(func, curriedStart);\n        }\n        if (iterable === undefined) {\n            return (curriedIterable) => reduce(func, start, curriedIterable);\n        }\n        return _reduce(func, start, iterable);\n    }\n\n    async function* _take(count, iterable) {\n        let taken = 0;\n        for await (const val of iterable) {\n            yield await val;\n            taken++;\n            if (taken >= count) {\n                break;\n            }\n        }\n    }\n    function* _syncTake(count, iterable) {\n        let taken = 0;\n        for (const val of iterable) {\n            yield val;\n            taken++;\n            if (taken >= count) {\n                break;\n            }\n        }\n    }\n    function take(count, iterable) {\n        if (iterable === undefined) {\n            return curriedIterable => take(count, curriedIterable);\n        }\n        if (iterable[Symbol.asyncIterator]) {\n            return _take(count, iterable);\n        }\n        return _syncTake(count, iterable);\n    }\n\n    async function* _asyncTap(func, iterable) {\n        for await (const val of iterable) {\n            await func(val);\n            yield val;\n        }\n    }\n    function tap(func, iterable) {\n        if (iterable === undefined) {\n            return (curriedIterable) => _asyncTap(func, curriedIterable);\n        }\n        return _asyncTap(func, iterable);\n    }\n\n    function addTime(a, b) {\n        let seconds = a[0] + b[0];\n        let nanoseconds = a[1] + b[1];\n        if (nanoseconds >= 1000000000) {\n            const remainder = nanoseconds % 1000000000;\n            seconds += (nanoseconds - remainder) / 1000000000;\n            nanoseconds = remainder;\n        }\n        return [seconds, nanoseconds];\n    }\n    async function* _asyncTime(config, iterable) {\n        const itr = iterable[Symbol.asyncIterator]();\n        let total = [0, 0];\n        while (true) {\n            const start = process.hrtime();\n            const { value, done } = await itr.next();\n            const delta = process.hrtime(start);\n            total = addTime(total, delta);\n            if (config.progress) {\n                config.progress(delta, total);\n            }\n            if (done) {\n                if (config.total) {\n                    config.total(total);\n                }\n                return value;\n            }\n            yield value;\n        }\n    }\n    function* _syncTime(config, iterable) {\n        const itr = iterable[Symbol.iterator]();\n        let total = [0, 0];\n        while (true) {\n            const start = process.hrtime();\n            const { value, done } = itr.next();\n            const delta = process.hrtime(start);\n            total = addTime(total, delta);\n            if (config.progress) {\n                config.progress(delta, total);\n            }\n            if (done) {\n                if (config.total) {\n                    config.total(total);\n                }\n                return value;\n            }\n            yield value;\n        }\n    }\n    function time(config = {}, iterable) {\n        if (iterable === undefined) {\n            return curriedIterable => time(config, curriedIterable);\n        }\n        if (iterable[Symbol.asyncIterator] !== undefined) {\n            return _asyncTime(config, iterable);\n        }\n        else {\n            return _syncTime(config, iterable);\n        }\n    }\n\n    function _transform(concurrency, func, iterable) {\n        const iterator = getIterator(iterable);\n        const resultQueue = [];\n        const readQueue = [];\n        let ended = false;\n        let reading = false;\n        let inflightCount = 0;\n        let lastError = null;\n        function fulfillReadQueue() {\n            while (readQueue.length > 0 && resultQueue.length > 0) {\n                const { resolve } = readQueue.shift();\n                const value = resultQueue.shift();\n                resolve({ done: false, value });\n            }\n            while (readQueue.length > 0 && inflightCount === 0 && ended) {\n                const { resolve, reject } = readQueue.shift();\n                if (lastError) {\n                    reject(lastError);\n                    lastError = null;\n                }\n                else {\n                    resolve({ done: true, value: undefined });\n                }\n            }\n        }\n        async function fillQueue() {\n            if (ended) {\n                fulfillReadQueue();\n                return;\n            }\n            if (reading) {\n                return;\n            }\n            if (inflightCount + resultQueue.length >= concurrency) {\n                return;\n            }\n            reading = true;\n            inflightCount++;\n            try {\n                const { done, value } = await iterator.next();\n                if (done) {\n                    ended = true;\n                    inflightCount--;\n                    fulfillReadQueue();\n                }\n                else {\n                    mapAndQueue(value);\n                }\n            }\n            catch (error) {\n                ended = true;\n                inflightCount--;\n                lastError = error;\n                fulfillReadQueue();\n            }\n            reading = false;\n            fillQueue();\n        }\n        async function mapAndQueue(itrValue) {\n            try {\n                const value = await func(itrValue);\n                resultQueue.push(value);\n            }\n            catch (error) {\n                ended = true;\n                lastError = error;\n            }\n            inflightCount--;\n            fulfillReadQueue();\n            fillQueue();\n        }\n        async function next() {\n            if (resultQueue.length === 0) {\n                const deferred = defer();\n                readQueue.push(deferred);\n                fillQueue();\n                return deferred.promise;\n            }\n            const value = resultQueue.shift();\n            fillQueue();\n            return { done: false, value };\n        }\n        const asyncIterableIterator = {\n            next,\n            [Symbol.asyncIterator]: () => asyncIterableIterator,\n        };\n        return asyncIterableIterator;\n    }\n    function transform(concurrency, func, iterable) {\n        if (func === undefined) {\n            return (curriedFunc, curriedIterable) => curriedIterable\n                ? transform(concurrency, curriedFunc, curriedIterable)\n                : transform(concurrency, curriedFunc);\n        }\n        if (iterable === undefined) {\n            return (curriedIterable) => transform(concurrency, func, curriedIterable);\n        }\n        return _transform(concurrency, func, iterable);\n    }\n\n    async function _writeToStream(stream, iterable) {\n        let lastError = null;\n        let errCb = null;\n        let drainCb = null;\n        const notifyError = err => {\n            lastError = err;\n            if (errCb) {\n                errCb(err);\n            }\n        };\n        const notifyDrain = () => {\n            if (drainCb) {\n                drainCb();\n            }\n        };\n        const cleanup = () => {\n            stream.removeListener('error', notifyError);\n            stream.removeListener('drain', notifyDrain);\n        };\n        stream.once('error', notifyError);\n        const waitForDrain = () => new Promise((resolve, reject) => {\n            if (lastError) {\n                return reject(lastError);\n            }\n            stream.once('drain', notifyDrain);\n            drainCb = resolve;\n            errCb = reject;\n        });\n        for await (const value of iterable) {\n            if (stream.write(value) === false) {\n                await waitForDrain();\n            }\n            if (lastError) {\n                break;\n            }\n        }\n        cleanup();\n        if (lastError) {\n            throw lastError;\n        }\n    }\n    function writeToStream(stream, iterable) {\n        if (iterable === undefined) {\n            return (curriedIterable) => _writeToStream(stream, curriedIterable);\n        }\n        return _writeToStream(stream, iterable);\n    }\n\n    exports.batch = batch;\n    exports.buffer = buffer;\n    exports.collect = collect;\n    exports.concat = concat;\n    exports.consume = consume;\n    exports.filter = filter;\n    exports.flatMap = flatMap;\n    exports.flatTransform = flatTransform;\n    exports.flatten = flatten;\n    exports.fromStream = fromStream;\n    exports.getIterator = getIterator;\n    exports.map = map;\n    exports.merge = merge;\n    exports.parallelFlatMap = parallelFlatMap;\n    exports.parallelMap = parallelMap;\n    exports.parallelMerge = parallelMerge;\n    exports.pipeline = pipeline;\n    exports.reduce = reduce;\n    exports.take = take;\n    exports.tap = tap;\n    exports.time = time;\n    exports.transform = transform;\n    exports.writeToStream = writeToStream;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n","'use strict'\n\n/**\n * Can be used with Array.sort to sort and array with Uint8Array entries\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction compare (a, b) {\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] < b[i]) {\n      return -1\n    }\n\n    if (a[i] > b[i]) {\n      return 1\n    }\n  }\n\n  if (a.byteLength > b.byteLength) {\n    return 1\n  }\n\n  if (a.byteLength < b.byteLength) {\n    return -1\n  }\n\n  return 0\n}\n\nmodule.exports = compare\n","'use strict'\n\n/**\n * Returns a new Uint8Array created by concatenating the passed ArrayLikes\n *\n * @param {Array<ArrayLike<number>>} arrays\n * @param {number} [length]\n */\nfunction concat (arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0)\n  }\n\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrays) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = concat\n","'use strict'\n\n/**\n * Returns true if the two passed Uint8Arrays have the same content\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction equals (a, b) {\n  if (a === b) {\n    return true\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = equals\n","'use strict'\n\nconst bases = require('./util/bases')\n\n/**\n * @typedef {import('./util/bases').SupportedEncodings} SupportedEncodings\n */\n\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8`, `hex`, and any encoding supported by the multiformats module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {string} string\n * @param {SupportedEncodings} [encoding=utf8] - utf8, base16, base64, base64urlpad, etc\n * @returns {Uint8Array}\n */\nfunction fromString (string, encoding = 'utf8') {\n  const base = bases[encoding]\n\n  if (!base) {\n    throw new Error(`Unsupported encoding \"${encoding}\"`)\n  }\n\n  // add multibase prefix\n  return base.decoder.decode(`${base.prefix}${string}`)\n}\n\nmodule.exports = fromString\n","'use strict'\nconst compare = require('./compare')\nconst concat = require('./concat')\nconst equals = require('./equals')\nconst fromString = require('./from-string')\nconst toString = require('./to-string')\nconst xor = require('./xor')\n\nmodule.exports = {\n  compare,\n  concat,\n  equals,\n  fromString,\n  toString,\n  xor\n}\n","'use strict'\n\nconst bases = require('./util/bases')\n\n/**\n * @typedef {import('./util/bases').SupportedEncodings} SupportedEncodings\n */\n\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {Uint8Array} array - The array to turn into a string\n * @param {SupportedEncodings} [encoding=utf8] - The encoding to use\n * @returns {string}\n */\nfunction toString (array, encoding = 'utf8') {\n  const base = bases[encoding]\n\n  if (!base) {\n    throw new Error(`Unsupported encoding \"${encoding}\"`)\n  }\n\n  // strip multibase prefix\n  return base.encoder.encode(array).substring(1)\n}\n\nmodule.exports = toString\n","  'use strict'\n\nconst { bases } = require('multiformats/basics')\n\n/**\n * @typedef {import('multiformats/bases/interface').MultibaseCodec<any>} MultibaseCodec\n */\n\n/**\n * @param {string} name\n * @param {string} prefix\n * @param {(buf: Uint8Array) => string} encode\n * @param {(str: string) => Uint8Array} decode\n * @returns {MultibaseCodec}\n */\nfunction createCodec (name, prefix, encode, decode) {\n  return {\n    name,\n    prefix,\n    encoder: {\n      name,\n      prefix,\n      encode\n    },\n    decoder: {\n      decode\n    }\n  }\n}\n\nconst string = createCodec('utf8', 'u', (buf) => {\n  const decoder = new TextDecoder('utf8')\n  return 'u' + decoder.decode(buf)\n}, (str) => {\n  const encoder = new TextEncoder()\n  return encoder.encode(str.substring(1))\n})\n\nconst ascii = createCodec('ascii', 'a', (buf) => {\n  let string = 'a'\n\n  for (let i = 0; i < buf.length; i++) {\n    string += String.fromCharCode(buf[i])\n  }\n  return string\n}, (str) => {\n  str = str.substring(1)\n  const buf = new Uint8Array(str.length)\n\n  for (let i = 0; i < str.length; i++) {\n    buf[i] = str.charCodeAt(i)\n  }\n\n  return buf\n})\n\n/**\n * @typedef {'utf8' | 'utf-8' | 'hex' | 'latin1' | 'ascii' | 'binary' | keyof bases } SupportedEncodings\n */\n\n/**\n * @type {Record<SupportedEncodings, MultibaseCodec>}\n */\nconst BASES = {\n  'utf8': string,\n  'utf-8': string,\n  'hex': bases.base16,\n  'latin1': ascii,\n  'ascii': ascii,\n  'binary': ascii,\n\n  ...bases\n}\n\nmodule.exports = BASES\n","'use strict'\n\n/**\n * Returns the xor distance between two arrays\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction xor (a, b) {\n  if (a.length !== b.length) {\n    throw new Error('Inputs should have the same length')\n  }\n\n  const result = new Uint8Array(a.length)\n\n  for (let i = 0; i < a.length; i++) {\n    result[i] = a[i] ^ b[i]\n  }\n\n  return result\n}\n\nmodule.exports = xor\n","module.exports = read\n\nvar MSB = 0x80\n  , REST = 0x7F\n\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length\n\n  do {\n    if (counter >= l || shift > 49) {\n      read.bytes = 0\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++]\n    res += shift < 28\n      ? (b & REST) << shift\n      : (b & REST) * Math.pow(2, shift)\n    shift += 7\n  } while (b >= MSB)\n\n  read.bytes = counter - offset\n\n  return res\n}\n","module.exports = encode\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31)\n\nfunction encode(num, out, offset) {\n  if (Number.MAX_SAFE_INTEGER && num > Number.MAX_SAFE_INTEGER) {\n    encode.bytes = 0\n    throw new RangeError('Could not encode varint')\n  }\n  out = out || []\n  offset = offset || 0\n  var oldOffset = offset\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB\n    num /= 128\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB\n    num >>>= 7\n  }\n  out[offset] = num | 0\n  \n  encode.bytes = offset - oldOffset + 1\n  \n  return out\n}\n","module.exports = {\n    encode: require('./encode.js')\n  , decode: require('./decode.js')\n  , encodingLength: require('./length.js')\n}\n","\nvar N1 = Math.pow(2,  7)\nvar N2 = Math.pow(2, 14)\nvar N3 = Math.pow(2, 21)\nvar N4 = Math.pow(2, 28)\nvar N5 = Math.pow(2, 35)\nvar N6 = Math.pow(2, 42)\nvar N7 = Math.pow(2, 49)\nvar N8 = Math.pow(2, 56)\nvar N9 = Math.pow(2, 63)\n\nmodule.exports = function (value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n}\n","\"use strict\"\n\nexports.TextEncoder =\n  typeof TextEncoder !== \"undefined\" ? TextEncoder : require(\"util\").TextEncoder\n\nexports.TextDecoder =\n  typeof TextDecoder !== \"undefined\" ? TextDecoder : require(\"util\").TextDecoder\n","/**\n * web-streams-polyfill v3.0.3\n */\n(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n    typeof define === 'function' && define.amd ? define(['exports'], factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.WebStreamsPolyfill = {}));\n}(this, (function (exports) { 'use strict';\n\n    /// <reference lib=\"es2015.symbol\" />\n    var SymbolPolyfill = typeof Symbol === 'function' && typeof Symbol.iterator === 'symbol' ?\n        Symbol :\n        function (description) { return \"Symbol(\" + description + \")\"; };\n\n    /// <reference lib=\"dom\" />\n    function noop() {\n        return undefined;\n    }\n    function getGlobals() {\n        if (typeof self !== 'undefined') {\n            return self;\n        }\n        else if (typeof window !== 'undefined') {\n            return window;\n        }\n        else if (typeof global !== 'undefined') {\n            return global;\n        }\n        return undefined;\n    }\n    var globals = getGlobals();\n\n    function typeIsObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    var rethrowAssertionErrorRejection = noop;\n\n    var originalPromise = Promise;\n    var originalPromiseThen = Promise.prototype.then;\n    var originalPromiseResolve = Promise.resolve.bind(originalPromise);\n    var originalPromiseReject = Promise.reject.bind(originalPromise);\n    function newPromise(executor) {\n        return new originalPromise(executor);\n    }\n    function promiseResolvedWith(value) {\n        return originalPromiseResolve(value);\n    }\n    function promiseRejectedWith(reason) {\n        return originalPromiseReject(reason);\n    }\n    function PerformPromiseThen(promise, onFulfilled, onRejected) {\n        // There doesn't appear to be any way to correctly emulate the behaviour from JavaScript, so this is just an\n        // approximation.\n        return originalPromiseThen.call(promise, onFulfilled, onRejected);\n    }\n    function uponPromise(promise, onFulfilled, onRejected) {\n        PerformPromiseThen(PerformPromiseThen(promise, onFulfilled, onRejected), undefined, rethrowAssertionErrorRejection);\n    }\n    function uponFulfillment(promise, onFulfilled) {\n        uponPromise(promise, onFulfilled);\n    }\n    function uponRejection(promise, onRejected) {\n        uponPromise(promise, undefined, onRejected);\n    }\n    function transformPromiseWith(promise, fulfillmentHandler, rejectionHandler) {\n        return PerformPromiseThen(promise, fulfillmentHandler, rejectionHandler);\n    }\n    function setPromiseIsHandledToTrue(promise) {\n        PerformPromiseThen(promise, undefined, rethrowAssertionErrorRejection);\n    }\n    var queueMicrotask = (function () {\n        var globalQueueMicrotask = globals && globals.queueMicrotask;\n        if (typeof globalQueueMicrotask === 'function') {\n            return globalQueueMicrotask;\n        }\n        var resolvedPromise = promiseResolvedWith(undefined);\n        return function (fn) { return PerformPromiseThen(resolvedPromise, fn); };\n    })();\n    function reflectCall(F, V, args) {\n        if (typeof F !== 'function') {\n            throw new TypeError('Argument is not a function');\n        }\n        return Function.prototype.apply.call(F, V, args);\n    }\n    function promiseCall(F, V, args) {\n        try {\n            return promiseResolvedWith(reflectCall(F, V, args));\n        }\n        catch (value) {\n            return promiseRejectedWith(value);\n        }\n    }\n\n    // Original from Chromium\n    // https://chromium.googlesource.com/chromium/src/+/0aee4434a4dba42a42abaea9bfbc0cd196a63bc1/third_party/blink/renderer/core/streams/SimpleQueue.js\n    var QUEUE_MAX_ARRAY_SIZE = 16384;\n    /**\n     * Simple queue structure.\n     *\n     * Avoids scalability issues with using a packed array directly by using\n     * multiple arrays in a linked list and keeping the array size bounded.\n     */\n    var SimpleQueue = /** @class */ (function () {\n        function SimpleQueue() {\n            this._cursor = 0;\n            this._size = 0;\n            // _front and _back are always defined.\n            this._front = {\n                _elements: [],\n                _next: undefined\n            };\n            this._back = this._front;\n            // The cursor is used to avoid calling Array.shift().\n            // It contains the index of the front element of the array inside the\n            // front-most node. It is always in the range [0, QUEUE_MAX_ARRAY_SIZE).\n            this._cursor = 0;\n            // When there is only one node, size === elements.length - cursor.\n            this._size = 0;\n        }\n        Object.defineProperty(SimpleQueue.prototype, \"length\", {\n            get: function () {\n                return this._size;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        // For exception safety, this method is structured in order:\n        // 1. Read state\n        // 2. Calculate required state mutations\n        // 3. Perform state mutations\n        SimpleQueue.prototype.push = function (element) {\n            var oldBack = this._back;\n            var newBack = oldBack;\n            if (oldBack._elements.length === QUEUE_MAX_ARRAY_SIZE - 1) {\n                newBack = {\n                    _elements: [],\n                    _next: undefined\n                };\n            }\n            // push() is the mutation most likely to throw an exception, so it\n            // goes first.\n            oldBack._elements.push(element);\n            if (newBack !== oldBack) {\n                this._back = newBack;\n                oldBack._next = newBack;\n            }\n            ++this._size;\n        };\n        // Like push(), shift() follows the read -> calculate -> mutate pattern for\n        // exception safety.\n        SimpleQueue.prototype.shift = function () { // must not be called on an empty queue\n            var oldFront = this._front;\n            var newFront = oldFront;\n            var oldCursor = this._cursor;\n            var newCursor = oldCursor + 1;\n            var elements = oldFront._elements;\n            var element = elements[oldCursor];\n            if (newCursor === QUEUE_MAX_ARRAY_SIZE) {\n                newFront = oldFront._next;\n                newCursor = 0;\n            }\n            // No mutations before this point.\n            --this._size;\n            this._cursor = newCursor;\n            if (oldFront !== newFront) {\n                this._front = newFront;\n            }\n            // Permit shifted element to be garbage collected.\n            elements[oldCursor] = undefined;\n            return element;\n        };\n        // The tricky thing about forEach() is that it can be called\n        // re-entrantly. The queue may be mutated inside the callback. It is easy to\n        // see that push() within the callback has no negative effects since the end\n        // of the queue is checked for on every iteration. If shift() is called\n        // repeatedly within the callback then the next iteration may return an\n        // element that has been removed. In this case the callback will be called\n        // with undefined values until we either \"catch up\" with elements that still\n        // exist or reach the back of the queue.\n        SimpleQueue.prototype.forEach = function (callback) {\n            var i = this._cursor;\n            var node = this._front;\n            var elements = node._elements;\n            while (i !== elements.length || node._next !== undefined) {\n                if (i === elements.length) {\n                    node = node._next;\n                    elements = node._elements;\n                    i = 0;\n                    if (elements.length === 0) {\n                        break;\n                    }\n                }\n                callback(elements[i]);\n                ++i;\n            }\n        };\n        // Return the element that would be returned if shift() was called now,\n        // without modifying the queue.\n        SimpleQueue.prototype.peek = function () { // must not be called on an empty queue\n            var front = this._front;\n            var cursor = this._cursor;\n            return front._elements[cursor];\n        };\n        return SimpleQueue;\n    }());\n\n    function ReadableStreamReaderGenericInitialize(reader, stream) {\n        reader._ownerReadableStream = stream;\n        stream._reader = reader;\n        if (stream._state === 'readable') {\n            defaultReaderClosedPromiseInitialize(reader);\n        }\n        else if (stream._state === 'closed') {\n            defaultReaderClosedPromiseInitializeAsResolved(reader);\n        }\n        else {\n            defaultReaderClosedPromiseInitializeAsRejected(reader, stream._storedError);\n        }\n    }\n    // A client of ReadableStreamDefaultReader and ReadableStreamBYOBReader may use these functions directly to bypass state\n    // check.\n    function ReadableStreamReaderGenericCancel(reader, reason) {\n        var stream = reader._ownerReadableStream;\n        return ReadableStreamCancel(stream, reason);\n    }\n    function ReadableStreamReaderGenericRelease(reader) {\n        if (reader._ownerReadableStream._state === 'readable') {\n            defaultReaderClosedPromiseReject(reader, new TypeError(\"Reader was released and can no longer be used to monitor the stream's closedness\"));\n        }\n        else {\n            defaultReaderClosedPromiseResetToRejected(reader, new TypeError(\"Reader was released and can no longer be used to monitor the stream's closedness\"));\n        }\n        reader._ownerReadableStream._reader = undefined;\n        reader._ownerReadableStream = undefined;\n    }\n    // Helper functions for the readers.\n    function readerLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released reader');\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderClosedPromiseInitialize(reader) {\n        reader._closedPromise = newPromise(function (resolve, reject) {\n            reader._closedPromise_resolve = resolve;\n            reader._closedPromise_reject = reject;\n        });\n    }\n    function defaultReaderClosedPromiseInitializeAsRejected(reader, reason) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseReject(reader, reason);\n    }\n    function defaultReaderClosedPromiseInitializeAsResolved(reader) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseResolve(reader);\n    }\n    function defaultReaderClosedPromiseReject(reader, reason) {\n        if (reader._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(reader._closedPromise);\n        reader._closedPromise_reject(reason);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n    function defaultReaderClosedPromiseResetToRejected(reader, reason) {\n        defaultReaderClosedPromiseInitializeAsRejected(reader, reason);\n    }\n    function defaultReaderClosedPromiseResolve(reader) {\n        if (reader._closedPromise_resolve === undefined) {\n            return;\n        }\n        reader._closedPromise_resolve(undefined);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n\n    var AbortSteps = SymbolPolyfill('[[AbortSteps]]');\n    var ErrorSteps = SymbolPolyfill('[[ErrorSteps]]');\n    var CancelSteps = SymbolPolyfill('[[CancelSteps]]');\n    var PullSteps = SymbolPolyfill('[[PullSteps]]');\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isFinite#Polyfill\n    var NumberIsFinite = Number.isFinite || function (x) {\n        return typeof x === 'number' && isFinite(x);\n    };\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc#Polyfill\n    var MathTrunc = Math.trunc || function (v) {\n        return v < 0 ? Math.ceil(v) : Math.floor(v);\n    };\n\n    // https://heycam.github.io/webidl/#idl-dictionaries\n    function isDictionary(x) {\n        return typeof x === 'object' || typeof x === 'function';\n    }\n    function assertDictionary(obj, context) {\n        if (obj !== undefined && !isDictionary(obj)) {\n            throw new TypeError(context + \" is not an object.\");\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-callback-functions\n    function assertFunction(x, context) {\n        if (typeof x !== 'function') {\n            throw new TypeError(context + \" is not a function.\");\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-object\n    function isObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    function assertObject(x, context) {\n        if (!isObject(x)) {\n            throw new TypeError(context + \" is not an object.\");\n        }\n    }\n    function assertRequiredArgument(x, position, context) {\n        if (x === undefined) {\n            throw new TypeError(\"Parameter \" + position + \" is required in '\" + context + \"'.\");\n        }\n    }\n    function assertRequiredField(x, field, context) {\n        if (x === undefined) {\n            throw new TypeError(field + \" is required in '\" + context + \"'.\");\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-unrestricted-double\n    function convertUnrestrictedDouble(value) {\n        return Number(value);\n    }\n    function censorNegativeZero(x) {\n        return x === 0 ? 0 : x;\n    }\n    function integerPart(x) {\n        return censorNegativeZero(MathTrunc(x));\n    }\n    // https://heycam.github.io/webidl/#idl-unsigned-long-long\n    function convertUnsignedLongLongWithEnforceRange(value, context) {\n        var lowerBound = 0;\n        var upperBound = Number.MAX_SAFE_INTEGER;\n        var x = Number(value);\n        x = censorNegativeZero(x);\n        if (!NumberIsFinite(x)) {\n            throw new TypeError(context + \" is not a finite number\");\n        }\n        x = integerPart(x);\n        if (x < lowerBound || x > upperBound) {\n            throw new TypeError(context + \" is outside the accepted range of \" + lowerBound + \" to \" + upperBound + \", inclusive\");\n        }\n        if (!NumberIsFinite(x) || x === 0) {\n            return 0;\n        }\n        // TODO Use BigInt if supported?\n        // let xBigInt = BigInt(integerPart(x));\n        // xBigInt = BigInt.asUintN(64, xBigInt);\n        // return Number(xBigInt);\n        return x;\n    }\n\n    function assertReadableStream(x, context) {\n        if (!IsReadableStream(x)) {\n            throw new TypeError(context + \" is not a ReadableStream.\");\n        }\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamDefaultReader(stream) {\n        return new ReadableStreamDefaultReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadRequest(stream, readRequest) {\n        stream._reader._readRequests.push(readRequest);\n    }\n    function ReadableStreamFulfillReadRequest(stream, chunk, done) {\n        var reader = stream._reader;\n        var readRequest = reader._readRequests.shift();\n        if (done) {\n            readRequest._closeSteps();\n        }\n        else {\n            readRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadRequests(stream) {\n        return stream._reader._readRequests.length;\n    }\n    function ReadableStreamHasDefaultReader(stream) {\n        var reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamDefaultReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A default reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    var ReadableStreamDefaultReader = /** @class */ (function () {\n        function ReadableStreamDefaultReader(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamDefaultReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readRequests = new SimpleQueue();\n        }\n        Object.defineProperty(ReadableStreamDefaultReader.prototype, \"closed\", {\n            /**\n             * Returns a promise that will be fulfilled when the stream becomes closed,\n             * or rejected if the stream ever errors or the reader's lock is released before the stream finishes closing.\n             */\n            get: function () {\n                if (!IsReadableStreamDefaultReader(this)) {\n                    return promiseRejectedWith(defaultReaderBrandCheckException('closed'));\n                }\n                return this._closedPromise;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        ReadableStreamDefaultReader.prototype.cancel = function (reason) {\n            if (reason === void 0) { reason = undefined; }\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        };\n        /**\n         * Returns a promise that allows access to the next chunk from the stream's internal queue, if available.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        ReadableStreamDefaultReader.prototype.read = function () {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('read'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            var resolvePromise;\n            var rejectPromise;\n            var promise = newPromise(function (resolve, reject) {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            var readRequest = {\n                _chunkSteps: function (chunk) { return resolvePromise({ value: chunk, done: false }); },\n                _closeSteps: function () { return resolvePromise({ value: undefined, done: true }); },\n                _errorSteps: function (e) { return rejectPromise(e); }\n            };\n            ReadableStreamDefaultReaderRead(this, readRequest);\n            return promise;\n        };\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamDefaultReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        ReadableStreamDefaultReader.prototype.releaseLock = function () {\n            if (!IsReadableStreamDefaultReader(this)) {\n                throw defaultReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        };\n        return ReadableStreamDefaultReader;\n    }());\n    Object.defineProperties(ReadableStreamDefaultReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamDefaultReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readRequests')) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamDefaultReaderRead(reader, readRequest) {\n        var stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            readRequest._closeSteps();\n        }\n        else if (stream._state === 'errored') {\n            readRequest._errorSteps(stream._storedError);\n        }\n        else {\n            stream._readableStreamController[PullSteps](readRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderBrandCheckException(name) {\n        return new TypeError(\"ReadableStreamDefaultReader.prototype.\" + name + \" can only be used on a ReadableStreamDefaultReader\");\n    }\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    var _a;\n    var AsyncIteratorPrototype;\n    if (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n        // We're running inside a ES2018+ environment, but we're compiling to an older syntax.\n        // We cannot access %AsyncIteratorPrototype% without non-ES2018 syntax, but we can re-create it.\n        AsyncIteratorPrototype = (_a = {},\n            // 25.1.3.1 %AsyncIteratorPrototype% [ @@asyncIterator ] ( )\n            // https://tc39.github.io/ecma262/#sec-asynciteratorprototype-asynciterator\n            _a[SymbolPolyfill.asyncIterator] = function () {\n                return this;\n            },\n            _a);\n        Object.defineProperty(AsyncIteratorPrototype, SymbolPolyfill.asyncIterator, { enumerable: false });\n    }\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    var ReadableStreamAsyncIteratorImpl = /** @class */ (function () {\n        function ReadableStreamAsyncIteratorImpl(reader, preventCancel) {\n            this._ongoingPromise = undefined;\n            this._isFinished = false;\n            this._reader = reader;\n            this._preventCancel = preventCancel;\n        }\n        ReadableStreamAsyncIteratorImpl.prototype.next = function () {\n            var _this = this;\n            var nextSteps = function () { return _this._nextSteps(); };\n            this._ongoingPromise = this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, nextSteps, nextSteps) :\n                nextSteps();\n            return this._ongoingPromise;\n        };\n        ReadableStreamAsyncIteratorImpl.prototype.return = function (value) {\n            var _this = this;\n            var returnSteps = function () { return _this._returnSteps(value); };\n            return this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, returnSteps, returnSteps) :\n                returnSteps();\n        };\n        ReadableStreamAsyncIteratorImpl.prototype._nextSteps = function () {\n            var _this = this;\n            if (this._isFinished) {\n                return Promise.resolve({ value: undefined, done: true });\n            }\n            var reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('iterate'));\n            }\n            var resolvePromise;\n            var rejectPromise;\n            var promise = newPromise(function (resolve, reject) {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            var readRequest = {\n                _chunkSteps: function (chunk) {\n                    _this._ongoingPromise = undefined;\n                    // This needs to be delayed by one microtask, otherwise we stop pulling too early which breaks a test.\n                    // FIXME Is this a bug in the specification, or in the test?\n                    queueMicrotask(function () { return resolvePromise({ value: chunk, done: false }); });\n                },\n                _closeSteps: function () {\n                    _this._ongoingPromise = undefined;\n                    _this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    resolvePromise({ value: undefined, done: true });\n                },\n                _errorSteps: function (reason) {\n                    _this._ongoingPromise = undefined;\n                    _this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    rejectPromise(reason);\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promise;\n        };\n        ReadableStreamAsyncIteratorImpl.prototype._returnSteps = function (value) {\n            if (this._isFinished) {\n                return Promise.resolve({ value: value, done: true });\n            }\n            this._isFinished = true;\n            var reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('finish iterating'));\n            }\n            if (!this._preventCancel) {\n                var result = ReadableStreamReaderGenericCancel(reader, value);\n                ReadableStreamReaderGenericRelease(reader);\n                return transformPromiseWith(result, function () { return ({ value: value, done: true }); });\n            }\n            ReadableStreamReaderGenericRelease(reader);\n            return promiseResolvedWith({ value: value, done: true });\n        };\n        return ReadableStreamAsyncIteratorImpl;\n    }());\n    var ReadableStreamAsyncIteratorPrototype = {\n        next: function () {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('next'));\n            }\n            return this._asyncIteratorImpl.next();\n        },\n        return: function (value) {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('return'));\n            }\n            return this._asyncIteratorImpl.return(value);\n        }\n    };\n    if (AsyncIteratorPrototype !== undefined) {\n        Object.setPrototypeOf(ReadableStreamAsyncIteratorPrototype, AsyncIteratorPrototype);\n    }\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamAsyncIterator(stream, preventCancel) {\n        var reader = AcquireReadableStreamDefaultReader(stream);\n        var impl = new ReadableStreamAsyncIteratorImpl(reader, preventCancel);\n        var iterator = Object.create(ReadableStreamAsyncIteratorPrototype);\n        iterator._asyncIteratorImpl = impl;\n        return iterator;\n    }\n    function IsReadableStreamAsyncIterator(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_asyncIteratorImpl')) {\n            return false;\n        }\n        return true;\n    }\n    // Helper functions for the ReadableStream.\n    function streamAsyncIteratorBrandCheckException(name) {\n        return new TypeError(\"ReadableStreamAsyncIterator.\" + name + \" can only be used on a ReadableSteamAsyncIterator\");\n    }\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isNaN#Polyfill\n    var NumberIsNaN = Number.isNaN || function (x) {\n        // eslint-disable-next-line no-self-compare\n        return x !== x;\n    };\n\n    function IsFiniteNonNegativeNumber(v) {\n        if (!IsNonNegativeNumber(v)) {\n            return false;\n        }\n        if (v === Infinity) {\n            return false;\n        }\n        return true;\n    }\n    function IsNonNegativeNumber(v) {\n        if (typeof v !== 'number') {\n            return false;\n        }\n        if (NumberIsNaN(v)) {\n            return false;\n        }\n        if (v < 0) {\n            return false;\n        }\n        return true;\n    }\n\n    function DequeueValue(container) {\n        var pair = container._queue.shift();\n        container._queueTotalSize -= pair.size;\n        if (container._queueTotalSize < 0) {\n            container._queueTotalSize = 0;\n        }\n        return pair.value;\n    }\n    function EnqueueValueWithSize(container, value, size) {\n        size = Number(size);\n        if (!IsFiniteNonNegativeNumber(size)) {\n            throw new RangeError('Size must be a finite, non-NaN, non-negative number.');\n        }\n        container._queue.push({ value: value, size: size });\n        container._queueTotalSize += size;\n    }\n    function PeekQueueValue(container) {\n        var pair = container._queue.peek();\n        return pair.value;\n    }\n    function ResetQueue(container) {\n        container._queue = new SimpleQueue();\n        container._queueTotalSize = 0;\n    }\n\n    function CreateArrayFromList(elements) {\n        // We use arrays to represent lists, so this is basically a no-op.\n        // Do a slice though just in case we happen to depend on the unique-ness.\n        return elements.slice();\n    }\n    function CopyDataBlockBytes(dest, destOffset, src, srcOffset, n) {\n        new Uint8Array(dest).set(new Uint8Array(src, srcOffset, n), destOffset);\n    }\n    // Not implemented correctly\n    function TransferArrayBuffer(O) {\n        return O;\n    }\n    // Not implemented correctly\n    function IsDetachedBuffer(O) {\n        return false;\n    }\n\n    /**\n     * A pull-into request in a {@link ReadableByteStreamController}.\n     *\n     * @public\n     */\n    var ReadableStreamBYOBRequest = /** @class */ (function () {\n        function ReadableStreamBYOBRequest() {\n            throw new TypeError('Illegal constructor');\n        }\n        Object.defineProperty(ReadableStreamBYOBRequest.prototype, \"view\", {\n            /**\n             * Returns the view for writing in to, or `null` if the BYOB request has already been responded to.\n             */\n            get: function () {\n                if (!IsReadableStreamBYOBRequest(this)) {\n                    throw byobRequestBrandCheckException('view');\n                }\n                return this._view;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        ReadableStreamBYOBRequest.prototype.respond = function (bytesWritten) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respond');\n            }\n            assertRequiredArgument(bytesWritten, 1, 'respond');\n            bytesWritten = convertUnsignedLongLongWithEnforceRange(bytesWritten, 'First parameter');\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(this._view.buffer)) ;\n            ReadableByteStreamControllerRespond(this._associatedReadableByteStreamController, bytesWritten);\n        };\n        ReadableStreamBYOBRequest.prototype.respondWithNewView = function (view) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respondWithNewView');\n            }\n            assertRequiredArgument(view, 1, 'respondWithNewView');\n            if (!ArrayBuffer.isView(view)) {\n                throw new TypeError('You can only respond with array buffer views');\n            }\n            if (view.byteLength === 0) {\n                throw new TypeError('chunk must have non-zero byteLength');\n            }\n            if (view.buffer.byteLength === 0) {\n                throw new TypeError(\"chunk's buffer must have non-zero byteLength\");\n            }\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            ReadableByteStreamControllerRespondWithNewView(this._associatedReadableByteStreamController, view);\n        };\n        return ReadableStreamBYOBRequest;\n    }());\n    Object.defineProperties(ReadableStreamBYOBRequest.prototype, {\n        respond: { enumerable: true },\n        respondWithNewView: { enumerable: true },\n        view: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBRequest.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBRequest',\n            configurable: true\n        });\n    }\n    /**\n     * Allows control of a {@link ReadableStream | readable byte stream}'s state and internal queue.\n     *\n     * @public\n     */\n    var ReadableByteStreamController = /** @class */ (function () {\n        function ReadableByteStreamController() {\n            throw new TypeError('Illegal constructor');\n        }\n        Object.defineProperty(ReadableByteStreamController.prototype, \"byobRequest\", {\n            /**\n             * Returns the current BYOB pull request, or `null` if there isn't one.\n             */\n            get: function () {\n                if (!IsReadableByteStreamController(this)) {\n                    throw byteStreamControllerBrandCheckException('byobRequest');\n                }\n                if (this._byobRequest === null && this._pendingPullIntos.length > 0) {\n                    var firstDescriptor = this._pendingPullIntos.peek();\n                    var view = new Uint8Array(firstDescriptor.buffer, firstDescriptor.byteOffset + firstDescriptor.bytesFilled, firstDescriptor.byteLength - firstDescriptor.bytesFilled);\n                    var byobRequest = Object.create(ReadableStreamBYOBRequest.prototype);\n                    SetUpReadableStreamBYOBRequest(byobRequest, this, view);\n                    this._byobRequest = byobRequest;\n                }\n                return this._byobRequest;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Object.defineProperty(ReadableByteStreamController.prototype, \"desiredSize\", {\n            /**\n             * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n             * over-full. An underlying byte source ought to use this information to determine when and how to apply backpressure.\n             */\n            get: function () {\n                if (!IsReadableByteStreamController(this)) {\n                    throw byteStreamControllerBrandCheckException('desiredSize');\n                }\n                return ReadableByteStreamControllerGetDesiredSize(this);\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        ReadableByteStreamController.prototype.close = function () {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('close');\n            }\n            if (this._closeRequested) {\n                throw new TypeError('The stream has already been closed; do not close it again!');\n            }\n            var state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(\"The stream (in \" + state + \" state) is not in the readable state and cannot be closed\");\n            }\n            ReadableByteStreamControllerClose(this);\n        };\n        ReadableByteStreamController.prototype.enqueue = function (chunk) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('enqueue');\n            }\n            assertRequiredArgument(chunk, 1, 'enqueue');\n            if (!ArrayBuffer.isView(chunk)) {\n                throw new TypeError('chunk must be an array buffer view');\n            }\n            if (chunk.byteLength === 0) {\n                throw new TypeError('chunk must have non-zero byteLength');\n            }\n            if (chunk.buffer.byteLength === 0) {\n                throw new TypeError(\"chunk's buffer must have non-zero byteLength\");\n            }\n            if (this._closeRequested) {\n                throw new TypeError('stream is closed or draining');\n            }\n            var state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(\"The stream (in \" + state + \" state) is not in the readable state and cannot be enqueued to\");\n            }\n            ReadableByteStreamControllerEnqueue(this, chunk);\n        };\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        ReadableByteStreamController.prototype.error = function (e) {\n            if (e === void 0) { e = undefined; }\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('error');\n            }\n            ReadableByteStreamControllerError(this, e);\n        };\n        /** @internal */\n        ReadableByteStreamController.prototype[CancelSteps] = function (reason) {\n            if (this._pendingPullIntos.length > 0) {\n                var firstDescriptor = this._pendingPullIntos.peek();\n                firstDescriptor.bytesFilled = 0;\n            }\n            ResetQueue(this);\n            var result = this._cancelAlgorithm(reason);\n            ReadableByteStreamControllerClearAlgorithms(this);\n            return result;\n        };\n        /** @internal */\n        ReadableByteStreamController.prototype[PullSteps] = function (readRequest) {\n            var stream = this._controlledReadableByteStream;\n            if (this._queueTotalSize > 0) {\n                var entry = this._queue.shift();\n                this._queueTotalSize -= entry.byteLength;\n                ReadableByteStreamControllerHandleQueueDrain(this);\n                var view = new Uint8Array(entry.buffer, entry.byteOffset, entry.byteLength);\n                readRequest._chunkSteps(view);\n                return;\n            }\n            var autoAllocateChunkSize = this._autoAllocateChunkSize;\n            if (autoAllocateChunkSize !== undefined) {\n                var buffer = void 0;\n                try {\n                    buffer = new ArrayBuffer(autoAllocateChunkSize);\n                }\n                catch (bufferE) {\n                    readRequest._errorSteps(bufferE);\n                    return;\n                }\n                var pullIntoDescriptor = {\n                    buffer: buffer,\n                    byteOffset: 0,\n                    byteLength: autoAllocateChunkSize,\n                    bytesFilled: 0,\n                    elementSize: 1,\n                    viewConstructor: Uint8Array,\n                    readerType: 'default'\n                };\n                this._pendingPullIntos.push(pullIntoDescriptor);\n            }\n            ReadableStreamAddReadRequest(stream, readRequest);\n            ReadableByteStreamControllerCallPullIfNeeded(this);\n        };\n        return ReadableByteStreamController;\n    }());\n    Object.defineProperties(ReadableByteStreamController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        byobRequest: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableByteStreamController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableByteStreamController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableByteStreamController.\n    function IsReadableByteStreamController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableByteStream')) {\n            return false;\n        }\n        return true;\n    }\n    function IsReadableStreamBYOBRequest(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_associatedReadableByteStreamController')) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableByteStreamControllerCallPullIfNeeded(controller) {\n        var shouldPull = ReadableByteStreamControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        // TODO: Test controller argument\n        var pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, function () {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableByteStreamControllerCallPullIfNeeded(controller);\n            }\n        }, function (e) {\n            ReadableByteStreamControllerError(controller, e);\n        });\n    }\n    function ReadableByteStreamControllerClearPendingPullIntos(controller) {\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        controller._pendingPullIntos = new SimpleQueue();\n    }\n    function ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor) {\n        var done = false;\n        if (stream._state === 'closed') {\n            done = true;\n        }\n        var filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n        if (pullIntoDescriptor.readerType === 'default') {\n            ReadableStreamFulfillReadRequest(stream, filledView, done);\n        }\n        else {\n            ReadableStreamFulfillReadIntoRequest(stream, filledView, done);\n        }\n    }\n    function ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor) {\n        var bytesFilled = pullIntoDescriptor.bytesFilled;\n        var elementSize = pullIntoDescriptor.elementSize;\n        return new pullIntoDescriptor.viewConstructor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, bytesFilled / elementSize);\n    }\n    function ReadableByteStreamControllerEnqueueChunkToQueue(controller, buffer, byteOffset, byteLength) {\n        controller._queue.push({ buffer: buffer, byteOffset: byteOffset, byteLength: byteLength });\n        controller._queueTotalSize += byteLength;\n    }\n    function ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) {\n        var elementSize = pullIntoDescriptor.elementSize;\n        var currentAlignedBytes = pullIntoDescriptor.bytesFilled - pullIntoDescriptor.bytesFilled % elementSize;\n        var maxBytesToCopy = Math.min(controller._queueTotalSize, pullIntoDescriptor.byteLength - pullIntoDescriptor.bytesFilled);\n        var maxBytesFilled = pullIntoDescriptor.bytesFilled + maxBytesToCopy;\n        var maxAlignedBytes = maxBytesFilled - maxBytesFilled % elementSize;\n        var totalBytesToCopyRemaining = maxBytesToCopy;\n        var ready = false;\n        if (maxAlignedBytes > currentAlignedBytes) {\n            totalBytesToCopyRemaining = maxAlignedBytes - pullIntoDescriptor.bytesFilled;\n            ready = true;\n        }\n        var queue = controller._queue;\n        while (totalBytesToCopyRemaining > 0) {\n            var headOfQueue = queue.peek();\n            var bytesToCopy = Math.min(totalBytesToCopyRemaining, headOfQueue.byteLength);\n            var destStart = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            CopyDataBlockBytes(pullIntoDescriptor.buffer, destStart, headOfQueue.buffer, headOfQueue.byteOffset, bytesToCopy);\n            if (headOfQueue.byteLength === bytesToCopy) {\n                queue.shift();\n            }\n            else {\n                headOfQueue.byteOffset += bytesToCopy;\n                headOfQueue.byteLength -= bytesToCopy;\n            }\n            controller._queueTotalSize -= bytesToCopy;\n            ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor);\n            totalBytesToCopyRemaining -= bytesToCopy;\n        }\n        return ready;\n    }\n    function ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, size, pullIntoDescriptor) {\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        pullIntoDescriptor.bytesFilled += size;\n    }\n    function ReadableByteStreamControllerHandleQueueDrain(controller) {\n        if (controller._queueTotalSize === 0 && controller._closeRequested) {\n            ReadableByteStreamControllerClearAlgorithms(controller);\n            ReadableStreamClose(controller._controlledReadableByteStream);\n        }\n        else {\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }\n    }\n    function ReadableByteStreamControllerInvalidateBYOBRequest(controller) {\n        if (controller._byobRequest === null) {\n            return;\n        }\n        controller._byobRequest._associatedReadableByteStreamController = undefined;\n        controller._byobRequest._view = null;\n        controller._byobRequest = null;\n    }\n    function ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller) {\n        while (controller._pendingPullIntos.length > 0) {\n            if (controller._queueTotalSize === 0) {\n                return;\n            }\n            var pullIntoDescriptor = controller._pendingPullIntos.peek();\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerPullInto(controller, view, readIntoRequest) {\n        var stream = controller._controlledReadableByteStream;\n        var elementSize = 1;\n        if (view.constructor !== DataView) {\n            elementSize = view.constructor.BYTES_PER_ELEMENT;\n        }\n        var ctor = view.constructor;\n        var buffer = TransferArrayBuffer(view.buffer);\n        var pullIntoDescriptor = {\n            buffer: buffer,\n            byteOffset: view.byteOffset,\n            byteLength: view.byteLength,\n            bytesFilled: 0,\n            elementSize: elementSize,\n            viewConstructor: ctor,\n            readerType: 'byob'\n        };\n        if (controller._pendingPullIntos.length > 0) {\n            controller._pendingPullIntos.push(pullIntoDescriptor);\n            // No ReadableByteStreamControllerCallPullIfNeeded() call since:\n            // - No change happens on desiredSize\n            // - The source has already been notified of that there's at least 1 pending read(view)\n            ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n            return;\n        }\n        if (stream._state === 'closed') {\n            var emptyView = new ctor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, 0);\n            readIntoRequest._closeSteps(emptyView);\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                var filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n                ReadableByteStreamControllerHandleQueueDrain(controller);\n                readIntoRequest._chunkSteps(filledView);\n                return;\n            }\n            if (controller._closeRequested) {\n                var e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                readIntoRequest._errorSteps(e);\n                return;\n            }\n        }\n        controller._pendingPullIntos.push(pullIntoDescriptor);\n        ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor) {\n        firstDescriptor.buffer = TransferArrayBuffer(firstDescriptor.buffer);\n        var stream = controller._controlledReadableByteStream;\n        if (ReadableStreamHasBYOBReader(stream)) {\n            while (ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n                var pullIntoDescriptor = ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, pullIntoDescriptor) {\n        if (pullIntoDescriptor.bytesFilled + bytesWritten > pullIntoDescriptor.byteLength) {\n            throw new RangeError('bytesWritten out of range');\n        }\n        ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor);\n        if (pullIntoDescriptor.bytesFilled < pullIntoDescriptor.elementSize) {\n            // TODO: Figure out whether we should detach the buffer or not here.\n            return;\n        }\n        ReadableByteStreamControllerShiftPendingPullInto(controller);\n        var remainderSize = pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize;\n        if (remainderSize > 0) {\n            var end = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            var remainder = pullIntoDescriptor.buffer.slice(end - remainderSize, end);\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, remainder, 0, remainder.byteLength);\n        }\n        pullIntoDescriptor.buffer = TransferArrayBuffer(pullIntoDescriptor.buffer);\n        pullIntoDescriptor.bytesFilled -= remainderSize;\n        ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n        ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n    }\n    function ReadableByteStreamControllerRespondInternal(controller, bytesWritten) {\n        var firstDescriptor = controller._pendingPullIntos.peek();\n        var state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (bytesWritten !== 0) {\n                throw new TypeError('bytesWritten must be 0 when calling respond() on a closed stream');\n            }\n            ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor);\n        }\n        else {\n            ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerShiftPendingPullInto(controller) {\n        var descriptor = controller._pendingPullIntos.shift();\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        return descriptor;\n    }\n    function ReadableByteStreamControllerShouldCallPull(controller) {\n        var stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return false;\n        }\n        if (controller._closeRequested) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (ReadableStreamHasDefaultReader(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        if (ReadableStreamHasBYOBReader(stream) && ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n            return true;\n        }\n        var desiredSize = ReadableByteStreamControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableByteStreamControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n    }\n    // A client of ReadableByteStreamController may use these functions directly to bypass state check.\n    function ReadableByteStreamControllerClose(controller) {\n        var stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            controller._closeRequested = true;\n            return;\n        }\n        if (controller._pendingPullIntos.length > 0) {\n            var firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (firstPendingPullInto.bytesFilled > 0) {\n                var e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                throw e;\n            }\n        }\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamClose(stream);\n    }\n    function ReadableByteStreamControllerEnqueue(controller, chunk) {\n        var stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        var buffer = chunk.buffer;\n        var byteOffset = chunk.byteOffset;\n        var byteLength = chunk.byteLength;\n        var transferredBuffer = TransferArrayBuffer(buffer);\n        if (ReadableStreamHasDefaultReader(stream)) {\n            if (ReadableStreamGetNumReadRequests(stream) === 0) {\n                ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            }\n            else {\n                var transferredView = new Uint8Array(transferredBuffer, byteOffset, byteLength);\n                ReadableStreamFulfillReadRequest(stream, transferredView, false);\n            }\n        }\n        else if (ReadableStreamHasBYOBReader(stream)) {\n            // TODO: Ideally in this branch detaching should happen only if the buffer is not consumed fully.\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n        }\n        else {\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerError(controller, e) {\n        var stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ReadableByteStreamControllerClearPendingPullIntos(controller);\n        ResetQueue(controller);\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableByteStreamControllerGetDesiredSize(controller) {\n        var state = controller._controlledReadableByteStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function ReadableByteStreamControllerRespond(controller, bytesWritten) {\n        bytesWritten = Number(bytesWritten);\n        if (!IsFiniteNonNegativeNumber(bytesWritten)) {\n            throw new RangeError('bytesWritten must be a finite');\n        }\n        ReadableByteStreamControllerRespondInternal(controller, bytesWritten);\n    }\n    function ReadableByteStreamControllerRespondWithNewView(controller, view) {\n        var firstDescriptor = controller._pendingPullIntos.peek();\n        if (firstDescriptor.byteOffset + firstDescriptor.bytesFilled !== view.byteOffset) {\n            throw new RangeError('The region specified by view does not match byobRequest');\n        }\n        if (firstDescriptor.byteLength !== view.byteLength) {\n            throw new RangeError('The buffer of view has different capacity than byobRequest');\n        }\n        firstDescriptor.buffer = view.buffer;\n        ReadableByteStreamControllerRespondInternal(controller, view.byteLength);\n    }\n    function SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize) {\n        controller._controlledReadableByteStream = stream;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._byobRequest = null;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._closeRequested = false;\n        controller._started = false;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        controller._autoAllocateChunkSize = autoAllocateChunkSize;\n        controller._pendingPullIntos = new SimpleQueue();\n        stream._readableStreamController = controller;\n        var startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), function () {\n            controller._started = true;\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }, function (r) {\n            ReadableByteStreamControllerError(controller, r);\n        });\n    }\n    function SetUpReadableByteStreamControllerFromUnderlyingSource(stream, underlyingByteSource, highWaterMark) {\n        var controller = Object.create(ReadableByteStreamController.prototype);\n        var startAlgorithm = function () { return undefined; };\n        var pullAlgorithm = function () { return promiseResolvedWith(undefined); };\n        var cancelAlgorithm = function () { return promiseResolvedWith(undefined); };\n        if (underlyingByteSource.start !== undefined) {\n            startAlgorithm = function () { return underlyingByteSource.start(controller); };\n        }\n        if (underlyingByteSource.pull !== undefined) {\n            pullAlgorithm = function () { return underlyingByteSource.pull(controller); };\n        }\n        if (underlyingByteSource.cancel !== undefined) {\n            cancelAlgorithm = function (reason) { return underlyingByteSource.cancel(reason); };\n        }\n        var autoAllocateChunkSize = underlyingByteSource.autoAllocateChunkSize;\n        if (autoAllocateChunkSize === 0) {\n            throw new TypeError('autoAllocateChunkSize must be greater than 0');\n        }\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize);\n    }\n    function SetUpReadableStreamBYOBRequest(request, controller, view) {\n        request._associatedReadableByteStreamController = controller;\n        request._view = view;\n    }\n    // Helper functions for the ReadableStreamBYOBRequest.\n    function byobRequestBrandCheckException(name) {\n        return new TypeError(\"ReadableStreamBYOBRequest.prototype.\" + name + \" can only be used on a ReadableStreamBYOBRequest\");\n    }\n    // Helper functions for the ReadableByteStreamController.\n    function byteStreamControllerBrandCheckException(name) {\n        return new TypeError(\"ReadableByteStreamController.prototype.\" + name + \" can only be used on a ReadableByteStreamController\");\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamBYOBReader(stream) {\n        return new ReadableStreamBYOBReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadIntoRequest(stream, readIntoRequest) {\n        stream._reader._readIntoRequests.push(readIntoRequest);\n    }\n    function ReadableStreamFulfillReadIntoRequest(stream, chunk, done) {\n        var reader = stream._reader;\n        var readIntoRequest = reader._readIntoRequests.shift();\n        if (done) {\n            readIntoRequest._closeSteps(chunk);\n        }\n        else {\n            readIntoRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadIntoRequests(stream) {\n        return stream._reader._readIntoRequests.length;\n    }\n    function ReadableStreamHasBYOBReader(stream) {\n        var reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamBYOBReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A BYOB reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    var ReadableStreamBYOBReader = /** @class */ (function () {\n        function ReadableStreamBYOBReader(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamBYOBReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            if (!IsReadableByteStreamController(stream._readableStreamController)) {\n                throw new TypeError('Cannot construct a ReadableStreamBYOBReader for a stream not constructed with a byte ' +\n                    'source');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readIntoRequests = new SimpleQueue();\n        }\n        Object.defineProperty(ReadableStreamBYOBReader.prototype, \"closed\", {\n            /**\n             * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n             * the reader's lock is released before the stream finishes closing.\n             */\n            get: function () {\n                if (!IsReadableStreamBYOBReader(this)) {\n                    return promiseRejectedWith(byobReaderBrandCheckException('closed'));\n                }\n                return this._closedPromise;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        ReadableStreamBYOBReader.prototype.cancel = function (reason) {\n            if (reason === void 0) { reason = undefined; }\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        };\n        /**\n         * Attempts to reads bytes into view, and returns a promise resolved with the result.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        ReadableStreamBYOBReader.prototype.read = function (view) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('read'));\n            }\n            if (!ArrayBuffer.isView(view)) {\n                return promiseRejectedWith(new TypeError('view must be an array buffer view'));\n            }\n            if (view.byteLength === 0) {\n                return promiseRejectedWith(new TypeError('view must have non-zero byteLength'));\n            }\n            if (view.buffer.byteLength === 0) {\n                return promiseRejectedWith(new TypeError(\"view's buffer must have non-zero byteLength\"));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            var resolvePromise;\n            var rejectPromise;\n            var promise = newPromise(function (resolve, reject) {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            var readIntoRequest = {\n                _chunkSteps: function (chunk) { return resolvePromise({ value: chunk, done: false }); },\n                _closeSteps: function (chunk) { return resolvePromise({ value: chunk, done: true }); },\n                _errorSteps: function (e) { return rejectPromise(e); }\n            };\n            ReadableStreamBYOBReaderRead(this, view, readIntoRequest);\n            return promise;\n        };\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamBYOBReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        ReadableStreamBYOBReader.prototype.releaseLock = function () {\n            if (!IsReadableStreamBYOBReader(this)) {\n                throw byobReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readIntoRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        };\n        return ReadableStreamBYOBReader;\n    }());\n    Object.defineProperties(ReadableStreamBYOBReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamBYOBReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readIntoRequests')) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamBYOBReaderRead(reader, view, readIntoRequest) {\n        var stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'errored') {\n            readIntoRequest._errorSteps(stream._storedError);\n        }\n        else {\n            ReadableByteStreamControllerPullInto(stream._readableStreamController, view, readIntoRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamBYOBReader.\n    function byobReaderBrandCheckException(name) {\n        return new TypeError(\"ReadableStreamBYOBReader.prototype.\" + name + \" can only be used on a ReadableStreamBYOBReader\");\n    }\n\n    function ExtractHighWaterMark(strategy, defaultHWM) {\n        var highWaterMark = strategy.highWaterMark;\n        if (highWaterMark === undefined) {\n            return defaultHWM;\n        }\n        if (NumberIsNaN(highWaterMark) || highWaterMark < 0) {\n            throw new RangeError('Invalid highWaterMark');\n        }\n        return highWaterMark;\n    }\n    function ExtractSizeAlgorithm(strategy) {\n        var size = strategy.size;\n        if (!size) {\n            return function () { return 1; };\n        }\n        return size;\n    }\n\n    function convertQueuingStrategy(init, context) {\n        assertDictionary(init, context);\n        var highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        var size = init === null || init === void 0 ? void 0 : init.size;\n        return {\n            highWaterMark: highWaterMark === undefined ? undefined : convertUnrestrictedDouble(highWaterMark),\n            size: size === undefined ? undefined : convertQueuingStrategySize(size, context + \" has member 'size' that\")\n        };\n    }\n    function convertQueuingStrategySize(fn, context) {\n        assertFunction(fn, context);\n        return function (chunk) { return convertUnrestrictedDouble(fn(chunk)); };\n    }\n\n    function convertUnderlyingSink(original, context) {\n        assertDictionary(original, context);\n        var abort = original === null || original === void 0 ? void 0 : original.abort;\n        var close = original === null || original === void 0 ? void 0 : original.close;\n        var start = original === null || original === void 0 ? void 0 : original.start;\n        var type = original === null || original === void 0 ? void 0 : original.type;\n        var write = original === null || original === void 0 ? void 0 : original.write;\n        return {\n            abort: abort === undefined ?\n                undefined :\n                convertUnderlyingSinkAbortCallback(abort, original, context + \" has member 'abort' that\"),\n            close: close === undefined ?\n                undefined :\n                convertUnderlyingSinkCloseCallback(close, original, context + \" has member 'close' that\"),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSinkStartCallback(start, original, context + \" has member 'start' that\"),\n            write: write === undefined ?\n                undefined :\n                convertUnderlyingSinkWriteCallback(write, original, context + \" has member 'write' that\"),\n            type: type\n        };\n    }\n    function convertUnderlyingSinkAbortCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (reason) { return promiseCall(fn, original, [reason]); };\n    }\n    function convertUnderlyingSinkCloseCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function () { return promiseCall(fn, original, []); };\n    }\n    function convertUnderlyingSinkStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (controller) { return reflectCall(fn, original, [controller]); };\n    }\n    function convertUnderlyingSinkWriteCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (chunk, controller) { return promiseCall(fn, original, [chunk, controller]); };\n    }\n\n    function assertWritableStream(x, context) {\n        if (!IsWritableStream(x)) {\n            throw new TypeError(context + \" is not a WritableStream.\");\n        }\n    }\n\n    /**\n     * A writable stream represents a destination for data, into which you can write.\n     *\n     * @public\n     */\n    var WritableStream = /** @class */ (function () {\n        function WritableStream(rawUnderlyingSink, rawStrategy) {\n            if (rawUnderlyingSink === void 0) { rawUnderlyingSink = {}; }\n            if (rawStrategy === void 0) { rawStrategy = {}; }\n            if (rawUnderlyingSink === undefined) {\n                rawUnderlyingSink = null;\n            }\n            else {\n                assertObject(rawUnderlyingSink, 'First parameter');\n            }\n            var strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            var underlyingSink = convertUnderlyingSink(rawUnderlyingSink, 'First parameter');\n            InitializeWritableStream(this);\n            var type = underlyingSink.type;\n            if (type !== undefined) {\n                throw new RangeError('Invalid type is specified');\n            }\n            var sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n            var highWaterMark = ExtractHighWaterMark(strategy, 1);\n            SetUpWritableStreamDefaultControllerFromUnderlyingSink(this, underlyingSink, highWaterMark, sizeAlgorithm);\n        }\n        Object.defineProperty(WritableStream.prototype, \"locked\", {\n            /**\n             * Returns whether or not the writable stream is locked to a writer.\n             */\n            get: function () {\n                if (!IsWritableStream(this)) {\n                    throw streamBrandCheckException$2('locked');\n                }\n                return IsWritableStreamLocked(this);\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * Aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be\n         * immediately moved to an errored state, with any queued-up writes discarded. This will also execute any abort\n         * mechanism of the underlying sink.\n         *\n         * The returned promise will fulfill if the stream shuts down successfully, or reject if the underlying sink signaled\n         * that there was an error doing so. Additionally, it will reject with a `TypeError` (without attempting to cancel\n         * the stream) if the stream is currently locked.\n         */\n        WritableStream.prototype.abort = function (reason) {\n            if (reason === void 0) { reason = undefined; }\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('abort'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot abort a stream that already has a writer'));\n            }\n            return WritableStreamAbort(this, reason);\n        };\n        /**\n         * Closes the stream. The underlying sink will finish processing any previously-written chunks, before invoking its\n         * close behavior. During this time any further attempts to write will fail (without erroring the stream).\n         *\n         * The method returns a promise that will fulfill if all remaining chunks are successfully written and the stream\n         * successfully closes, or rejects if an error is encountered during this process. Additionally, it will reject with\n         * a `TypeError` (without attempting to cancel the stream) if the stream is currently locked.\n         */\n        WritableStream.prototype.close = function () {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('close'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close a stream that already has a writer'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamClose(this);\n        };\n        /**\n         * Creates a {@link WritableStreamDefaultWriter | writer} and locks the stream to the new writer. While the stream\n         * is locked, no other writer can be acquired until this one is released.\n         *\n         * This functionality is especially useful for creating abstractions that desire the ability to write to a stream\n         * without interruption or interleaving. By getting a writer for the stream, you can ensure nobody else can write at\n         * the same time, which would cause the resulting written data to be unpredictable and probably useless.\n         */\n        WritableStream.prototype.getWriter = function () {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('getWriter');\n            }\n            return AcquireWritableStreamDefaultWriter(this);\n        };\n        return WritableStream;\n    }());\n    Object.defineProperties(WritableStream.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        getWriter: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStream',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStream.\n    function AcquireWritableStreamDefaultWriter(stream) {\n        return new WritableStreamDefaultWriter(stream);\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n        if (highWaterMark === void 0) { highWaterMark = 1; }\n        if (sizeAlgorithm === void 0) { sizeAlgorithm = function () { return 1; }; }\n        var stream = Object.create(WritableStream.prototype);\n        InitializeWritableStream(stream);\n        var controller = Object.create(WritableStreamDefaultController.prototype);\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    function InitializeWritableStream(stream) {\n        stream._state = 'writable';\n        // The error that will be reported by new method calls once the state becomes errored. Only set when [[state]] is\n        // 'erroring' or 'errored'. May be set to an undefined value.\n        stream._storedError = undefined;\n        stream._writer = undefined;\n        // Initialize to undefined first because the constructor of the controller checks this\n        // variable to validate the caller.\n        stream._writableStreamController = undefined;\n        // This queue is placed here instead of the writer class in order to allow for passing a writer to the next data\n        // producer without waiting for the queued writes to finish.\n        stream._writeRequests = new SimpleQueue();\n        // Write requests are removed from _writeRequests when write() is called on the underlying sink. This prevents\n        // them from being erroneously rejected on error. If a write() call is in-flight, the request is stored here.\n        stream._inFlightWriteRequest = undefined;\n        // The promise that was returned from writer.close(). Stored here because it may be fulfilled after the writer\n        // has been detached.\n        stream._closeRequest = undefined;\n        // Close request is removed from _closeRequest when close() is called on the underlying sink. This prevents it\n        // from being erroneously rejected on error. If a close() call is in-flight, the request is stored here.\n        stream._inFlightCloseRequest = undefined;\n        // The promise that was returned from writer.abort(). This may also be fulfilled after the writer has detached.\n        stream._pendingAbortRequest = undefined;\n        // The backpressure signal set by the controller.\n        stream._backpressure = false;\n    }\n    function IsWritableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_writableStreamController')) {\n            return false;\n        }\n        return true;\n    }\n    function IsWritableStreamLocked(stream) {\n        if (stream._writer === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamAbort(stream, reason) {\n        var state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._pendingAbortRequest !== undefined) {\n            return stream._pendingAbortRequest._promise;\n        }\n        var wasAlreadyErroring = false;\n        if (state === 'erroring') {\n            wasAlreadyErroring = true;\n            // reason will not be used, so don't keep a reference to it.\n            reason = undefined;\n        }\n        var promise = newPromise(function (resolve, reject) {\n            stream._pendingAbortRequest = {\n                _promise: undefined,\n                _resolve: resolve,\n                _reject: reject,\n                _reason: reason,\n                _wasAlreadyErroring: wasAlreadyErroring\n            };\n        });\n        stream._pendingAbortRequest._promise = promise;\n        if (!wasAlreadyErroring) {\n            WritableStreamStartErroring(stream, reason);\n        }\n        return promise;\n    }\n    function WritableStreamClose(stream) {\n        var state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseRejectedWith(new TypeError(\"The stream (in \" + state + \" state) is not in the writable state and cannot be closed\"));\n        }\n        var promise = newPromise(function (resolve, reject) {\n            var closeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._closeRequest = closeRequest;\n        });\n        var writer = stream._writer;\n        if (writer !== undefined && stream._backpressure && state === 'writable') {\n            defaultWriterReadyPromiseResolve(writer);\n        }\n        WritableStreamDefaultControllerClose(stream._writableStreamController);\n        return promise;\n    }\n    // WritableStream API exposed for controllers.\n    function WritableStreamAddWriteRequest(stream) {\n        var promise = newPromise(function (resolve, reject) {\n            var writeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._writeRequests.push(writeRequest);\n        });\n        return promise;\n    }\n    function WritableStreamDealWithRejection(stream, error) {\n        var state = stream._state;\n        if (state === 'writable') {\n            WritableStreamStartErroring(stream, error);\n            return;\n        }\n        WritableStreamFinishErroring(stream);\n    }\n    function WritableStreamStartErroring(stream, reason) {\n        var controller = stream._writableStreamController;\n        stream._state = 'erroring';\n        stream._storedError = reason;\n        var writer = stream._writer;\n        if (writer !== undefined) {\n            WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, reason);\n        }\n        if (!WritableStreamHasOperationMarkedInFlight(stream) && controller._started) {\n            WritableStreamFinishErroring(stream);\n        }\n    }\n    function WritableStreamFinishErroring(stream) {\n        stream._state = 'errored';\n        stream._writableStreamController[ErrorSteps]();\n        var storedError = stream._storedError;\n        stream._writeRequests.forEach(function (writeRequest) {\n            writeRequest._reject(storedError);\n        });\n        stream._writeRequests = new SimpleQueue();\n        if (stream._pendingAbortRequest === undefined) {\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        var abortRequest = stream._pendingAbortRequest;\n        stream._pendingAbortRequest = undefined;\n        if (abortRequest._wasAlreadyErroring) {\n            abortRequest._reject(storedError);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        var promise = stream._writableStreamController[AbortSteps](abortRequest._reason);\n        uponPromise(promise, function () {\n            abortRequest._resolve();\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        }, function (reason) {\n            abortRequest._reject(reason);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        });\n    }\n    function WritableStreamFinishInFlightWrite(stream) {\n        stream._inFlightWriteRequest._resolve(undefined);\n        stream._inFlightWriteRequest = undefined;\n    }\n    function WritableStreamFinishInFlightWriteWithError(stream, error) {\n        stream._inFlightWriteRequest._reject(error);\n        stream._inFlightWriteRequest = undefined;\n        WritableStreamDealWithRejection(stream, error);\n    }\n    function WritableStreamFinishInFlightClose(stream) {\n        stream._inFlightCloseRequest._resolve(undefined);\n        stream._inFlightCloseRequest = undefined;\n        var state = stream._state;\n        if (state === 'erroring') {\n            // The error was too late to do anything, so it is ignored.\n            stream._storedError = undefined;\n            if (stream._pendingAbortRequest !== undefined) {\n                stream._pendingAbortRequest._resolve();\n                stream._pendingAbortRequest = undefined;\n            }\n        }\n        stream._state = 'closed';\n        var writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseResolve(writer);\n        }\n    }\n    function WritableStreamFinishInFlightCloseWithError(stream, error) {\n        stream._inFlightCloseRequest._reject(error);\n        stream._inFlightCloseRequest = undefined;\n        // Never execute sink abort() after sink close().\n        if (stream._pendingAbortRequest !== undefined) {\n            stream._pendingAbortRequest._reject(error);\n            stream._pendingAbortRequest = undefined;\n        }\n        WritableStreamDealWithRejection(stream, error);\n    }\n    // TODO(ricea): Fix alphabetical order.\n    function WritableStreamCloseQueuedOrInFlight(stream) {\n        if (stream._closeRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamHasOperationMarkedInFlight(stream) {\n        if (stream._inFlightWriteRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamMarkCloseRequestInFlight(stream) {\n        stream._inFlightCloseRequest = stream._closeRequest;\n        stream._closeRequest = undefined;\n    }\n    function WritableStreamMarkFirstWriteRequestInFlight(stream) {\n        stream._inFlightWriteRequest = stream._writeRequests.shift();\n    }\n    function WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream) {\n        if (stream._closeRequest !== undefined) {\n            stream._closeRequest._reject(stream._storedError);\n            stream._closeRequest = undefined;\n        }\n        var writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseReject(writer, stream._storedError);\n        }\n    }\n    function WritableStreamUpdateBackpressure(stream, backpressure) {\n        var writer = stream._writer;\n        if (writer !== undefined && backpressure !== stream._backpressure) {\n            if (backpressure) {\n                defaultWriterReadyPromiseReset(writer);\n            }\n            else {\n                defaultWriterReadyPromiseResolve(writer);\n            }\n        }\n        stream._backpressure = backpressure;\n    }\n    /**\n     * A default writer vended by a {@link WritableStream}.\n     *\n     * @public\n     */\n    var WritableStreamDefaultWriter = /** @class */ (function () {\n        function WritableStreamDefaultWriter(stream) {\n            assertRequiredArgument(stream, 1, 'WritableStreamDefaultWriter');\n            assertWritableStream(stream, 'First parameter');\n            if (IsWritableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive writing by another writer');\n            }\n            this._ownerWritableStream = stream;\n            stream._writer = this;\n            var state = stream._state;\n            if (state === 'writable') {\n                if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._backpressure) {\n                    defaultWriterReadyPromiseInitialize(this);\n                }\n                else {\n                    defaultWriterReadyPromiseInitializeAsResolved(this);\n                }\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'erroring') {\n                defaultWriterReadyPromiseInitializeAsRejected(this, stream._storedError);\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'closed') {\n                defaultWriterReadyPromiseInitializeAsResolved(this);\n                defaultWriterClosedPromiseInitializeAsResolved(this);\n            }\n            else {\n                var storedError = stream._storedError;\n                defaultWriterReadyPromiseInitializeAsRejected(this, storedError);\n                defaultWriterClosedPromiseInitializeAsRejected(this, storedError);\n            }\n        }\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, \"closed\", {\n            /**\n             * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n             * the writer’s lock is released before the stream finishes closing.\n             */\n            get: function () {\n                if (!IsWritableStreamDefaultWriter(this)) {\n                    return promiseRejectedWith(defaultWriterBrandCheckException('closed'));\n                }\n                return this._closedPromise;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, \"desiredSize\", {\n            /**\n             * Returns the desired size to fill the stream’s internal queue. It can be negative, if the queue is over-full.\n             * A producer can use this information to determine the right amount of data to write.\n             *\n             * It will be `null` if the stream cannot be successfully written to (due to either being errored, or having an abort\n             * queued up). It will return zero if the stream is closed. And the getter will throw an exception if invoked when\n             * the writer’s lock is released.\n             */\n            get: function () {\n                if (!IsWritableStreamDefaultWriter(this)) {\n                    throw defaultWriterBrandCheckException('desiredSize');\n                }\n                if (this._ownerWritableStream === undefined) {\n                    throw defaultWriterLockException('desiredSize');\n                }\n                return WritableStreamDefaultWriterGetDesiredSize(this);\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, \"ready\", {\n            /**\n             * Returns a promise that will be fulfilled when the desired size to fill the stream’s internal queue transitions\n             * from non-positive to positive, signaling that it is no longer applying backpressure. Once the desired size dips\n             * back to zero or below, the getter will return a new promise that stays pending until the next transition.\n             *\n             * If the stream becomes errored or aborted, or the writer’s lock is released, the returned promise will become\n             * rejected.\n             */\n            get: function () {\n                if (!IsWritableStreamDefaultWriter(this)) {\n                    return promiseRejectedWith(defaultWriterBrandCheckException('ready'));\n                }\n                return this._readyPromise;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.abort | stream.abort(reason)}.\n         */\n        WritableStreamDefaultWriter.prototype.abort = function (reason) {\n            if (reason === void 0) { reason = undefined; }\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('abort'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('abort'));\n            }\n            return WritableStreamDefaultWriterAbort(this, reason);\n        };\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.close | stream.close()}.\n         */\n        WritableStreamDefaultWriter.prototype.close = function () {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('close'));\n            }\n            var stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('close'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(stream)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamDefaultWriterClose(this);\n        };\n        /**\n         * Releases the writer’s lock on the corresponding stream. After the lock is released, the writer is no longer active.\n         * If the associated stream is errored when the lock is released, the writer will appear errored in the same way from\n         * now on; otherwise, the writer will appear closed.\n         *\n         * Note that the lock can still be released even if some ongoing writes have not yet finished (i.e. even if the\n         * promises returned from previous calls to {@link WritableStreamDefaultWriter.write | write()} have not yet settled).\n         * It’s not necessary to hold the lock on the writer for the duration of the write; the lock instead simply prevents\n         * other producers from writing in an interleaved manner.\n         */\n        WritableStreamDefaultWriter.prototype.releaseLock = function () {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('releaseLock');\n            }\n            var stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return;\n            }\n            WritableStreamDefaultWriterRelease(this);\n        };\n        WritableStreamDefaultWriter.prototype.write = function (chunk) {\n            if (chunk === void 0) { chunk = undefined; }\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('write'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('write to'));\n            }\n            return WritableStreamDefaultWriterWrite(this, chunk);\n        };\n        return WritableStreamDefaultWriter;\n    }());\n    Object.defineProperties(WritableStreamDefaultWriter.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        releaseLock: { enumerable: true },\n        write: { enumerable: true },\n        closed: { enumerable: true },\n        desiredSize: { enumerable: true },\n        ready: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultWriter',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStreamDefaultWriter.\n    function IsWritableStreamDefaultWriter(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_ownerWritableStream')) {\n            return false;\n        }\n        return true;\n    }\n    // A client of WritableStreamDefaultWriter may use these functions directly to bypass state check.\n    function WritableStreamDefaultWriterAbort(writer, reason) {\n        var stream = writer._ownerWritableStream;\n        return WritableStreamAbort(stream, reason);\n    }\n    function WritableStreamDefaultWriterClose(writer) {\n        var stream = writer._ownerWritableStream;\n        return WritableStreamClose(stream);\n    }\n    function WritableStreamDefaultWriterCloseWithErrorPropagation(writer) {\n        var stream = writer._ownerWritableStream;\n        var state = stream._state;\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        return WritableStreamDefaultWriterClose(writer);\n    }\n    function WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, error) {\n        if (writer._closedPromiseState === 'pending') {\n            defaultWriterClosedPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterClosedPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, error) {\n        if (writer._readyPromiseState === 'pending') {\n            defaultWriterReadyPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterReadyPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterGetDesiredSize(writer) {\n        var stream = writer._ownerWritableStream;\n        var state = stream._state;\n        if (state === 'errored' || state === 'erroring') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return WritableStreamDefaultControllerGetDesiredSize(stream._writableStreamController);\n    }\n    function WritableStreamDefaultWriterRelease(writer) {\n        var stream = writer._ownerWritableStream;\n        var releasedError = new TypeError(\"Writer was released and can no longer be used to monitor the stream's closedness\");\n        WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, releasedError);\n        // The state transitions to \"errored\" before the sink abort() method runs, but the writer.closed promise is not\n        // rejected until afterwards. This means that simply testing state will not work.\n        WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, releasedError);\n        stream._writer = undefined;\n        writer._ownerWritableStream = undefined;\n    }\n    function WritableStreamDefaultWriterWrite(writer, chunk) {\n        var stream = writer._ownerWritableStream;\n        var controller = stream._writableStreamController;\n        var chunkSize = WritableStreamDefaultControllerGetChunkSize(controller, chunk);\n        if (stream !== writer._ownerWritableStream) {\n            return promiseRejectedWith(defaultWriterLockException('write to'));\n        }\n        var state = stream._state;\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseRejectedWith(new TypeError('The stream is closing or closed and cannot be written to'));\n        }\n        if (state === 'erroring') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        var promise = WritableStreamAddWriteRequest(stream);\n        WritableStreamDefaultControllerWrite(controller, chunk, chunkSize);\n        return promise;\n    }\n    var closeSentinel = {};\n    /**\n     * Allows control of a {@link WritableStream | writable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    var WritableStreamDefaultController = /** @class */ (function () {\n        function WritableStreamDefaultController() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Closes the controlled writable stream, making all future interactions with it fail with the given error `e`.\n         *\n         * This method is rarely used, since usually it suffices to return a rejected promise from one of the underlying\n         * sink's methods. However, it can be useful for suddenly shutting down a stream in response to an event outside the\n         * normal lifecycle of interactions with the underlying sink.\n         */\n        WritableStreamDefaultController.prototype.error = function (e) {\n            if (e === void 0) { e = undefined; }\n            if (!IsWritableStreamDefaultController(this)) {\n                throw new TypeError('WritableStreamDefaultController.prototype.error can only be used on a WritableStreamDefaultController');\n            }\n            var state = this._controlledWritableStream._state;\n            if (state !== 'writable') {\n                // The stream is closed, errored or will be soon. The sink can't do anything useful if it gets an error here, so\n                // just treat it as a no-op.\n                return;\n            }\n            WritableStreamDefaultControllerError(this, e);\n        };\n        /** @internal */\n        WritableStreamDefaultController.prototype[AbortSteps] = function (reason) {\n            var result = this._abortAlgorithm(reason);\n            WritableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        };\n        /** @internal */\n        WritableStreamDefaultController.prototype[ErrorSteps] = function () {\n            ResetQueue(this);\n        };\n        return WritableStreamDefaultController;\n    }());\n    Object.defineProperties(WritableStreamDefaultController.prototype, {\n        error: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations implementing interface required by the WritableStream.\n    function IsWritableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledWritableStream')) {\n            return false;\n        }\n        return true;\n    }\n    function SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledWritableStream = stream;\n        stream._writableStreamController = controller;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._started = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._writeAlgorithm = writeAlgorithm;\n        controller._closeAlgorithm = closeAlgorithm;\n        controller._abortAlgorithm = abortAlgorithm;\n        var backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n        WritableStreamUpdateBackpressure(stream, backpressure);\n        var startResult = startAlgorithm();\n        var startPromise = promiseResolvedWith(startResult);\n        uponPromise(startPromise, function () {\n            controller._started = true;\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, function (r) {\n            controller._started = true;\n            WritableStreamDealWithRejection(stream, r);\n        });\n    }\n    function SetUpWritableStreamDefaultControllerFromUnderlyingSink(stream, underlyingSink, highWaterMark, sizeAlgorithm) {\n        var controller = Object.create(WritableStreamDefaultController.prototype);\n        var startAlgorithm = function () { return undefined; };\n        var writeAlgorithm = function () { return promiseResolvedWith(undefined); };\n        var closeAlgorithm = function () { return promiseResolvedWith(undefined); };\n        var abortAlgorithm = function () { return promiseResolvedWith(undefined); };\n        if (underlyingSink.start !== undefined) {\n            startAlgorithm = function () { return underlyingSink.start(controller); };\n        }\n        if (underlyingSink.write !== undefined) {\n            writeAlgorithm = function (chunk) { return underlyingSink.write(chunk, controller); };\n        }\n        if (underlyingSink.close !== undefined) {\n            closeAlgorithm = function () { return underlyingSink.close(); };\n        }\n        if (underlyingSink.abort !== undefined) {\n            abortAlgorithm = function (reason) { return underlyingSink.abort(reason); };\n        }\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // ClearAlgorithms may be called twice. Erroring the same stream in multiple ways will often result in redundant calls.\n    function WritableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._writeAlgorithm = undefined;\n        controller._closeAlgorithm = undefined;\n        controller._abortAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    function WritableStreamDefaultControllerClose(controller) {\n        EnqueueValueWithSize(controller, closeSentinel, 0);\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    function WritableStreamDefaultControllerGetChunkSize(controller, chunk) {\n        try {\n            return controller._strategySizeAlgorithm(chunk);\n        }\n        catch (chunkSizeE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, chunkSizeE);\n            return 1;\n        }\n    }\n    function WritableStreamDefaultControllerGetDesiredSize(controller) {\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function WritableStreamDefaultControllerWrite(controller, chunk, chunkSize) {\n        try {\n            EnqueueValueWithSize(controller, chunk, chunkSize);\n        }\n        catch (enqueueE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, enqueueE);\n            return;\n        }\n        var stream = controller._controlledWritableStream;\n        if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._state === 'writable') {\n            var backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n            WritableStreamUpdateBackpressure(stream, backpressure);\n        }\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    // Abstract operations for the WritableStreamDefaultController.\n    function WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller) {\n        var stream = controller._controlledWritableStream;\n        if (!controller._started) {\n            return;\n        }\n        if (stream._inFlightWriteRequest !== undefined) {\n            return;\n        }\n        var state = stream._state;\n        if (state === 'erroring') {\n            WritableStreamFinishErroring(stream);\n            return;\n        }\n        if (controller._queue.length === 0) {\n            return;\n        }\n        var value = PeekQueueValue(controller);\n        if (value === closeSentinel) {\n            WritableStreamDefaultControllerProcessClose(controller);\n        }\n        else {\n            WritableStreamDefaultControllerProcessWrite(controller, value);\n        }\n    }\n    function WritableStreamDefaultControllerErrorIfNeeded(controller, error) {\n        if (controller._controlledWritableStream._state === 'writable') {\n            WritableStreamDefaultControllerError(controller, error);\n        }\n    }\n    function WritableStreamDefaultControllerProcessClose(controller) {\n        var stream = controller._controlledWritableStream;\n        WritableStreamMarkCloseRequestInFlight(stream);\n        DequeueValue(controller);\n        var sinkClosePromise = controller._closeAlgorithm();\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        uponPromise(sinkClosePromise, function () {\n            WritableStreamFinishInFlightClose(stream);\n        }, function (reason) {\n            WritableStreamFinishInFlightCloseWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerProcessWrite(controller, chunk) {\n        var stream = controller._controlledWritableStream;\n        WritableStreamMarkFirstWriteRequestInFlight(stream);\n        var sinkWritePromise = controller._writeAlgorithm(chunk);\n        uponPromise(sinkWritePromise, function () {\n            WritableStreamFinishInFlightWrite(stream);\n            var state = stream._state;\n            DequeueValue(controller);\n            if (!WritableStreamCloseQueuedOrInFlight(stream) && state === 'writable') {\n                var backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n                WritableStreamUpdateBackpressure(stream, backpressure);\n            }\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, function (reason) {\n            if (stream._state === 'writable') {\n                WritableStreamDefaultControllerClearAlgorithms(controller);\n            }\n            WritableStreamFinishInFlightWriteWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerGetBackpressure(controller) {\n        var desiredSize = WritableStreamDefaultControllerGetDesiredSize(controller);\n        return desiredSize <= 0;\n    }\n    // A client of WritableStreamDefaultController may use these functions directly to bypass state check.\n    function WritableStreamDefaultControllerError(controller, error) {\n        var stream = controller._controlledWritableStream;\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        WritableStreamStartErroring(stream, error);\n    }\n    // Helper functions for the WritableStream.\n    function streamBrandCheckException$2(name) {\n        return new TypeError(\"WritableStream.prototype.\" + name + \" can only be used on a WritableStream\");\n    }\n    // Helper functions for the WritableStreamDefaultWriter.\n    function defaultWriterBrandCheckException(name) {\n        return new TypeError(\"WritableStreamDefaultWriter.prototype.\" + name + \" can only be used on a WritableStreamDefaultWriter\");\n    }\n    function defaultWriterLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released writer');\n    }\n    function defaultWriterClosedPromiseInitialize(writer) {\n        writer._closedPromise = newPromise(function (resolve, reject) {\n            writer._closedPromise_resolve = resolve;\n            writer._closedPromise_reject = reject;\n            writer._closedPromiseState = 'pending';\n        });\n    }\n    function defaultWriterClosedPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseReject(writer, reason);\n    }\n    function defaultWriterClosedPromiseInitializeAsResolved(writer) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseResolve(writer);\n    }\n    function defaultWriterClosedPromiseReject(writer, reason) {\n        if (writer._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._closedPromise);\n        writer._closedPromise_reject(reason);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'rejected';\n    }\n    function defaultWriterClosedPromiseResetToRejected(writer, reason) {\n        defaultWriterClosedPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterClosedPromiseResolve(writer) {\n        if (writer._closedPromise_resolve === undefined) {\n            return;\n        }\n        writer._closedPromise_resolve(undefined);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'resolved';\n    }\n    function defaultWriterReadyPromiseInitialize(writer) {\n        writer._readyPromise = newPromise(function (resolve, reject) {\n            writer._readyPromise_resolve = resolve;\n            writer._readyPromise_reject = reject;\n        });\n        writer._readyPromiseState = 'pending';\n    }\n    function defaultWriterReadyPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseReject(writer, reason);\n    }\n    function defaultWriterReadyPromiseInitializeAsResolved(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseResolve(writer);\n    }\n    function defaultWriterReadyPromiseReject(writer, reason) {\n        if (writer._readyPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._readyPromise);\n        writer._readyPromise_reject(reason);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'rejected';\n    }\n    function defaultWriterReadyPromiseReset(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n    }\n    function defaultWriterReadyPromiseResetToRejected(writer, reason) {\n        defaultWriterReadyPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterReadyPromiseResolve(writer) {\n        if (writer._readyPromise_resolve === undefined) {\n            return;\n        }\n        writer._readyPromise_resolve(undefined);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'fulfilled';\n    }\n\n    function isAbortSignal(value) {\n        if (typeof value !== 'object' || value === null) {\n            return false;\n        }\n        try {\n            return typeof value.aborted === 'boolean';\n        }\n        catch (_a) {\n            // AbortSignal.prototype.aborted throws if its brand check fails\n            return false;\n        }\n    }\n\n    /// <reference lib=\"dom\" />\n    var NativeDOMException = typeof DOMException !== 'undefined' ? DOMException : undefined;\n\n    /// <reference types=\"node\" />\n    function isDOMExceptionConstructor(ctor) {\n        if (!(typeof ctor === 'function' || typeof ctor === 'object')) {\n            return false;\n        }\n        try {\n            new ctor();\n            return true;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    function createDOMExceptionPolyfill() {\n        // eslint-disable-next-line no-shadow\n        var ctor = function DOMException(message, name) {\n            this.message = message || '';\n            this.name = name || 'Error';\n            if (Error.captureStackTrace) {\n                Error.captureStackTrace(this, this.constructor);\n            }\n        };\n        ctor.prototype = Object.create(Error.prototype);\n        Object.defineProperty(ctor.prototype, 'constructor', { value: ctor, writable: true, configurable: true });\n        return ctor;\n    }\n    // eslint-disable-next-line no-redeclare\n    var DOMException$1 = isDOMExceptionConstructor(NativeDOMException) ? NativeDOMException : createDOMExceptionPolyfill();\n\n    function ReadableStreamPipeTo(source, dest, preventClose, preventAbort, preventCancel, signal) {\n        var reader = AcquireReadableStreamDefaultReader(source);\n        var writer = AcquireWritableStreamDefaultWriter(dest);\n        source._disturbed = true;\n        var shuttingDown = false;\n        // This is used to keep track of the spec's requirement that we wait for ongoing writes during shutdown.\n        var currentWrite = promiseResolvedWith(undefined);\n        return newPromise(function (resolve, reject) {\n            var abortAlgorithm;\n            if (signal !== undefined) {\n                abortAlgorithm = function () {\n                    var error = new DOMException$1('Aborted', 'AbortError');\n                    var actions = [];\n                    if (!preventAbort) {\n                        actions.push(function () {\n                            if (dest._state === 'writable') {\n                                return WritableStreamAbort(dest, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    if (!preventCancel) {\n                        actions.push(function () {\n                            if (source._state === 'readable') {\n                                return ReadableStreamCancel(source, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    shutdownWithAction(function () { return Promise.all(actions.map(function (action) { return action(); })); }, true, error);\n                };\n                if (signal.aborted) {\n                    abortAlgorithm();\n                    return;\n                }\n                signal.addEventListener('abort', abortAlgorithm);\n            }\n            // Using reader and writer, read all chunks from this and write them to dest\n            // - Backpressure must be enforced\n            // - Shutdown must stop all activity\n            function pipeLoop() {\n                return newPromise(function (resolveLoop, rejectLoop) {\n                    function next(done) {\n                        if (done) {\n                            resolveLoop();\n                        }\n                        else {\n                            // Use `PerformPromiseThen` instead of `uponPromise` to avoid\n                            // adding unnecessary `.catch(rethrowAssertionErrorRejection)` handlers\n                            PerformPromiseThen(pipeStep(), next, rejectLoop);\n                        }\n                    }\n                    next(false);\n                });\n            }\n            function pipeStep() {\n                if (shuttingDown) {\n                    return promiseResolvedWith(true);\n                }\n                return PerformPromiseThen(writer._readyPromise, function () {\n                    return newPromise(function (resolveRead, rejectRead) {\n                        ReadableStreamDefaultReaderRead(reader, {\n                            _chunkSteps: function (chunk) {\n                                currentWrite = PerformPromiseThen(WritableStreamDefaultWriterWrite(writer, chunk), undefined, noop);\n                                resolveRead(false);\n                            },\n                            _closeSteps: function () { return resolveRead(true); },\n                            _errorSteps: rejectRead\n                        });\n                    });\n                });\n            }\n            // Errors must be propagated forward\n            isOrBecomesErrored(source, reader._closedPromise, function (storedError) {\n                if (!preventAbort) {\n                    shutdownWithAction(function () { return WritableStreamAbort(dest, storedError); }, true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Errors must be propagated backward\n            isOrBecomesErrored(dest, writer._closedPromise, function (storedError) {\n                if (!preventCancel) {\n                    shutdownWithAction(function () { return ReadableStreamCancel(source, storedError); }, true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Closing must be propagated forward\n            isOrBecomesClosed(source, reader._closedPromise, function () {\n                if (!preventClose) {\n                    shutdownWithAction(function () { return WritableStreamDefaultWriterCloseWithErrorPropagation(writer); });\n                }\n                else {\n                    shutdown();\n                }\n            });\n            // Closing must be propagated backward\n            if (WritableStreamCloseQueuedOrInFlight(dest) || dest._state === 'closed') {\n                var destClosed_1 = new TypeError('the destination writable stream closed before all data could be piped to it');\n                if (!preventCancel) {\n                    shutdownWithAction(function () { return ReadableStreamCancel(source, destClosed_1); }, true, destClosed_1);\n                }\n                else {\n                    shutdown(true, destClosed_1);\n                }\n            }\n            setPromiseIsHandledToTrue(pipeLoop());\n            function waitForWritesToFinish() {\n                // Another write may have started while we were waiting on this currentWrite, so we have to be sure to wait\n                // for that too.\n                var oldCurrentWrite = currentWrite;\n                return PerformPromiseThen(currentWrite, function () { return oldCurrentWrite !== currentWrite ? waitForWritesToFinish() : undefined; });\n            }\n            function isOrBecomesErrored(stream, promise, action) {\n                if (stream._state === 'errored') {\n                    action(stream._storedError);\n                }\n                else {\n                    uponRejection(promise, action);\n                }\n            }\n            function isOrBecomesClosed(stream, promise, action) {\n                if (stream._state === 'closed') {\n                    action();\n                }\n                else {\n                    uponFulfillment(promise, action);\n                }\n            }\n            function shutdownWithAction(action, originalIsError, originalError) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), doTheRest);\n                }\n                else {\n                    doTheRest();\n                }\n                function doTheRest() {\n                    uponPromise(action(), function () { return finalize(originalIsError, originalError); }, function (newError) { return finalize(true, newError); });\n                }\n            }\n            function shutdown(isError, error) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), function () { return finalize(isError, error); });\n                }\n                else {\n                    finalize(isError, error);\n                }\n            }\n            function finalize(isError, error) {\n                WritableStreamDefaultWriterRelease(writer);\n                ReadableStreamReaderGenericRelease(reader);\n                if (signal !== undefined) {\n                    signal.removeEventListener('abort', abortAlgorithm);\n                }\n                if (isError) {\n                    reject(error);\n                }\n                else {\n                    resolve(undefined);\n                }\n            }\n        });\n    }\n\n    /**\n     * Allows control of a {@link ReadableStream | readable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    var ReadableStreamDefaultController = /** @class */ (function () {\n        function ReadableStreamDefaultController() {\n            throw new TypeError('Illegal constructor');\n        }\n        Object.defineProperty(ReadableStreamDefaultController.prototype, \"desiredSize\", {\n            /**\n             * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n             * over-full. An underlying source ought to use this information to determine when and how to apply backpressure.\n             */\n            get: function () {\n                if (!IsReadableStreamDefaultController(this)) {\n                    throw defaultControllerBrandCheckException$1('desiredSize');\n                }\n                return ReadableStreamDefaultControllerGetDesiredSize(this);\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        ReadableStreamDefaultController.prototype.close = function () {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('close');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits close');\n            }\n            ReadableStreamDefaultControllerClose(this);\n        };\n        ReadableStreamDefaultController.prototype.enqueue = function (chunk) {\n            if (chunk === void 0) { chunk = undefined; }\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('enqueue');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits enqueue');\n            }\n            return ReadableStreamDefaultControllerEnqueue(this, chunk);\n        };\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        ReadableStreamDefaultController.prototype.error = function (e) {\n            if (e === void 0) { e = undefined; }\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('error');\n            }\n            ReadableStreamDefaultControllerError(this, e);\n        };\n        /** @internal */\n        ReadableStreamDefaultController.prototype[CancelSteps] = function (reason) {\n            ResetQueue(this);\n            var result = this._cancelAlgorithm(reason);\n            ReadableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        };\n        /** @internal */\n        ReadableStreamDefaultController.prototype[PullSteps] = function (readRequest) {\n            var stream = this._controlledReadableStream;\n            if (this._queue.length > 0) {\n                var chunk = DequeueValue(this);\n                if (this._closeRequested && this._queue.length === 0) {\n                    ReadableStreamDefaultControllerClearAlgorithms(this);\n                    ReadableStreamClose(stream);\n                }\n                else {\n                    ReadableStreamDefaultControllerCallPullIfNeeded(this);\n                }\n                readRequest._chunkSteps(chunk);\n            }\n            else {\n                ReadableStreamAddReadRequest(stream, readRequest);\n                ReadableStreamDefaultControllerCallPullIfNeeded(this);\n            }\n        };\n        return ReadableStreamDefaultController;\n    }());\n    Object.defineProperties(ReadableStreamDefaultController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStreamDefaultController.\n    function IsReadableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableStream')) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamDefaultControllerCallPullIfNeeded(controller) {\n        var shouldPull = ReadableStreamDefaultControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        var pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, function () {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n            }\n        }, function (e) {\n            ReadableStreamDefaultControllerError(controller, e);\n        });\n    }\n    function ReadableStreamDefaultControllerShouldCallPull(controller) {\n        var stream = controller._controlledReadableStream;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        var desiredSize = ReadableStreamDefaultControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    // A client of ReadableStreamDefaultController may use these functions directly to bypass state check.\n    function ReadableStreamDefaultControllerClose(controller) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        var stream = controller._controlledReadableStream;\n        controller._closeRequested = true;\n        if (controller._queue.length === 0) {\n            ReadableStreamDefaultControllerClearAlgorithms(controller);\n            ReadableStreamClose(stream);\n        }\n    }\n    function ReadableStreamDefaultControllerEnqueue(controller, chunk) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        var stream = controller._controlledReadableStream;\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            ReadableStreamFulfillReadRequest(stream, chunk, false);\n        }\n        else {\n            var chunkSize = void 0;\n            try {\n                chunkSize = controller._strategySizeAlgorithm(chunk);\n            }\n            catch (chunkSizeE) {\n                ReadableStreamDefaultControllerError(controller, chunkSizeE);\n                throw chunkSizeE;\n            }\n            try {\n                EnqueueValueWithSize(controller, chunk, chunkSize);\n            }\n            catch (enqueueE) {\n                ReadableStreamDefaultControllerError(controller, enqueueE);\n                throw enqueueE;\n            }\n        }\n        ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n    }\n    function ReadableStreamDefaultControllerError(controller, e) {\n        var stream = controller._controlledReadableStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ResetQueue(controller);\n        ReadableStreamDefaultControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableStreamDefaultControllerGetDesiredSize(controller) {\n        var state = controller._controlledReadableStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    // This is used in the implementation of TransformStream.\n    function ReadableStreamDefaultControllerHasBackpressure(controller) {\n        if (ReadableStreamDefaultControllerShouldCallPull(controller)) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamDefaultControllerCanCloseOrEnqueue(controller) {\n        var state = controller._controlledReadableStream._state;\n        if (!controller._closeRequested && state === 'readable') {\n            return true;\n        }\n        return false;\n    }\n    function SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledReadableStream = stream;\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._started = false;\n        controller._closeRequested = false;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        stream._readableStreamController = controller;\n        var startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), function () {\n            controller._started = true;\n            ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n        }, function (r) {\n            ReadableStreamDefaultControllerError(controller, r);\n        });\n    }\n    function SetUpReadableStreamDefaultControllerFromUnderlyingSource(stream, underlyingSource, highWaterMark, sizeAlgorithm) {\n        var controller = Object.create(ReadableStreamDefaultController.prototype);\n        var startAlgorithm = function () { return undefined; };\n        var pullAlgorithm = function () { return promiseResolvedWith(undefined); };\n        var cancelAlgorithm = function () { return promiseResolvedWith(undefined); };\n        if (underlyingSource.start !== undefined) {\n            startAlgorithm = function () { return underlyingSource.start(controller); };\n        }\n        if (underlyingSource.pull !== undefined) {\n            pullAlgorithm = function () { return underlyingSource.pull(controller); };\n        }\n        if (underlyingSource.cancel !== undefined) {\n            cancelAlgorithm = function (reason) { return underlyingSource.cancel(reason); };\n        }\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // Helper functions for the ReadableStreamDefaultController.\n    function defaultControllerBrandCheckException$1(name) {\n        return new TypeError(\"ReadableStreamDefaultController.prototype.\" + name + \" can only be used on a ReadableStreamDefaultController\");\n    }\n\n    function ReadableStreamTee(stream, cloneForBranch2) {\n        var reader = AcquireReadableStreamDefaultReader(stream);\n        var reading = false;\n        var canceled1 = false;\n        var canceled2 = false;\n        var reason1;\n        var reason2;\n        var branch1;\n        var branch2;\n        var resolveCancelPromise;\n        var cancelPromise = newPromise(function (resolve) {\n            resolveCancelPromise = resolve;\n        });\n        function pullAlgorithm() {\n            if (reading) {\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            var readRequest = {\n                _chunkSteps: function (value) {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(function () {\n                        reading = false;\n                        var value1 = value;\n                        var value2 = value;\n                        // There is no way to access the cloning code right now in the reference implementation.\n                        // If we add one then we'll need an implementation for serializable objects.\n                        // if (!canceled2 && cloneForBranch2) {\n                        //   value2 = StructuredDeserialize(StructuredSerialize(value2));\n                        // }\n                        if (!canceled1) {\n                            ReadableStreamDefaultControllerEnqueue(branch1._readableStreamController, value1);\n                        }\n                        if (!canceled2) {\n                            ReadableStreamDefaultControllerEnqueue(branch2._readableStreamController, value2);\n                        }\n                    });\n                },\n                _closeSteps: function () {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableStreamDefaultControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableStreamDefaultControllerClose(branch2._readableStreamController);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: function () {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                var compositeReason = CreateArrayFromList([reason1, reason2]);\n                var cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                var compositeReason = CreateArrayFromList([reason1, reason2]);\n                var cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            // do nothing\n        }\n        branch1 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel1Algorithm);\n        branch2 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel2Algorithm);\n        uponRejection(reader._closedPromise, function (r) {\n            ReadableStreamDefaultControllerError(branch1._readableStreamController, r);\n            ReadableStreamDefaultControllerError(branch2._readableStreamController, r);\n            if (!canceled1 || !canceled2) {\n                resolveCancelPromise(undefined);\n            }\n        });\n        return [branch1, branch2];\n    }\n\n    function convertUnderlyingDefaultOrByteSource(source, context) {\n        assertDictionary(source, context);\n        var original = source;\n        var autoAllocateChunkSize = original === null || original === void 0 ? void 0 : original.autoAllocateChunkSize;\n        var cancel = original === null || original === void 0 ? void 0 : original.cancel;\n        var pull = original === null || original === void 0 ? void 0 : original.pull;\n        var start = original === null || original === void 0 ? void 0 : original.start;\n        var type = original === null || original === void 0 ? void 0 : original.type;\n        return {\n            autoAllocateChunkSize: autoAllocateChunkSize === undefined ?\n                undefined :\n                convertUnsignedLongLongWithEnforceRange(autoAllocateChunkSize, context + \" has member 'autoAllocateChunkSize' that\"),\n            cancel: cancel === undefined ?\n                undefined :\n                convertUnderlyingSourceCancelCallback(cancel, original, context + \" has member 'cancel' that\"),\n            pull: pull === undefined ?\n                undefined :\n                convertUnderlyingSourcePullCallback(pull, original, context + \" has member 'pull' that\"),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSourceStartCallback(start, original, context + \" has member 'start' that\"),\n            type: type === undefined ? undefined : convertReadableStreamType(type, context + \" has member 'type' that\")\n        };\n    }\n    function convertUnderlyingSourceCancelCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (reason) { return promiseCall(fn, original, [reason]); };\n    }\n    function convertUnderlyingSourcePullCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (controller) { return promiseCall(fn, original, [controller]); };\n    }\n    function convertUnderlyingSourceStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (controller) { return reflectCall(fn, original, [controller]); };\n    }\n    function convertReadableStreamType(type, context) {\n        type = \"\" + type;\n        if (type !== 'bytes') {\n            throw new TypeError(context + \" '\" + type + \"' is not a valid enumeration value for ReadableStreamType\");\n        }\n        return type;\n    }\n\n    function convertReaderOptions(options, context) {\n        assertDictionary(options, context);\n        var mode = options === null || options === void 0 ? void 0 : options.mode;\n        return {\n            mode: mode === undefined ? undefined : convertReadableStreamReaderMode(mode, context + \" has member 'mode' that\")\n        };\n    }\n    function convertReadableStreamReaderMode(mode, context) {\n        mode = \"\" + mode;\n        if (mode !== 'byob') {\n            throw new TypeError(context + \" '\" + mode + \"' is not a valid enumeration value for ReadableStreamReaderMode\");\n        }\n        return mode;\n    }\n\n    function convertIteratorOptions(options, context) {\n        assertDictionary(options, context);\n        var preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        return { preventCancel: Boolean(preventCancel) };\n    }\n\n    function convertPipeOptions(options, context) {\n        assertDictionary(options, context);\n        var preventAbort = options === null || options === void 0 ? void 0 : options.preventAbort;\n        var preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        var preventClose = options === null || options === void 0 ? void 0 : options.preventClose;\n        var signal = options === null || options === void 0 ? void 0 : options.signal;\n        if (signal !== undefined) {\n            assertAbortSignal(signal, context + \" has member 'signal' that\");\n        }\n        return {\n            preventAbort: Boolean(preventAbort),\n            preventCancel: Boolean(preventCancel),\n            preventClose: Boolean(preventClose),\n            signal: signal\n        };\n    }\n    function assertAbortSignal(signal, context) {\n        if (!isAbortSignal(signal)) {\n            throw new TypeError(context + \" is not an AbortSignal.\");\n        }\n    }\n\n    function convertReadableWritablePair(pair, context) {\n        assertDictionary(pair, context);\n        var readable = pair === null || pair === void 0 ? void 0 : pair.readable;\n        assertRequiredField(readable, 'readable', 'ReadableWritablePair');\n        assertReadableStream(readable, context + \" has member 'readable' that\");\n        var writable = pair === null || pair === void 0 ? void 0 : pair.writable;\n        assertRequiredField(writable, 'writable', 'ReadableWritablePair');\n        assertWritableStream(writable, context + \" has member 'writable' that\");\n        return { readable: readable, writable: writable };\n    }\n\n    /**\n     * A readable stream represents a source of data, from which you can read.\n     *\n     * @public\n     */\n    var ReadableStream = /** @class */ (function () {\n        function ReadableStream(rawUnderlyingSource, rawStrategy) {\n            if (rawUnderlyingSource === void 0) { rawUnderlyingSource = {}; }\n            if (rawStrategy === void 0) { rawStrategy = {}; }\n            if (rawUnderlyingSource === undefined) {\n                rawUnderlyingSource = null;\n            }\n            else {\n                assertObject(rawUnderlyingSource, 'First parameter');\n            }\n            var strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            var underlyingSource = convertUnderlyingDefaultOrByteSource(rawUnderlyingSource, 'First parameter');\n            InitializeReadableStream(this);\n            if (underlyingSource.type === 'bytes') {\n                if (strategy.size !== undefined) {\n                    throw new RangeError('The strategy for a byte stream cannot have a size function');\n                }\n                var highWaterMark = ExtractHighWaterMark(strategy, 0);\n                SetUpReadableByteStreamControllerFromUnderlyingSource(this, underlyingSource, highWaterMark);\n            }\n            else {\n                var sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n                var highWaterMark = ExtractHighWaterMark(strategy, 1);\n                SetUpReadableStreamDefaultControllerFromUnderlyingSource(this, underlyingSource, highWaterMark, sizeAlgorithm);\n            }\n        }\n        Object.defineProperty(ReadableStream.prototype, \"locked\", {\n            /**\n             * Whether or not the readable stream is locked to a {@link ReadableStreamDefaultReader | reader}.\n             */\n            get: function () {\n                if (!IsReadableStream(this)) {\n                    throw streamBrandCheckException$1('locked');\n                }\n                return IsReadableStreamLocked(this);\n            },\n            enumerable: false,\n            configurable: true\n        });\n        /**\n         * Cancels the stream, signaling a loss of interest in the stream by a consumer.\n         *\n         * The supplied `reason` argument will be given to the underlying source's {@link UnderlyingSource.cancel | cancel()}\n         * method, which might or might not use it.\n         */\n        ReadableStream.prototype.cancel = function (reason) {\n            if (reason === void 0) { reason = undefined; }\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('cancel'));\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot cancel a stream that already has a reader'));\n            }\n            return ReadableStreamCancel(this, reason);\n        };\n        ReadableStream.prototype.getReader = function (rawOptions) {\n            if (rawOptions === void 0) { rawOptions = undefined; }\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('getReader');\n            }\n            var options = convertReaderOptions(rawOptions, 'First parameter');\n            if (options.mode === undefined) {\n                return AcquireReadableStreamDefaultReader(this);\n            }\n            return AcquireReadableStreamBYOBReader(this);\n        };\n        ReadableStream.prototype.pipeThrough = function (rawTransform, rawOptions) {\n            if (rawOptions === void 0) { rawOptions = {}; }\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('pipeThrough');\n            }\n            assertRequiredArgument(rawTransform, 1, 'pipeThrough');\n            var transform = convertReadableWritablePair(rawTransform, 'First parameter');\n            var options = convertPipeOptions(rawOptions, 'Second parameter');\n            if (IsReadableStreamLocked(this)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked ReadableStream');\n            }\n            if (IsWritableStreamLocked(transform.writable)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked WritableStream');\n            }\n            var promise = ReadableStreamPipeTo(this, transform.writable, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n            setPromiseIsHandledToTrue(promise);\n            return transform.readable;\n        };\n        ReadableStream.prototype.pipeTo = function (destination, rawOptions) {\n            if (rawOptions === void 0) { rawOptions = {}; }\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('pipeTo'));\n            }\n            if (destination === undefined) {\n                return promiseRejectedWith(\"Parameter 1 is required in 'pipeTo'.\");\n            }\n            if (!IsWritableStream(destination)) {\n                return promiseRejectedWith(new TypeError(\"ReadableStream.prototype.pipeTo's first argument must be a WritableStream\"));\n            }\n            var options;\n            try {\n                options = convertPipeOptions(rawOptions, 'Second parameter');\n            }\n            catch (e) {\n                return promiseRejectedWith(e);\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked ReadableStream'));\n            }\n            if (IsWritableStreamLocked(destination)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked WritableStream'));\n            }\n            return ReadableStreamPipeTo(this, destination, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n        };\n        /**\n         * Tees this readable stream, returning a two-element array containing the two resulting branches as\n         * new {@link ReadableStream} instances.\n         *\n         * Teeing a stream will lock it, preventing any other consumer from acquiring a reader.\n         * To cancel the stream, cancel both of the resulting branches; a composite cancellation reason will then be\n         * propagated to the stream's underlying source.\n         *\n         * Note that the chunks seen in each branch will be the same object. If the chunks are not immutable,\n         * this could allow interference between the two branches.\n         */\n        ReadableStream.prototype.tee = function () {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('tee');\n            }\n            var branches = ReadableStreamTee(this);\n            return CreateArrayFromList(branches);\n        };\n        ReadableStream.prototype.values = function (rawOptions) {\n            if (rawOptions === void 0) { rawOptions = undefined; }\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('values');\n            }\n            var options = convertIteratorOptions(rawOptions, 'First parameter');\n            return AcquireReadableStreamAsyncIterator(this, options.preventCancel);\n        };\n        return ReadableStream;\n    }());\n    Object.defineProperties(ReadableStream.prototype, {\n        cancel: { enumerable: true },\n        getReader: { enumerable: true },\n        pipeThrough: { enumerable: true },\n        pipeTo: { enumerable: true },\n        tee: { enumerable: true },\n        values: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStream',\n            configurable: true\n        });\n    }\n    if (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.asyncIterator, {\n            value: ReadableStream.prototype.values,\n            writable: true,\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStream.\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n        if (highWaterMark === void 0) { highWaterMark = 1; }\n        if (sizeAlgorithm === void 0) { sizeAlgorithm = function () { return 1; }; }\n        var stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        var controller = Object.create(ReadableStreamDefaultController.prototype);\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    function InitializeReadableStream(stream) {\n        stream._state = 'readable';\n        stream._reader = undefined;\n        stream._storedError = undefined;\n        stream._disturbed = false;\n    }\n    function IsReadableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readableStreamController')) {\n            return false;\n        }\n        return true;\n    }\n    function IsReadableStreamLocked(stream) {\n        if (stream._reader === undefined) {\n            return false;\n        }\n        return true;\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamCancel(stream, reason) {\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        ReadableStreamClose(stream);\n        var sourceCancelPromise = stream._readableStreamController[CancelSteps](reason);\n        return transformPromiseWith(sourceCancelPromise, noop);\n    }\n    function ReadableStreamClose(stream) {\n        stream._state = 'closed';\n        var reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseResolve(reader);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(function (readRequest) {\n                readRequest._closeSteps();\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n    }\n    function ReadableStreamError(stream, e) {\n        stream._state = 'errored';\n        stream._storedError = e;\n        var reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseReject(reader, e);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(function (readRequest) {\n                readRequest._errorSteps(e);\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n        else {\n            reader._readIntoRequests.forEach(function (readIntoRequest) {\n                readIntoRequest._errorSteps(e);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamBrandCheckException$1(name) {\n        return new TypeError(\"ReadableStream.prototype.\" + name + \" can only be used on a ReadableStream\");\n    }\n\n    function convertQueuingStrategyInit(init, context) {\n        assertDictionary(init, context);\n        var highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        assertRequiredField(highWaterMark, 'highWaterMark', 'QueuingStrategyInit');\n        return {\n            highWaterMark: convertUnrestrictedDouble(highWaterMark)\n        };\n    }\n\n    var byteLengthSizeFunction = function size(chunk) {\n        return chunk.byteLength;\n    };\n    /**\n     * A queuing strategy that counts the number of bytes in each chunk.\n     *\n     * @public\n     */\n    var ByteLengthQueuingStrategy = /** @class */ (function () {\n        function ByteLengthQueuingStrategy(options) {\n            assertRequiredArgument(options, 1, 'ByteLengthQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._byteLengthQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        Object.defineProperty(ByteLengthQueuingStrategy.prototype, \"highWaterMark\", {\n            /**\n             * Returns the high water mark provided to the constructor.\n             */\n            get: function () {\n                if (!IsByteLengthQueuingStrategy(this)) {\n                    throw byteLengthBrandCheckException('highWaterMark');\n                }\n                return this._byteLengthQueuingStrategyHighWaterMark;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Object.defineProperty(ByteLengthQueuingStrategy.prototype, \"size\", {\n            /**\n             * Measures the size of `chunk` by returning the value of its `byteLength` property.\n             */\n            get: function () {\n                if (!IsByteLengthQueuingStrategy(this)) {\n                    throw byteLengthBrandCheckException('size');\n                }\n                return byteLengthSizeFunction;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        return ByteLengthQueuingStrategy;\n    }());\n    Object.defineProperties(ByteLengthQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ByteLengthQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ByteLengthQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the ByteLengthQueuingStrategy.\n    function byteLengthBrandCheckException(name) {\n        return new TypeError(\"ByteLengthQueuingStrategy.prototype.\" + name + \" can only be used on a ByteLengthQueuingStrategy\");\n    }\n    function IsByteLengthQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_byteLengthQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return true;\n    }\n\n    var countSizeFunction = function size() {\n        return 1;\n    };\n    /**\n     * A queuing strategy that counts the number of chunks.\n     *\n     * @public\n     */\n    var CountQueuingStrategy = /** @class */ (function () {\n        function CountQueuingStrategy(options) {\n            assertRequiredArgument(options, 1, 'CountQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._countQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        Object.defineProperty(CountQueuingStrategy.prototype, \"highWaterMark\", {\n            /**\n             * Returns the high water mark provided to the constructor.\n             */\n            get: function () {\n                if (!IsCountQueuingStrategy(this)) {\n                    throw countBrandCheckException('highWaterMark');\n                }\n                return this._countQueuingStrategyHighWaterMark;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Object.defineProperty(CountQueuingStrategy.prototype, \"size\", {\n            /**\n             * Measures the size of `chunk` by always returning 1.\n             * This ensures that the total queue size is a count of the number of chunks in the queue.\n             */\n            get: function () {\n                if (!IsCountQueuingStrategy(this)) {\n                    throw countBrandCheckException('size');\n                }\n                return countSizeFunction;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        return CountQueuingStrategy;\n    }());\n    Object.defineProperties(CountQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(CountQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'CountQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the CountQueuingStrategy.\n    function countBrandCheckException(name) {\n        return new TypeError(\"CountQueuingStrategy.prototype.\" + name + \" can only be used on a CountQueuingStrategy\");\n    }\n    function IsCountQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_countQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return true;\n    }\n\n    function convertTransformer(original, context) {\n        assertDictionary(original, context);\n        var flush = original === null || original === void 0 ? void 0 : original.flush;\n        var readableType = original === null || original === void 0 ? void 0 : original.readableType;\n        var start = original === null || original === void 0 ? void 0 : original.start;\n        var transform = original === null || original === void 0 ? void 0 : original.transform;\n        var writableType = original === null || original === void 0 ? void 0 : original.writableType;\n        return {\n            flush: flush === undefined ?\n                undefined :\n                convertTransformerFlushCallback(flush, original, context + \" has member 'flush' that\"),\n            readableType: readableType,\n            start: start === undefined ?\n                undefined :\n                convertTransformerStartCallback(start, original, context + \" has member 'start' that\"),\n            transform: transform === undefined ?\n                undefined :\n                convertTransformerTransformCallback(transform, original, context + \" has member 'transform' that\"),\n            writableType: writableType\n        };\n    }\n    function convertTransformerFlushCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (controller) { return promiseCall(fn, original, [controller]); };\n    }\n    function convertTransformerStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (controller) { return reflectCall(fn, original, [controller]); };\n    }\n    function convertTransformerTransformCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return function (chunk, controller) { return promiseCall(fn, original, [chunk, controller]); };\n    }\n\n    // Class TransformStream\n    /**\n     * A transform stream consists of a pair of streams: a {@link WritableStream | writable stream},\n     * known as its writable side, and a {@link ReadableStream | readable stream}, known as its readable side.\n     * In a manner specific to the transform stream in question, writes to the writable side result in new data being\n     * made available for reading from the readable side.\n     *\n     * @public\n     */\n    var TransformStream = /** @class */ (function () {\n        function TransformStream(rawTransformer, rawWritableStrategy, rawReadableStrategy) {\n            if (rawTransformer === void 0) { rawTransformer = {}; }\n            if (rawWritableStrategy === void 0) { rawWritableStrategy = {}; }\n            if (rawReadableStrategy === void 0) { rawReadableStrategy = {}; }\n            if (rawTransformer === undefined) {\n                rawTransformer = null;\n            }\n            var writableStrategy = convertQueuingStrategy(rawWritableStrategy, 'Second parameter');\n            var readableStrategy = convertQueuingStrategy(rawReadableStrategy, 'Third parameter');\n            var transformer = convertTransformer(rawTransformer, 'First parameter');\n            if (transformer.readableType !== undefined) {\n                throw new RangeError('Invalid readableType specified');\n            }\n            if (transformer.writableType !== undefined) {\n                throw new RangeError('Invalid writableType specified');\n            }\n            var readableHighWaterMark = ExtractHighWaterMark(readableStrategy, 0);\n            var readableSizeAlgorithm = ExtractSizeAlgorithm(readableStrategy);\n            var writableHighWaterMark = ExtractHighWaterMark(writableStrategy, 1);\n            var writableSizeAlgorithm = ExtractSizeAlgorithm(writableStrategy);\n            var startPromise_resolve;\n            var startPromise = newPromise(function (resolve) {\n                startPromise_resolve = resolve;\n            });\n            InitializeTransformStream(this, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n            SetUpTransformStreamDefaultControllerFromTransformer(this, transformer);\n            if (transformer.start !== undefined) {\n                startPromise_resolve(transformer.start(this._transformStreamController));\n            }\n            else {\n                startPromise_resolve(undefined);\n            }\n        }\n        Object.defineProperty(TransformStream.prototype, \"readable\", {\n            /**\n             * The readable side of the transform stream.\n             */\n            get: function () {\n                if (!IsTransformStream(this)) {\n                    throw streamBrandCheckException('readable');\n                }\n                return this._readable;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Object.defineProperty(TransformStream.prototype, \"writable\", {\n            /**\n             * The writable side of the transform stream.\n             */\n            get: function () {\n                if (!IsTransformStream(this)) {\n                    throw streamBrandCheckException('writable');\n                }\n                return this._writable;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        return TransformStream;\n    }());\n    Object.defineProperties(TransformStream.prototype, {\n        readable: { enumerable: true },\n        writable: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStream',\n            configurable: true\n        });\n    }\n    function InitializeTransformStream(stream, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm) {\n        function startAlgorithm() {\n            return startPromise;\n        }\n        function writeAlgorithm(chunk) {\n            return TransformStreamDefaultSinkWriteAlgorithm(stream, chunk);\n        }\n        function abortAlgorithm(reason) {\n            return TransformStreamDefaultSinkAbortAlgorithm(stream, reason);\n        }\n        function closeAlgorithm() {\n            return TransformStreamDefaultSinkCloseAlgorithm(stream);\n        }\n        stream._writable = CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, writableHighWaterMark, writableSizeAlgorithm);\n        function pullAlgorithm() {\n            return TransformStreamDefaultSourcePullAlgorithm(stream);\n        }\n        function cancelAlgorithm(reason) {\n            TransformStreamErrorWritableAndUnblockWrite(stream, reason);\n            return promiseResolvedWith(undefined);\n        }\n        stream._readable = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n        // The [[backpressure]] slot is set to undefined so that it can be initialised by TransformStreamSetBackpressure.\n        stream._backpressure = undefined;\n        stream._backpressureChangePromise = undefined;\n        stream._backpressureChangePromise_resolve = undefined;\n        TransformStreamSetBackpressure(stream, true);\n        stream._transformStreamController = undefined;\n    }\n    function IsTransformStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_transformStreamController')) {\n            return false;\n        }\n        return true;\n    }\n    // This is a no-op if both sides are already errored.\n    function TransformStreamError(stream, e) {\n        ReadableStreamDefaultControllerError(stream._readable._readableStreamController, e);\n        TransformStreamErrorWritableAndUnblockWrite(stream, e);\n    }\n    function TransformStreamErrorWritableAndUnblockWrite(stream, e) {\n        TransformStreamDefaultControllerClearAlgorithms(stream._transformStreamController);\n        WritableStreamDefaultControllerErrorIfNeeded(stream._writable._writableStreamController, e);\n        if (stream._backpressure) {\n            // Pretend that pull() was called to permit any pending write() calls to complete. TransformStreamSetBackpressure()\n            // cannot be called from enqueue() or pull() once the ReadableStream is errored, so this will will be the final time\n            // _backpressure is set.\n            TransformStreamSetBackpressure(stream, false);\n        }\n    }\n    function TransformStreamSetBackpressure(stream, backpressure) {\n        // Passes also when called during construction.\n        if (stream._backpressureChangePromise !== undefined) {\n            stream._backpressureChangePromise_resolve();\n        }\n        stream._backpressureChangePromise = newPromise(function (resolve) {\n            stream._backpressureChangePromise_resolve = resolve;\n        });\n        stream._backpressure = backpressure;\n    }\n    // Class TransformStreamDefaultController\n    /**\n     * Allows control of the {@link ReadableStream} and {@link WritableStream} of the associated {@link TransformStream}.\n     *\n     * @public\n     */\n    var TransformStreamDefaultController = /** @class */ (function () {\n        function TransformStreamDefaultController() {\n            throw new TypeError('Illegal constructor');\n        }\n        Object.defineProperty(TransformStreamDefaultController.prototype, \"desiredSize\", {\n            /**\n             * Returns the desired size to fill the readable side’s internal queue. It can be negative, if the queue is over-full.\n             */\n            get: function () {\n                if (!IsTransformStreamDefaultController(this)) {\n                    throw defaultControllerBrandCheckException('desiredSize');\n                }\n                var readableController = this._controlledTransformStream._readable._readableStreamController;\n                return ReadableStreamDefaultControllerGetDesiredSize(readableController);\n            },\n            enumerable: false,\n            configurable: true\n        });\n        TransformStreamDefaultController.prototype.enqueue = function (chunk) {\n            if (chunk === void 0) { chunk = undefined; }\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('enqueue');\n            }\n            TransformStreamDefaultControllerEnqueue(this, chunk);\n        };\n        /**\n         * Errors both the readable side and the writable side of the controlled transform stream, making all future\n         * interactions with it fail with the given error `e`. Any chunks queued for transformation will be discarded.\n         */\n        TransformStreamDefaultController.prototype.error = function (reason) {\n            if (reason === void 0) { reason = undefined; }\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('error');\n            }\n            TransformStreamDefaultControllerError(this, reason);\n        };\n        /**\n         * Closes the readable side and errors the writable side of the controlled transform stream. This is useful when the\n         * transformer only needs to consume a portion of the chunks written to the writable side.\n         */\n        TransformStreamDefaultController.prototype.terminate = function () {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('terminate');\n            }\n            TransformStreamDefaultControllerTerminate(this);\n        };\n        return TransformStreamDefaultController;\n    }());\n    Object.defineProperties(TransformStreamDefaultController.prototype, {\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        terminate: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Transform Stream Default Controller Abstract Operations\n    function IsTransformStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledTransformStream')) {\n            return false;\n        }\n        return true;\n    }\n    function SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm) {\n        controller._controlledTransformStream = stream;\n        stream._transformStreamController = controller;\n        controller._transformAlgorithm = transformAlgorithm;\n        controller._flushAlgorithm = flushAlgorithm;\n    }\n    function SetUpTransformStreamDefaultControllerFromTransformer(stream, transformer) {\n        var controller = Object.create(TransformStreamDefaultController.prototype);\n        var transformAlgorithm = function (chunk) {\n            try {\n                TransformStreamDefaultControllerEnqueue(controller, chunk);\n                return promiseResolvedWith(undefined);\n            }\n            catch (transformResultE) {\n                return promiseRejectedWith(transformResultE);\n            }\n        };\n        var flushAlgorithm = function () { return promiseResolvedWith(undefined); };\n        if (transformer.transform !== undefined) {\n            transformAlgorithm = function (chunk) { return transformer.transform(chunk, controller); };\n        }\n        if (transformer.flush !== undefined) {\n            flushAlgorithm = function () { return transformer.flush(controller); };\n        }\n        SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm);\n    }\n    function TransformStreamDefaultControllerClearAlgorithms(controller) {\n        controller._transformAlgorithm = undefined;\n        controller._flushAlgorithm = undefined;\n    }\n    function TransformStreamDefaultControllerEnqueue(controller, chunk) {\n        var stream = controller._controlledTransformStream;\n        var readableController = stream._readable._readableStreamController;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(readableController)) {\n            throw new TypeError('Readable side is not in a state that permits enqueue');\n        }\n        // We throttle transform invocations based on the backpressure of the ReadableStream, but we still\n        // accept TransformStreamDefaultControllerEnqueue() calls.\n        try {\n            ReadableStreamDefaultControllerEnqueue(readableController, chunk);\n        }\n        catch (e) {\n            // This happens when readableStrategy.size() throws.\n            TransformStreamErrorWritableAndUnblockWrite(stream, e);\n            throw stream._readable._storedError;\n        }\n        var backpressure = ReadableStreamDefaultControllerHasBackpressure(readableController);\n        if (backpressure !== stream._backpressure) {\n            TransformStreamSetBackpressure(stream, true);\n        }\n    }\n    function TransformStreamDefaultControllerError(controller, e) {\n        TransformStreamError(controller._controlledTransformStream, e);\n    }\n    function TransformStreamDefaultControllerPerformTransform(controller, chunk) {\n        var transformPromise = controller._transformAlgorithm(chunk);\n        return transformPromiseWith(transformPromise, undefined, function (r) {\n            TransformStreamError(controller._controlledTransformStream, r);\n            throw r;\n        });\n    }\n    function TransformStreamDefaultControllerTerminate(controller) {\n        var stream = controller._controlledTransformStream;\n        var readableController = stream._readable._readableStreamController;\n        ReadableStreamDefaultControllerClose(readableController);\n        var error = new TypeError('TransformStream terminated');\n        TransformStreamErrorWritableAndUnblockWrite(stream, error);\n    }\n    // TransformStreamDefaultSink Algorithms\n    function TransformStreamDefaultSinkWriteAlgorithm(stream, chunk) {\n        var controller = stream._transformStreamController;\n        if (stream._backpressure) {\n            var backpressureChangePromise = stream._backpressureChangePromise;\n            return transformPromiseWith(backpressureChangePromise, function () {\n                var writable = stream._writable;\n                var state = writable._state;\n                if (state === 'erroring') {\n                    throw writable._storedError;\n                }\n                return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n            });\n        }\n        return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n    }\n    function TransformStreamDefaultSinkAbortAlgorithm(stream, reason) {\n        // abort() is not called synchronously, so it is possible for abort() to be called when the stream is already\n        // errored.\n        TransformStreamError(stream, reason);\n        return promiseResolvedWith(undefined);\n    }\n    function TransformStreamDefaultSinkCloseAlgorithm(stream) {\n        // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n        var readable = stream._readable;\n        var controller = stream._transformStreamController;\n        var flushPromise = controller._flushAlgorithm();\n        TransformStreamDefaultControllerClearAlgorithms(controller);\n        // Return a promise that is fulfilled with undefined on success.\n        return transformPromiseWith(flushPromise, function () {\n            if (readable._state === 'errored') {\n                throw readable._storedError;\n            }\n            ReadableStreamDefaultControllerClose(readable._readableStreamController);\n        }, function (r) {\n            TransformStreamError(stream, r);\n            throw readable._storedError;\n        });\n    }\n    // TransformStreamDefaultSource Algorithms\n    function TransformStreamDefaultSourcePullAlgorithm(stream) {\n        // Invariant. Enforced by the promises returned by start() and pull().\n        TransformStreamSetBackpressure(stream, false);\n        // Prevent the next pull() call until there is backpressure.\n        return stream._backpressureChangePromise;\n    }\n    // Helper functions for the TransformStreamDefaultController.\n    function defaultControllerBrandCheckException(name) {\n        return new TypeError(\"TransformStreamDefaultController.prototype.\" + name + \" can only be used on a TransformStreamDefaultController\");\n    }\n    // Helper functions for the TransformStream.\n    function streamBrandCheckException(name) {\n        return new TypeError(\"TransformStream.prototype.\" + name + \" can only be used on a TransformStream\");\n    }\n\n    var exports$1 = {\n        ReadableStream: ReadableStream,\n        ReadableStreamDefaultController: ReadableStreamDefaultController,\n        ReadableByteStreamController: ReadableByteStreamController,\n        ReadableStreamBYOBRequest: ReadableStreamBYOBRequest,\n        ReadableStreamDefaultReader: ReadableStreamDefaultReader,\n        ReadableStreamBYOBReader: ReadableStreamBYOBReader,\n        WritableStream: WritableStream,\n        WritableStreamDefaultController: WritableStreamDefaultController,\n        WritableStreamDefaultWriter: WritableStreamDefaultWriter,\n        ByteLengthQueuingStrategy: ByteLengthQueuingStrategy,\n        CountQueuingStrategy: CountQueuingStrategy,\n        TransformStream: TransformStream,\n        TransformStreamDefaultController: TransformStreamDefaultController\n    };\n    // Add classes to global scope\n    if (typeof globals !== 'undefined') {\n        for (var prop in exports$1) {\n            if (Object.prototype.hasOwnProperty.call(exports$1, prop)) {\n                Object.defineProperty(globals, prop, {\n                    value: exports$1[prop],\n                    writable: true,\n                    configurable: true\n                });\n            }\n        }\n    }\n\n    exports.ByteLengthQueuingStrategy = ByteLengthQueuingStrategy;\n    exports.CountQueuingStrategy = CountQueuingStrategy;\n    exports.ReadableByteStreamController = ReadableByteStreamController;\n    exports.ReadableStream = ReadableStream;\n    exports.ReadableStreamBYOBReader = ReadableStreamBYOBReader;\n    exports.ReadableStreamBYOBRequest = ReadableStreamBYOBRequest;\n    exports.ReadableStreamDefaultController = ReadableStreamDefaultController;\n    exports.ReadableStreamDefaultReader = ReadableStreamDefaultReader;\n    exports.TransformStream = TransformStream;\n    exports.TransformStreamDefaultController = TransformStreamDefaultController;\n    exports.WritableStream = WritableStream;\n    exports.WritableStreamDefaultController = WritableStreamDefaultController;\n    exports.WritableStreamDefaultWriter = WritableStreamDefaultWriter;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n//# sourceMappingURL=polyfill.js.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar Path = require('path');\nvar fs = require('fs');\nvar glob = require('it-glob');\nvar errCode = require('err-code');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar Path__default = /*#__PURE__*/_interopDefaultLegacy(Path);\nvar fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);\nvar glob__default = /*#__PURE__*/_interopDefaultLegacy(glob);\nvar errCode__default = /*#__PURE__*/_interopDefaultLegacy(errCode);\n\nasync function getFilesFromPath(paths, options) {\n  const files = [];\n  for await (const file of filesFromPath(paths, options)) {\n    files.push(file);\n  }\n  return files;\n}\nasync function* filesFromPath(paths, options) {\n  options = options || {};\n  if (typeof paths === 'string') {\n    paths = [paths];\n  }\n  const globSourceOptions = {\n    recursive: true,\n    glob: {\n      dot: Boolean(options.hidden),\n      ignore: Array.isArray(options.ignore) ? options.ignore : [],\n      follow: options.followSymlinks != null ? options.followSymlinks : true\n    }\n  };\n  for await (const path of paths) {\n    if (typeof path !== 'string') {\n      throw errCode__default['default'](new Error('Path must be a string'), 'ERR_INVALID_PATH', { path });\n    }\n    const absolutePath = Path__default['default'].resolve(process.cwd(), path);\n    const stat = await fs.promises.stat(absolutePath);\n    const prefix = Path__default['default'].dirname(absolutePath);\n    let mode = options.mode;\n    if (options.preserveMode) {\n      mode = stat.mode;\n    }\n    let mtime = options.mtime;\n    if (options.preserveMtime) {\n      mtime = stat.mtime;\n    }\n    yield* toGlobSource({\n      path,\n      type: stat.isDirectory() ? 'dir' : 'file',\n      prefix,\n      mode,\n      mtime,\n      size: stat.size,\n      preserveMode: options.preserveMode,\n      preserveMtime: options.preserveMtime\n    }, globSourceOptions);\n  }\n}\nasync function* toGlobSource({path, type, prefix, mode, mtime, size, preserveMode, preserveMtime}, options) {\n  options = options || {};\n  const baseName = Path__default['default'].basename(path);\n  if (type === 'file') {\n    yield {\n      name: `/${ baseName.replace(prefix, '') }`,\n      stream: () => fs__default['default'].createReadStream(Path__default['default'].isAbsolute(path) ? path : Path__default['default'].join(process.cwd(), path)),\n      mode,\n      mtime,\n      size\n    };\n    return;\n  }\n  const globOptions = Object.assign({}, options.glob, {\n    cwd: path,\n    nodir: false,\n    realpath: false,\n    absolute: true\n  });\n  for await (const p of glob__default['default'](path, '**/*', globOptions)) {\n    const stat = await fs.promises.stat(p);\n    if (!stat.isFile()) {\n      continue;\n    }\n    if (preserveMode || preserveMtime) {\n      if (preserveMode) {\n        mode = stat.mode;\n      }\n      if (preserveMtime) {\n        mtime = stat.mtime;\n      }\n    }\n    yield {\n      name: toPosix(p.replace(prefix, '')),\n      stream: () => fs__default['default'].createReadStream(p),\n      mode,\n      mtime,\n      size: stat.size\n    };\n  }\n}\nconst toPosix = path => path.replace(/\\\\/g, '/');\n\nexports.filesFromPath = filesFromPath;\nexports.getFilesFromPath = getFilesFromPath;\n","const { getFilesFromPath } = require('files-from-path')\nconst { Web3Storage } = require('web3.storage')\n\nasync function addToWeb3 ({ endpoint, token, pathToAdd, name, wrapWithDirectory = false }) {\n  const web3 = new Web3Storage({ endpoint, token })\n  const files = await getFilesFromPath(`${pathToAdd}`)\n  const cid = await web3.put(files, { name, wrapWithDirectory })\n  const url = `https://dweb.link/ipfs/${cid}`\n  return { cid, url }\n}\n\nfunction pickName ({ repo, run, sha }) {\n  return `${repo.replace('/', '-')}-${run}-${sha.substring(0, 8)}`\n}\n\nmodule.exports.addToWeb3 = addToWeb3\nmodule.exports.pickName = pickName\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar _package = require('./package.cjs');\nvar webEncoding = require('web-encoding');\n\n/**\n * @implements {globalThis.Blob}\n */\nconst WebBlob = class Blob {\n  /**\n   * @param {BlobPart[]} [init]\n   * @param {BlobPropertyBag} [options]\n   */\n  constructor(init = [], options = {}) {\n    /** @type {Uint8Array[]} */\n    const parts = [];\n\n    let size = 0;\n    for (const part of init) {\n      if (typeof part === \"string\") {\n        const bytes = new webEncoding.TextEncoder().encode(part);\n        parts.push(bytes);\n        size += bytes.byteLength;\n      } else if (part instanceof WebBlob) {\n        size += part.size;\n        // @ts-ignore - `_parts` is marked private so TS will complain about\n        // accessing it.\n        parts.push(...part._parts);\n      } else if (part instanceof ArrayBuffer) {\n        parts.push(new Uint8Array(part));\n        size += part.byteLength;\n      } else if (part instanceof Uint8Array) {\n        parts.push(part);\n        size += part.byteLength;\n      } else if (ArrayBuffer.isView(part)) {\n        const { buffer, byteOffset, byteLength } = part;\n        parts.push(new Uint8Array(buffer, byteOffset, byteLength));\n        size += byteLength;\n      } else {\n        const bytes = new webEncoding.TextEncoder().encode(String(part));\n        parts.push(bytes);\n        size += bytes.byteLength;\n      }\n    }\n\n    /** @private */\n    this._size = size;\n    /** @private */\n    this._type = readType(options.type);\n    /** @private */\n    this._parts = parts;\n\n    Object.defineProperties(this, {\n      _size: { enumerable: false },\n      _type: { enumerable: false },\n      _parts: { enumerable: false }\n    });\n  }\n\n  /**\n   * A string indicating the MIME type of the data contained in the Blob.\n   * If the type is unknown, this string is empty.\n   * @type {string}\n   */\n  get type() {\n    return this._type\n  }\n  /**\n   * The size, in bytes, of the data contained in the Blob object.\n   * @type {number}\n   */\n  get size() {\n    return this._size\n  }\n\n  /**\n   * Returns a new Blob object containing the data in the specified range of\n   * bytes of the blob on which it's called.\n   * @param {number} [start=0] - An index into the Blob indicating the first\n   * byte to include in the new Blob. If you specify a negative value, it's\n   * treated as an offset from the end of the Blob toward the beginning. For\n   * example, `-10` would be the 10th from last byte in the Blob. The default\n   * value is `0`. If you specify a value for start that is larger than the\n   * size of the source Blob, the returned Blob has size 0 and contains no\n   * data.\n   * @param {number} [end] - An index into the `Blob` indicating the first byte\n   *  that will *not* be included in the new `Blob` (i.e. the byte exactly at\n   * this index is not included). If you specify a negative value, it's treated\n   * as an offset from the end of the Blob toward the beginning. For example,\n   * `-10` would be the 10th from last byte in the `Blob`. The default value is\n   * size.\n   * @param {string} [type] - The content type to assign to the new Blob;\n   * this will be the value of its type property. The default value is an empty\n   * string.\n   * @returns {Blob}\n   */\n  slice(start = 0, end = this.size, type = \"\") {\n    const { size, _parts } = this;\n    let offset = start < 0 ? Math.max(size + start, 0) : Math.min(start, size);\n\n    let limit = end < 0 ? Math.max(size + end, 0) : Math.min(end, size);\n    const span = Math.max(limit - offset, 0);\n    const blob = new Blob([], { type });\n\n    if (span === 0) {\n      return blob\n    }\n\n    let blobSize = 0;\n    const blobParts = [];\n    for (const part of _parts) {\n      const { byteLength } = part;\n      if (offset > 0 && byteLength <= offset) {\n        offset -= byteLength;\n        limit -= byteLength;\n      } else {\n        const chunk = part.subarray(offset, Math.min(byteLength, limit));\n        blobParts.push(chunk);\n        blobSize += chunk.byteLength;\n        // no longer need to take that into account\n        offset = 0;\n\n        // don't add the overflow to new blobParts\n        if (blobSize >= span) {\n          break\n        }\n      }\n    }\n\n    blob._parts = blobParts;\n    blob._size = blobSize;\n\n    return blob\n  }\n\n  /**\n   * Returns a promise that resolves with an ArrayBuffer containing the entire\n   * contents of the Blob as binary data.\n   * @returns {Promise<ArrayBuffer>}\n   */\n  // eslint-disable-next-line require-await\n  async arrayBuffer() {\n    const buffer = new ArrayBuffer(this.size);\n    const bytes = new Uint8Array(buffer);\n    let offset = 0;\n    for (const part of this._parts) {\n      bytes.set(part, offset);\n      offset += part.byteLength;\n    }\n    return buffer\n  }\n\n  /**\n   * Returns a promise that resolves with a USVString containing the entire\n   * contents of the Blob interpreted as UTF-8 text.\n   * @returns {Promise<string>}\n   */\n  // eslint-disable-next-line require-await\n  async text() {\n    const decoder = new webEncoding.TextDecoder();\n    let text = \"\";\n    for (const part of this._parts) {\n      text += decoder.decode(part);\n    }\n    return text\n  }\n\n  /**\n   * @returns {BlobStream}\n   */\n  stream() {\n    return new BlobStream(this._parts)\n  }\n\n  /**\n   * @returns {string}\n   */\n  toString() {\n    return \"[object Blob]\"\n  }\n\n  get [Symbol.toStringTag]() {\n    return \"Blob\"\n  }\n};\n\n// Marking export as a DOM File object instead of custom class.\n/** @type {typeof globalThis.Blob} */\nconst Blob = WebBlob;\n\n/**\n * Blob stream is a `ReadableStream` extension optimized to have minimal\n * overhead when consumed as `AsyncIterable<Uint8Array>`.\n * @extends {ReadableStream<Uint8Array>}\n * @implements {AsyncIterable<Uint8Array>}\n */\nclass BlobStream extends _package.ReadableStream {\n  /**\n   * @param {Uint8Array[]} chunks\n   */\n  constructor(chunks) {\n    // @ts-ignore\n    super(new BlobStreamController(chunks.values()), { type: \"bytes\" });\n    /** @private */\n    this._chunks = chunks;\n  }\n\n  /**\n   * @param {Object} [_options]\n   * @property {boolean} [_options.preventCancel]\n   * @returns {AsyncIterator<Uint8Array>}\n   */\n  async *[Symbol.asyncIterator](_options) {\n    const reader = this.getReader();\n    yield* this._chunks;\n    reader.releaseLock();\n  }\n}\n\nclass BlobStreamController {\n  /**\n   * @param {Iterator<Uint8Array>} chunks\n   */\n  constructor(chunks) {\n    this.chunks = chunks;\n  }\n\n  /**\n   * @param {ReadableStreamDefaultController} controller\n   */\n  start(controller) {\n    this.work(controller);\n    this.isWorking = false;\n    this.isCancelled = false;\n  }\n  /**\n   *\n   * @param {ReadableStreamDefaultController} controller\n   */\n  async work(controller) {\n    const { chunks } = this;\n\n    this.isWorking = true;\n    while (!this.isCancelled && (controller.desiredSize || 0) > 0) {\n      let next = null;\n      try {\n        next = chunks.next();\n      } catch (error) {\n        controller.error(error);\n        break\n      }\n\n      if (next) {\n        if (!next.done && !this.isCancelled) {\n          controller.enqueue(next.value);\n        } else {\n          controller.close();\n        }\n      }\n    }\n\n    this.isWorking = false;\n  }\n\n  /**\n   * @param {ReadableStreamDefaultController} controller\n   */\n  pull(controller) {\n    if (!this.isWorking) {\n      this.work(controller);\n    }\n  }\n  cancel() {\n    this.isCancelled = true;\n  }\n}\n\n/**\n * @param {string} [input]\n * @returns {string}\n */\nconst readType = (input = \"\") => {\n  const type = String(input).toLowerCase();\n  return /[^\\u0020-\\u007E]/.test(type) ? \"\" : type\n};\n\nexports.ReadableStream = _package.ReadableStream;\nObject.defineProperty(exports, 'TextDecoder', {\n  enumerable: true,\n  get: function () {\n    return webEncoding.TextDecoder;\n  }\n});\nObject.defineProperty(exports, 'TextEncoder', {\n  enumerable: true,\n  get: function () {\n    return webEncoding.TextEncoder;\n  }\n});\nexports.Blob = Blob;\n//# sourceMappingURL=lib.node.cjs.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar webEncoding = require('web-encoding');\nvar streams = require('web-streams-polyfill');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar streams__default = /*#__PURE__*/_interopDefaultLegacy(streams);\n\nconst { ReadableStream: ReadableStreamPolyfill } = streams__default['default'];\n/** @type {typeof globalThis.ReadableStream} */\n// @ts-ignore\nconst ReadableStream = ReadableStreamPolyfill;\n\nObject.defineProperty(exports, 'TextDecoder', {\n\tenumerable: true,\n\tget: function () {\n\t\treturn webEncoding.TextDecoder;\n\t}\n});\nObject.defineProperty(exports, 'TextEncoder', {\n\tenumerable: true,\n\tget: function () {\n\t\treturn webEncoding.TextEncoder;\n\t}\n});\nexports.ReadableStream = ReadableStream;\n//# sourceMappingURL=package.cjs.map\n","'use strict';\n\nexports = module.exports = fetch;\n\nconst http = require('http');\nconst https = require('https');\nconst zlib = require('zlib');\nconst dataUriToBuffer = require('data-uri-to-buffer');\nconst Stream = require('stream');\nconst util = require('util');\nconst blob = require('@web-std/blob');\nconst WebStreams = require('web-streams-polyfill');\nconst crypto = require('crypto');\nconst url = require('url');\n\nclass FetchBaseError extends Error {\n\tconstructor(message, type) {\n\t\tsuper(message);\n\t\t// Hide custom error implementation details from end-users\n\t\tError.captureStackTrace(this, this.constructor);\n\n\t\tthis.type = type;\n\t}\n\n\tget name() {\n\t\treturn this.constructor.name;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n}\n\n/**\n * @typedef {{ address?: string, code: string, dest?: string, errno: number, info?: object, message: string, path?: string, port?: number, syscall: string}} SystemError\n*/\n\n/**\n * FetchError interface for operational errors\n */\nclass FetchError extends FetchBaseError {\n\t/**\n\t * @param  {string} message -      Error message for human\n\t * @param  {string} [type] -        Error type for machine\n\t * @param  {SystemError} [systemError] - For Node.js system error\n\t */\n\tconstructor(message, type, systemError) {\n\t\tsuper(message, type);\n\t\t// When err.type is `system`, err.erroredSysCall contains system error and err.code contains system error code\n\t\tif (systemError) {\n\t\t\t// eslint-disable-next-line no-multi-assign\n\t\t\tthis.code = this.errno = systemError.code;\n\t\t\tthis.erroredSysCall = systemError.syscall;\n\t\t}\n\t}\n}\n\n/**\n * Is.js\n *\n * Object type checks.\n */\n\nconst NAME = Symbol.toStringTag;\n\n/**\n * Check if `obj` is a URLSearchParams object\n * ref: https://github.com/node-fetch/node-fetch/issues/296#issuecomment-307598143\n *\n * @param  {*} obj\n * @return {obj is URLSearchParams}\n */\nconst isURLSearchParameters = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.has === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.sort === 'function' &&\n\t\tobject[NAME] === 'URLSearchParams'\n\t);\n};\n\n/**\n * Check if `object` is a W3C `Blob` object (which `File` inherits from)\n *\n * @param  {*} object\n * @return {object is Blob}\n */\nconst isBlob = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.arrayBuffer === 'function' &&\n\t\ttypeof object.type === 'string' &&\n\t\ttypeof object.stream === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\t/^(Blob|File)$/.test(object[NAME])\n\t);\n};\n\n/**\n * Check if `obj` is a spec-compliant `FormData` object\n *\n * @param {*} object\n * @return {object is FormData}\n */\nfunction isFormData(object) {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.keys === 'function' &&\n\t\ttypeof object.values === 'function' &&\n\t\ttypeof object.entries === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\tobject[NAME] === 'FormData'\n\t);\n}\n\n/**\n * Detect form data input from form-data module\n *\n * @param {any} value\n * @returns {value is Stream & {getBoundary():string, hasKnownLength():boolean, getLengthSync():number|null}}\n */\nconst isMultipartFormDataStream = value => {\n\treturn (\n\t\tvalue instanceof Stream &&\n\t\ttypeof value.getBoundary === 'function' &&\n\t\ttypeof value.hasKnownLength === 'function' &&\n\t\ttypeof value.getLengthSync === 'function'\n\t);\n};\n\n/**\n * Check if `obj` is an instance of AbortSignal.\n *\n * @param  {*} obj\n * @return {obj is AbortSignal}\n */\nconst isAbortSignal = object => {\n\treturn (\n\t\ttypeof object === 'object' && (\n\t\t\tobject[NAME] === 'AbortSignal' ||\n\t\t\tobject[NAME] === 'EventTarget'\n\t\t)\n\t);\n};\n\n/**\n * Check if `value` is a ReadableStream.\n *\n * @param {*} value\n * @returns {value is ReadableStream}\n */\nconst isReadableStream = value => {\n\treturn (\n\t\ttypeof value === 'object' &&\n\t\ttypeof value.getReader === 'function' &&\n\t\ttypeof value.cancel === 'function' &&\n\t\ttypeof value.tee === 'function'\n\t);\n};\n\nconst carriage = '\\r\\n';\nconst dashes = '-'.repeat(2);\nconst carriageLength = Buffer.byteLength(carriage);\n\n/**\n * @param {string} boundary\n */\nconst getFooter = boundary => `${dashes}${boundary}${dashes}${carriage.repeat(2)}`;\n\n/**\n * @param {string} boundary\n * @param {string} name\n * @param {*} field\n *\n * @return {string}\n */\nfunction getHeader(boundary, name, field) {\n\tlet header = '';\n\n\theader += `${dashes}${boundary}${carriage}`;\n\theader += `Content-Disposition: form-data; name=\"${name}\"`;\n\n\tif (isBlob(field)) {\n\t\theader += `; filename=\"${field.name}\"${carriage}`;\n\t\theader += `Content-Type: ${field.type || 'application/octet-stream'}`;\n\t}\n\n\treturn `${header}${carriage.repeat(2)}`;\n}\n\n/**\n * @return {string}\n */\nconst getBoundary = () => crypto.randomBytes(8).toString('hex');\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nasync function * formDataIterator(form, boundary) {\n\tfor (const [name, value] of form) {\n\t\tyield getHeader(boundary, name, value);\n\n\t\tif (isBlob(value)) {\n\t\t\tyield * value.stream();\n\t\t} else {\n\t\t\tyield value;\n\t\t}\n\n\t\tyield carriage;\n\t}\n\n\tyield getFooter(boundary);\n}\n\n/**\n * @param {FormData} form\n * @param {string} boundary\n */\nfunction getFormDataLength(form, boundary) {\n\tlet length = 0;\n\n\tfor (const [name, value] of form) {\n\t\tlength += Buffer.byteLength(getHeader(boundary, name, value));\n\n\t\tif (isBlob(value)) {\n\t\t\tlength += value.size;\n\t\t} else {\n\t\t\tlength += Buffer.byteLength(String(value));\n\t\t}\n\n\t\tlength += carriageLength;\n\t}\n\n\tlength += Buffer.byteLength(getFooter(boundary));\n\n\treturn length;\n}\n\nconst encoder = new util.TextEncoder();\nconst decoder = new util.TextDecoder();\n\n/**\n * @param {string} text\n */\nconst encode = text => encoder.encode(text);\n\n/**\n * @param {Uint8Array} bytes\n */\nconst decode = bytes => decoder.decode(bytes);\n\n// @ts-check\n\nconst {readableHighWaterMark} = new Stream.Readable();\n\nconst {ReadableStream: ReadableStream$1} = WebStreams;\nconst INTERNALS$2 = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param {BodyInit}  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\n\nclass Body {\n\t/**\n\t * @param {BodyInit|Stream} body\n\t * @param {{size?:number}} options\n\t */\n\tconstructor(body, {\n\t\tsize = 0\n\t} = {}) {\n\t\tconst state = {\n\t\t\t/** @type {null|ReadableStream<Uint8Array>} */\n\t\t\tbody: null,\n\t\t\t/** @type {string|null} */\n\t\t\ttype: null,\n\t\t\t/** @type {number|null} */\n\t\t\tsize: null,\n\t\t\t/** @type {null|string} */\n\t\t\tboundary: null,\n\t\t\tdisturbed: false,\n\t\t\t/** @type {null|Error} */\n\t\t\terror: null\n\t\t};\n\t\tthis[INTERNALS$2] = state;\n\n\t\tif (body === null) {\n\t\t\t// Body is undefined or null\n\t\t\tstate.body = null;\n\t\t\tstate.size = 0;\n\t\t} else if (isURLSearchParameters(body)) {\n\t\t// Body is a URLSearchParams\n\t\t\tconst bytes = encode(body.toString());\n\t\t\tstate.body = fromBytes(bytes);\n\t\t\tstate.size = bytes.byteLength;\n\t\t\tstate.type = 'application/x-www-form-urlencoded;charset=UTF-8';\n\t\t} else if (isBlob(body)) {\n\t\t\t// Body is blob\n\t\t\tstate.size = body.size;\n\t\t\tstate.type = body.type || null;\n\t\t\tstate.body = body.stream();\n\t\t} else if (body instanceof Uint8Array) {\n\t\t\t// Body is Buffer\n\t\t\tstate.body = fromBytes(body);\n\t\t\tstate.size = body.byteLength;\n\t\t} else if (util.types.isAnyArrayBuffer(body)) {\n\t\t\t// Body is ArrayBuffer\n\t\t\tconst bytes = new Uint8Array(body);\n\t\t\tstate.body = fromBytes(bytes);\n\t\t\tstate.size = bytes.byteLength;\n\t\t} else if (ArrayBuffer.isView(body)) {\n\t\t\t// Body is ArrayBufferView\n\t\t\tconst bytes = new Uint8Array(body.buffer, body.byteOffset, body.byteLength);\n\t\t\tstate.body = fromBytes(bytes);\n\t\t\tstate.size = bytes.byteLength;\n\t\t} else if (isReadableStream(body)) {\n\t\t\t// Body is stream\n\t\t\tstate.body = body;\n\t\t} else if (isFormData(body)) {\n\t\t\t// Body is an instance of formdata-node\n\t\t\tconst boundary = `NodeFetchFormDataBoundary${getBoundary()}`;\n\t\t\tstate.type = `multipart/form-data; boundary=${boundary}`;\n\t\t\tstate.size = getFormDataLength(body, boundary);\n\t\t\tstate.body = fromAsyncIterable(formDataIterator(body, boundary));\n\t\t} else if (isMultipartFormDataStream(body)) {\n\t\t\tstate.type = `multipart/form-data; boundary=${body.getBoundary()}`;\n\t\t\tstate.size = body.hasKnownLength() ? body.getLengthSync() : null;\n\t\t\tstate.body = fromStream(body);\n\t\t} else if (body instanceof Stream) {\n\t\t\tstate.body = fromStream(body);\n\t\t} else {\n\t\t\t// None of the above\n\t\t\t// coerce to string then buffer\n\t\t\tconst bytes = encode(String(body));\n\t\t\tstate.type = 'text/plain;charset=UTF-8';\n\t\t\tstate.size = bytes.byteLength;\n\t\t\tstate.body = fromBytes(bytes);\n\t\t}\n\n\t\tthis.size = size;\n\n\t\t// if (body instanceof Stream) {\n\t\t// \tbody.on('error', err => {\n\t\t// \t\tconst error = err instanceof FetchBaseError ?\n\t\t// \t\t\terr :\n\t\t// \t\t\tnew FetchError(`Invalid response body while trying to fetch ${this.url}: ${err.message}`, 'system', err);\n\t\t// \t\tthis[INTERNALS].error = error;\n\t\t// \t});\n\t\t// }\n\t}\n\n\t/** @type {Headers|undefined} */\n\t/* c8 ignore next 3 */\n\tget headers() {\n\t\treturn null;\n\t}\n\n\tget body() {\n\t\treturn this[INTERNALS$2].body;\n\t}\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS$2].disturbed;\n\t}\n\n\t/**\n\t * Decode response as ArrayBuffer\n\t *\n\t * @return {Promise<ArrayBuffer>}\n\t */\n\tasync arrayBuffer() {\n\t\tconst {buffer, byteOffset, byteLength} = await consumeBody(this);\n\t\treturn buffer.slice(byteOffset, byteOffset + byteLength);\n\t}\n\n\t/**\n\t * Return raw response as Blob\n\t *\n\t * @return Promise\n\t */\n\tasync blob() {\n\t\tconst ct = (this.headers && this.headers.get('content-type')) || (this[INTERNALS$2].body && this[INTERNALS$2].type) || '';\n\t\tconst buf = await consumeBody(this);\n\n\t\treturn new blob.Blob([buf], {\n\t\t\ttype: ct\n\t\t});\n\t}\n\n\t/**\n\t * Decode response as json\n\t *\n\t * @return  Promise\n\t */\n\tasync json() {\n\t\treturn JSON.parse(await this.text());\n\t}\n\n\t/**\n\t * Decode response as text\n\t *\n\t * @return  Promise\n\t */\n\tasync text() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn decode(buffer);\n\t}\n}\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: {enumerable: true},\n\tbodyUsed: {enumerable: true},\n\tarrayBuffer: {enumerable: true},\n\tblob: {enumerable: true},\n\tjson: {enumerable: true},\n\ttext: {enumerable: true}\n});\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @param {Body & {url?:string}} data\n * @return {Promise<Uint8Array>}\n */\nasync function consumeBody(data) {\n\tconst state = data[INTERNALS$2];\n\tif (state.disturbed) {\n\t\tthrow new TypeError(`body used already for: ${data.url}`);\n\t}\n\n\tstate.disturbed = true;\n\n\tif (state.error) {\n\t\tthrow state.error;\n\t}\n\n\tconst {body} = state;\n\n\t// Body is null\n\tif (body === null) {\n\t\treturn new Uint8Array(0);\n\t}\n\n\t// Body is stream\n\t// get ready to actually consume the body\n\tconst [buffer, chunks, limit] = data.size > 0 ?\n\t\t[new Uint8Array(data.size), null, data.size] :\n\t\t[null, [], Infinity];\n\tlet offset = 0;\n\n\tconst source = streamIterator(body);\n\ttry {\n\t\tfor await (const chunk of source) {\n\t\t\tconst bytes = chunk instanceof Uint8Array ?\n\t\t\t\tchunk :\n\t\t\t\tBuffer.from(chunk);\n\n\t\t\tif (offset + bytes.byteLength > limit) {\n\t\t\t\tconst error = new FetchError(`content size at ${data.url} over limit: ${limit}`, 'max-size');\n\t\t\t\tsource.throw(error);\n\t\t\t\tthrow error;\n\t\t\t} else if (buffer) {\n\t\t\t\tbuffer.set(bytes, offset);\n\t\t\t} else {\n\t\t\t\tchunks.push(bytes);\n\t\t\t}\n\n\t\t\toffset += bytes.byteLength;\n\t\t}\n\n\t\tif (buffer) {\n\t\t\tif (offset < buffer.byteLength) {\n\t\t\t\tthrow new FetchError(`Premature close of server response while trying to fetch ${data.url}`);\n\t\t\t} else {\n\t\t\t\treturn buffer;\n\t\t\t}\n\t\t} else {\n\t\t\treturn writeBytes(new Uint8Array(offset), chunks);\n\t\t}\n\t} catch (error) {\n\t\tif (error instanceof FetchBaseError) {\n\t\t\tthrow error;\n\t\t} else if (error && error.name === 'AbortError') {\n\t\t\tthrow error;\n\t\t} else {\n\t\t\t// Other errors, such as incorrect content-encoding\n\t\t\tthrow new FetchError(`Invalid response body while trying to fetch ${data.url}: ${error.message}`, 'system', error);\n\t\t}\n\t}\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param {Body} instance       Response or Request instance\n * @return {ReadableStream<Uint8Array>}\n */\nconst clone = instance => {\n\tconst {body} = instance;\n\n\t// Don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\tconst [left, right] = body.tee();\n\tinstance[INTERNALS$2].body = left;\n\treturn right;\n};\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param {Body} source Any options.body input\n * @returns {string | null}\n */\nconst extractContentType = source => source[INTERNALS$2].type;\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param {Body} source - Body object from the Body instance.\n * @returns {number | null}\n */\nconst getTotalBytes = source => source[INTERNALS$2].size;\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param {Stream.Writable} dest - The stream to write to.\n * @param {Body} source - Body object from the Body instance.\n * @returns {void}\n */\nconst writeToStream = (dest, {body}) => {\n\tif (body === null) {\n\t\t// Body is null\n\t\tdest.end();\n\t} else {\n\t\tStream.Readable.from(streamIterator(body)).pipe(dest);\n\t}\n};\n\n/**\n * @template T\n * @implements {AsyncGenerator<T, void, void>}\n */\nclass StreamIterableIterator {\n\t/**\n\t * @param {ReadableStream<T>} stream\n\t */\n\tconstructor(stream) {\n\t\tthis.stream = stream;\n\t\tthis.reader = null;\n\t\tthis.state = null;\n\t}\n\n\t/**\n\t * @returns {AsyncGenerator<T, void, void>}\n\t */\n\t[Symbol.asyncIterator]() {\n\t\treturn this;\n\t}\n\n\tgetReader() {\n\t\tif (this.reader) {\n\t\t\treturn this.reader;\n\t\t}\n\n\t\tconst reader = this.stream.getReader();\n\t\tthis.reader = reader;\n\t\treturn reader;\n\t}\n\n\t/**\n\t * @returns {Promise<IteratorResult<T, void>>}\n\t */\n\tnext() {\n\t\treturn /** @type {Promise<IteratorResult<T, void>>} */ (this.getReader().read());\n\t}\n\n\tasync return() {\n\t\tif (this.reader) {\n\t\t\tawait this.reader.cancel();\n\t\t}\n\n\t\treturn {done: true, value: undefined};\n\t}\n\n\tasync throw(error) {\n\t\tawait this.getReader().cancel(error);\n\t\treturn {done: true, value: undefined};\n\t}\n}\n\n/**\n * @template T\n * @param {ReadableStream<T>} stream\n */\nconst streamIterator = stream => new StreamIterableIterator(stream);\n\n/**\n * @param {Uint8Array} buffer\n * @param {Uint8Array[]} chunks\n */\nconst writeBytes = (buffer, chunks) => {\n\tlet offset = 0;\n\tfor (const chunk of chunks) {\n\t\tbuffer.set(chunk, offset);\n\t\toffset += chunk.byteLength;\n\t}\n\n\treturn buffer;\n};\n\n/**\n * @param {Uint8Array} bytes\n * @returns {ReadableStream<Uint8Array>}\n */\n// @ts-ignore\nconst fromBytes = bytes => new ReadableStream$1({\n\tstart(controller) {\n\t\tcontroller.enqueue(bytes);\n\t\tcontroller.close();\n\t}\n});\n\n/**\n * @param {AsyncIterable<Uint8Array>} content\n * @returns {ReadableStream<Uint8Array>}\n */\nconst fromAsyncIterable = content =>\n\t// @ts-ignore\n\tnew ReadableStream$1(new AsyncIterablePump(content));\n\n/**\n * @implements {UnderlyingSource<Uint8Array>}\n */\nclass AsyncIterablePump {\n\t/**\n\t * @param {AsyncIterable<Uint8Array>} source\n\t */\n\tconstructor(source) {\n\t\tthis.source = source[Symbol.asyncIterator]();\n\t}\n\n\t/**\n\t * @param {ReadableStreamController<Uint8Array>} controller\n\t */\n\tasync pull(controller) {\n\t\ttry {\n\t\t\twhile (controller.desiredSize > 0) {\n\t\t\t\t// eslint-disable-next-line no-await-in-loop\n\t\t\t\tconst next = await this.source.next();\n\t\t\t\tif (next.done) {\n\t\t\t\t\tcontroller.close();\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\tcontroller.enqueue(next.value);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tcontroller.error(error);\n\t\t}\n\t}\n\n\tcancel(reason) {\n\t\tif (reason) {\n\t\t\tif (typeof this.source.throw === 'function') {\n\t\t\t\tthis.source.throw(reason);\n\t\t\t} else if (typeof this.source.return === 'function') {\n\t\t\t\tthis.source.return();\n\t\t\t}\n\t\t} else if (typeof this.source.return === 'function') {\n\t\t\tthis.source.return();\n\t\t}\n\t}\n}\n\n/**\n * @param {Stream & {readableHighWaterMark?:number}} source\n * @returns {ReadableStream<Uint8Array>}\n */\nconst fromStream = source => {\n\tconst pump = new StreamPump(source);\n\tconst stream =\n\t\t/** @type {ReadableStream<Uint8Array>} */(new ReadableStream$1(pump, pump));\n\treturn stream;\n};\n\n/**\n * @implements {WebStreams.UnderlyingSource<Uint8Array>}\n */\nclass StreamPump {\n\t/**\n\t * @param {Stream & {\n\t * \treadableHighWaterMark?: number\n\t * \treadable?:boolean,\n\t * \tresume?: () => void,\n\t * \tpause?: () => void\n\t * \tdestroy?: (error?:Error) => void\n\t * }} stream\n\t */\n\tconstructor(stream) {\n\t\tthis.highWaterMark = stream.readableHighWaterMark || readableHighWaterMark;\n\t\tthis.accumalatedSize = 0;\n\t\tthis.stream = stream;\n\t\tthis.enqueue = this.enqueue.bind(this);\n\t\tthis.error = this.error.bind(this);\n\t\tthis.close = this.close.bind(this);\n\t}\n\n\tsize(chunk) {\n\t\treturn chunk.byteLength;\n\t}\n\n\t/**\n\t * @param {ReadableStreamController<Uint8Array>} controller\n\t */\n\tstart(controller) {\n\t\tthis.controller = controller;\n\t\tthis.stream.on('data', this.enqueue);\n\t\tthis.stream.once('error', this.error);\n\t\tthis.stream.once('end', this.close);\n\t\tthis.stream.once('close', this.close);\n\t}\n\n\tpull() {\n\t\tthis.resume();\n\t}\n\n\tcancel(reason) {\n\t\tif (this.stream.destroy) {\n\t\t\tthis.stream.destroy(reason);\n\t\t}\n\n\t\tthis.stream.off('data', this.enqueue);\n\t\tthis.stream.off('error', this.error);\n\t\tthis.stream.off('end', this.close);\n\t\tthis.stream.off('close', this.close);\n\t}\n\n\t/**\n\t * @param {Uint8Array|string} chunk\n\t */\n\tenqueue(chunk) {\n\t\tif (this.controller) {\n\t\t\ttry {\n\t\t\t\tconst bytes = chunk instanceof Uint8Array ?\n\t\t\t\t\tchunk :\n\t\t\t\t\tBuffer.from(chunk);\n\n\t\t\t\tconst available = this.controller.desiredSize - bytes.byteLength;\n\t\t\t\tthis.controller.enqueue(bytes);\n\t\t\t\tif (available <= 0) {\n\t\t\t\t\tthis.pause();\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tthis.controller.error(new Error('Could not create Buffer, chunk must be of type string or an instance of Buffer, ArrayBuffer, or Array or an Array-like Object'));\n\t\t\t\tthis.cancel();\n\t\t\t}\n\t\t}\n\t}\n\n\tpause() {\n\t\tif (this.stream.pause) {\n\t\t\tthis.stream.pause();\n\t\t}\n\t}\n\n\tresume() {\n\t\tif (this.stream.readable && this.stream.resume) {\n\t\t\tthis.stream.resume();\n\t\t}\n\t}\n\n\tclose() {\n\t\tif (this.controller) {\n\t\t\tthis.controller.close();\n\t\t\tdelete this.controller;\n\t\t}\n\t}\n\n\terror(error) {\n\t\tif (this.controller) {\n\t\t\tthis.controller.error(error);\n\t\t\tdelete this.controller;\n\t\t}\n\t}\n}\n\n/**\n * Headers.js\n *\n * Headers class offers convenient helpers\n */\n\nconst validateHeaderName = typeof http.validateHeaderName === 'function' ?\n\thttp.validateHeaderName :\n\tname => {\n\t\tif (!/^[\\^`\\-\\w!#$%&'*+.|~]+$/.test(name)) {\n\t\t\tconst err = new TypeError(`Header name must be a valid HTTP token [${name}]`);\n\t\t\tObject.defineProperty(err, 'code', {value: 'ERR_INVALID_HTTP_TOKEN'});\n\t\t\tthrow err;\n\t\t}\n\t};\n\nconst validateHeaderValue = typeof http.validateHeaderValue === 'function' ?\n\thttp.validateHeaderValue :\n\t(name, value) => {\n\t\tif (/[^\\t\\u0020-\\u007E\\u0080-\\u00FF]/.test(value)) {\n\t\t\tconst err = new TypeError(`Invalid character in header content [\"${name}\"]`);\n\t\t\tObject.defineProperty(err, 'code', {value: 'ERR_INVALID_CHAR'});\n\t\t\tthrow err;\n\t\t}\n\t};\n\n/**\n * @typedef {Headers | Record<string, string> | Iterable<readonly [string, string]> | Iterable<Iterable<string>>} HeadersInit\n */\n\n/**\n * This Fetch API interface allows you to perform various actions on HTTP request and response headers.\n * These actions include retrieving, setting, adding to, and removing.\n * A Headers object has an associated header list, which is initially empty and consists of zero or more name and value pairs.\n * You can add to this using methods like append() (see Examples.)\n * In all methods of this interface, header names are matched by case-insensitive byte sequence.\n *\n */\nclass Headers extends URLSearchParams {\n\t/**\n\t * Headers class\n\t *\n\t * @constructor\n\t * @param {HeadersInit} [init] - Response headers\n\t */\n\tconstructor(init) {\n\t\t// Validate and normalize init object in [name, value(s)][]\n\t\t/** @type {string[][]} */\n\t\tlet result = [];\n\t\tif (init instanceof Headers) {\n\t\t\tconst raw = init.raw();\n\t\t\tfor (const [name, values] of Object.entries(raw)) {\n\t\t\t\tresult.push(...values.map(value => [name, value]));\n\t\t\t}\n\t\t} else if (init == null) ; else if (typeof init === 'object' && !util.types.isBoxedPrimitive(init)) {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\t\tif (method == null) {\n\t\t\t\t// Record<ByteString, ByteString>\n\t\t\t\tresult.push(...Object.entries(init));\n\t\t\t} else {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// Sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tresult = [...init]\n\t\t\t\t\t.map(pair => {\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof pair !== 'object' || util.types.isBoxedPrimitive(pair)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be an iterable object');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t}).map(pair => {\n\t\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Failed to construct \\'Headers\\': The provided value is not of type \\'(sequence<sequence<ByteString>> or record<ByteString, ByteString>)');\n\t\t}\n\n\t\t// Validate and lowercase\n\t\tresult =\n\t\t\tresult.length > 0 ?\n\t\t\t\tresult.map(([name, value]) => {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn [String(name).toLowerCase(), String(value)];\n\t\t\t\t}) :\n\t\t\t\tundefined;\n\n\t\tsuper(result);\n\n\t\t// Returning a Proxy that will lowercase key names, validate parameters and sort keys\n\t\t// eslint-disable-next-line no-constructor-return\n\t\treturn new Proxy(this, {\n\t\t\tget(target, p, receiver) {\n\t\t\t\tswitch (p) {\n\t\t\t\t\tcase 'append':\n\t\t\t\t\tcase 'set':\n\t\t\t\t\t\treturn (name, value) => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\treceiver,\n\t\t\t\t\t\t\t\tString(name).toLowerCase(),\n\t\t\t\t\t\t\t\tString(value)\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'delete':\n\t\t\t\t\tcase 'has':\n\t\t\t\t\tcase 'getAll':\n\t\t\t\t\t\treturn name => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\treceiver,\n\t\t\t\t\t\t\t\tString(name).toLowerCase()\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'keys':\n\t\t\t\t\t\treturn () => {\n\t\t\t\t\t\t\ttarget.sort();\n\t\t\t\t\t\t\treturn new Set(URLSearchParams.prototype.keys.call(target)).keys();\n\t\t\t\t\t\t};\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn Reflect.get(target, p, receiver);\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* c8 ignore next */\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n\n\ttoString() {\n\t\treturn Object.prototype.toString.call(this);\n\t}\n\n\tget(name) {\n\t\tconst values = this.getAll(name);\n\t\tif (values.length === 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet value = values.join(', ');\n\t\tif (/^content-encoding$/i.test(name)) {\n\t\t\tvalue = value.toLowerCase();\n\t\t}\n\n\t\treturn value;\n\t}\n\n\tforEach(callback, thisArg = undefined) {\n\t\tfor (const name of this.keys()) {\n\t\t\tReflect.apply(callback, thisArg, [this.get(name), name, this]);\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield this.get(name);\n\t\t}\n\t}\n\n\t/**\n\t * @type {() => IterableIterator<[string, string]>}\n\t */\n\t* entries() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield [name, this.get(name)];\n\t\t}\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.entries();\n\t}\n\n\t/**\n\t * Node-fetch non-spec method\n\t * returning all headers and their values as array\n\t * @returns {Record<string, string[]>}\n\t */\n\traw() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tresult[key] = this.getAll(key);\n\t\t\treturn result;\n\t\t}, {});\n\t}\n\n\t/**\n\t * For better console.log(headers) and also to convert Headers into Node.js Request compatible format\n\t */\n\t[Symbol.for('nodejs.util.inspect.custom')]() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tconst values = this.getAll(key);\n\t\t\t// Http.request() only supports string as Host header.\n\t\t\t// This hack makes specifying custom Host header possible.\n\t\t\tif (key === 'host') {\n\t\t\t\tresult[key] = values[0];\n\t\t\t} else {\n\t\t\t\tresult[key] = values.length > 1 ? values : values[0];\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}, {});\n\t}\n}\n\n/**\n * Re-shaping object for Web IDL tests\n * Only need to do it for overridden methods\n */\nObject.defineProperties(\n\tHeaders.prototype,\n\t['get', 'entries', 'forEach', 'values'].reduce((result, property) => {\n\t\tresult[property] = {enumerable: true};\n\t\treturn result;\n\t}, {})\n);\n\n/**\n * Create a Headers object from an http.IncomingMessage.rawHeaders, ignoring those that do\n * not conform to HTTP grammar productions.\n * @param {import('http').IncomingMessage['rawHeaders']} headers\n */\nfunction fromRawHeaders(headers = []) {\n\treturn new Headers(\n\t\theaders\n\t\t\t// Split into pairs\n\t\t\t.reduce((result, value, index, array) => {\n\t\t\t\tif (index % 2 === 0) {\n\t\t\t\t\tresult.push(array.slice(index, index + 2));\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}, [])\n\t\t\t.filter(([name, value]) => {\n\t\t\t\ttry {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn true;\n\t\t\t\t} catch {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t})\n\n\t);\n}\n\nconst redirectStatus = new Set([301, 302, 303, 307, 308]);\n\n/**\n * Redirect code matching\n *\n * @param {number} code - Status code\n * @return {boolean}\n */\nconst isRedirect = code => {\n\treturn redirectStatus.has(code);\n};\n\n/**\n * Response.js\n *\n * Response class provides content decoding\n */\n\nconst INTERNALS$1 = Symbol('Response internals');\n\n/**\n * Response class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nclass Response extends Body {\n\tconstructor(body = null, options = {}) {\n\t\tsuper(body, options);\n\n\t\tconst status = options.status || 200;\n\t\tconst headers = new Headers(options.headers);\n\n\t\tif (body !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS$1] = {\n\t\t\turl: options.url,\n\t\t\tstatus,\n\t\t\tstatusText: options.statusText || '',\n\t\t\theaders,\n\t\t\tcounter: options.counter,\n\t\t\thighWaterMark: options.highWaterMark\n\t\t};\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS$1].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS$1].status;\n\t}\n\n\t/**\n\t * Convenience property representing if the request ended normally\n\t */\n\tget ok() {\n\t\treturn this[INTERNALS$1].status >= 200 && this[INTERNALS$1].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS$1].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS$1].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$1].headers;\n\t}\n\n\tget highWaterMark() {\n\t\treturn this[INTERNALS$1].highWaterMark;\n\t}\n\n\t/**\n\t * Clone this response\n\t *\n\t * @return  Response\n\t */\n\tclone() {\n\t\treturn new Response(clone(this, this.highWaterMark), {\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected,\n\t\t\tsize: this.size\n\t\t});\n\t}\n\n\t/**\n\t * @param {string} url    The URL that the new response is to originate from.\n\t * @param {number} status An optional status code for the response (e.g., 302.)\n\t * @returns {Response}    A Response object.\n\t */\n\tstatic redirect(url, status = 302) {\n\t\tif (!isRedirect(status)) {\n\t\t\tthrow new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code');\n\t\t}\n\n\t\treturn new Response(null, {\n\t\t\theaders: {\n\t\t\t\tlocation: new URL(url).toString()\n\t\t\t},\n\t\t\tstatus\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Response';\n\t}\n}\n\nObject.defineProperties(Response.prototype, {\n\turl: {enumerable: true},\n\tstatus: {enumerable: true},\n\tok: {enumerable: true},\n\tredirected: {enumerable: true},\n\tstatusText: {enumerable: true},\n\theaders: {enumerable: true},\n\tclone: {enumerable: true}\n});\n\nconst getSearch = parsedURL => {\n\tif (parsedURL.search) {\n\t\treturn parsedURL.search;\n\t}\n\n\tconst lastOffset = parsedURL.href.length - 1;\n\tconst hash = parsedURL.hash || (parsedURL.href[lastOffset] === '#' ? '#' : '');\n\treturn parsedURL.href[lastOffset - hash.length] === '?' ? '?' : '';\n};\n\nconst INTERNALS = Symbol('Request internals');\n\n/**\n * Check if `obj` is an instance of Request.\n *\n * @param  {any} object\n * @return {object is Request}\n */\nconst isRequest = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object[INTERNALS] === 'object'\n\t);\n};\n\n/**\n * Request class\n */\nclass Request extends Body {\n\t/**\n\t * @param {string|Request input  Url or Request instance\n\t * @param {RequestInit} init   Custom options\n\t */\n\tconstructor(input, init = {}) {\n\t\tlet parsedURL;\n\n\t\t// Normalize input and force URL to be encoded as UTF-8 (https://github.com/node-fetch/node-fetch/issues/245)\n\t\tif (isRequest(input)) {\n\t\t\tparsedURL = new URL(input.url);\n\t\t} else {\n\t\t\tparsedURL = new URL(input);\n\t\t\tinput = {};\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (((init.body != null || isRequest(input)) && input.body !== null) &&\n\t\t\t(method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tconst inputBody = init.body ?\n\t\t\tinit.body :\n\t\t\t(isRequest(input) && input.body !== null ?\n\t\t\t\tclone(input) :\n\t\t\t\tnull);\n\n\t\tsuper(inputBody, {\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (inputBody !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = extractContentType(this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ?\n\t\t\tinput.signal :\n\t\t\tnull;\n\t\tif ('signal' in init) {\n\t\t\tsignal = init.signal;\n\t\t}\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (signal != null && !isAbortSignal(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal or EventTarget');\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal\n\t\t};\n\n\t\t// Node-fetch-only options\n\t\tthis.follow = init.follow === undefined ? (input.follow === undefined ? 20 : input.follow) : init.follow;\n\t\tthis.compress = init.compress === undefined ? (input.compress === undefined ? true : input.compress) : init.compress;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t\tthis.highWaterMark = init.highWaterMark || input.highWaterMark || 16384;\n\t\tthis.insecureHTTPParser = init.insecureHTTPParser || input.insecureHTTPParser || false;\n\t}\n\n\tget method() {\n\t\treturn this[INTERNALS].method;\n\t}\n\n\t/**\n\t * @type {URL}\n\t */\n\tget url() {\n\t\treturn url.format(this[INTERNALS].parsedURL);\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS].redirect;\n\t}\n\n\tget signal() {\n\t\treturn this[INTERNALS].signal;\n\t}\n\n\t/**\n\t * Clone this request\n\t *\n\t * @return  Request\n\t */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Request';\n\t}\n}\n\nObject.defineProperties(Request.prototype, {\n\tmethod: {enumerable: true},\n\turl: {enumerable: true},\n\theaders: {enumerable: true},\n\tredirect: {enumerable: true},\n\tclone: {enumerable: true},\n\tsignal: {enumerable: true}\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param   Request  A Request instance\n * @return  Object   The options object to be passed to http.request\n */\nconst getNodeRequestOptions = request => {\n\tconst {parsedURL} = request[INTERNALS];\n\tconst headers = new Headers(request[INTERNALS].headers);\n\n\t// Fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body === null && /^(post|put)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\n\tif (request.body !== null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\t// Set Content-Length if totalBytes is a number (that is not NaN)\n\t\tif (typeof totalBytes === 'number' && !Number.isNaN(totalBytes)) {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate,br');\n\t}\n\n\tlet {agent} = request;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\tconst search = getSearch(parsedURL);\n\n\t// Manually spread the URL object instead of spread syntax\n\tconst requestOptions = {\n\t\tpath: parsedURL.pathname + search,\n\t\tpathname: parsedURL.pathname,\n\t\thostname: parsedURL.hostname,\n\t\tprotocol: parsedURL.protocol,\n\t\tport: parsedURL.port,\n\t\thash: parsedURL.hash,\n\t\tsearch: parsedURL.search,\n\t\tquery: parsedURL.query,\n\t\thref: parsedURL.href,\n\t\tmethod: request.method,\n\t\theaders: headers[Symbol.for('nodejs.util.inspect.custom')](),\n\t\tinsecureHTTPParser: request.insecureHTTPParser,\n\t\tagent\n\t};\n\n\treturn requestOptions;\n};\n\n/**\n * AbortError interface for cancelled requests\n */\nclass AbortError extends FetchBaseError {\n\tconstructor(message, type = 'aborted') {\n\t\tsuper(message, type);\n\t}\n}\n\n/**\n * Index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nconst {ReadableStream} = WebStreams;\n\nconst supportedSchemas = new Set(['data:', 'http:', 'https:']);\n\n/**\n * Fetch function\n *\n * @param   {string | URL | import('./request').default} url - Absolute url or Request instance\n * @param   {RequestInit} [options_] - Fetch options\n * @return  {Promise<import('./response').default>}\n */\nasync function fetch(url, options_ = {}) {\n\treturn new Promise((resolve, reject) => {\n\t\t// Build request object\n\t\tconst request = new Request(url, options_);\n\t\tconst options = getNodeRequestOptions(request);\n\t\tif (!supportedSchemas.has(options.protocol)) {\n\t\t\tthrow new TypeError(`node-fetch cannot load ${url}. URL scheme \"${options.protocol.replace(/:$/, '')}\" is not supported.`);\n\t\t}\n\n\t\tif (options.protocol === 'data:') {\n\t\t\tconst data = dataUriToBuffer(request.url);\n\t\t\tconst response = new Response(data, {headers: {'Content-Type': data.typeFull}});\n\t\t\tresolve(response);\n\t\t\treturn;\n\t\t}\n\n\t\t// Wrap http.request into fetch\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\t\tconst {signal} = request;\n\t\tlet response = null;\n\t\tlet response_ = null;\n\n\t\tconst abort = () => {\n\t\t\tconst error = new AbortError('The operation was aborted.');\n\t\t\treject(error);\n\t\t\tif (request.body) {\n\t\t\t\trequest.body.cancel(error);\n\t\t\t}\n\n\t\t\tif (!response_) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresponse_.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = () => {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// Send request\n\t\tconst request_ = send(options);\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tconst finalize = () => {\n\t\t\trequest_.abort();\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t}\n\t\t};\n\n\t\trequest_.on('error', err => {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\n\t\t\tfinalize();\n\t\t});\n\n\t\tfixResponseChunkedTransferBadEnding(request_, err => {\n\t\t\tresponse_.emit('error', err);\n\t\t});\n\n\t\t/* c8 ignore next 18 */\n\t\tif (process.version < 'v14') {\n\t\t\t// Before Node.js 14, pipeline() does not fully support async iterators and does not always\n\t\t\t// properly handle when the socket close/end events are out of order.\n\t\t\trequest_.on('socket', s => {\n\t\t\t\tlet endedWithEventsCount;\n\t\t\t\ts.prependListener('end', () => {\n\t\t\t\t\tendedWithEventsCount = s._eventsCount;\n\t\t\t\t});\n\t\t\t\ts.prependListener('close', hadError => {\n\t\t\t\t\t// if end happened before close but the socket didn't emit an error, do it now\n\t\t\t\t\tif (response && endedWithEventsCount < s._eventsCount && !hadError) {\n\t\t\t\t\t\tconst err = new Error('Premature close');\n\t\t\t\t\t\terr.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\t\t\tresponse_.emit('error', err);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\n\t\trequest_.on('response', incoming => {\n\t\t\tresponse_ = incoming;\n\t\t\trequest_.setTimeout(0);\n\t\t\tconst headers = fromRawHeaders(response_.rawHeaders);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (isRedirect(response_.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : new URL(location, request.url);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// Node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\theaders.set('Location', locationURL);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow': {\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOptions = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\t// Note: We can not use `request.body` because send would have\n\t\t\t\t\t\t\t// consumed it already.\n\t\t\t\t\t\t\tbody: options_.body,\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\tsize: request.size\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tconst isStreamBody =\n\t\t\t\t\t\t\trequestOptions.body instanceof ReadableStream ||\n\t\t\t\t\t\t\trequestOptions.body instanceof Stream.Readable;\n\t\t\t\t\t\tif (response_.statusCode !== 303 && isStreamBody) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (response_.statusCode === 303 || ((response_.statusCode === 301 || response_.statusCode === 302) && request.method === 'POST')) {\n\t\t\t\t\t\t\trequestOptions.method = 'GET';\n\t\t\t\t\t\t\trequestOptions.body = undefined;\n\t\t\t\t\t\t\trequestOptions.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOptions)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn reject(new TypeError(`Redirect option '${request.redirect}' is not a valid value of RequestRedirect`));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Prepare response\n\t\t\tif (signal) {\n\t\t\t\tresponse_.once('end', () => {\n\t\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tlet body = Stream.pipeline(response_, new Stream.PassThrough(), reject);\n\t\t\t// see https://github.com/nodejs/node/pull/29376\n\t\t\t/* c8 ignore next 3 */\n\t\t\tif (process.version < 'v12.10') {\n\t\t\t\tresponse_.on('aborted', abortAndFinalize);\n\t\t\t}\n\n\t\t\tconst responseOptions = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: response_.statusCode,\n\t\t\t\tstatusText: response_.statusMessage,\n\t\t\t\theaders,\n\t\t\t\tsize: request.size,\n\t\t\t\tcounter: request.counter,\n\t\t\t\thighWaterMark: request.highWaterMark\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || response_.statusCode === 204 || response_.statusCode === 304) {\n\t\t\t\tresponse = new Response(body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// For gzip\n\t\t\tif (codings === 'gzip' || codings === 'x-gzip') {\n\t\t\t\tbody = Stream.pipeline(body, zlib.createGunzip(zlibOptions), reject);\n\t\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For deflate\n\t\t\tif (codings === 'deflate' || codings === 'x-deflate') {\n\t\t\t\t// Handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = Stream.pipeline(response_, new Stream.PassThrough(), reject);\n\t\t\t\traw.once('data', chunk => {\n\t\t\t\t\t// See http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = Stream.pipeline(body, zlib.createInflate(), reject);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = Stream.pipeline(body, zlib.createInflateRaw(), reject);\n\t\t\t\t\t}\n\n\t\t\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For br\n\t\t\tif (codings === 'br') {\n\t\t\t\tbody = Stream.pipeline(body, zlib.createBrotliDecompress(), reject);\n\t\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, use response as-is\n\t\t\tresponse = new Response(fromAsyncIterable(body), responseOptions);\n\t\t\tresolve(response);\n\t\t});\n\n\t\twriteToStream(request_, request);\n\t});\n}\n\nfunction fixResponseChunkedTransferBadEnding(request, errorCallback) {\n\tconst LAST_CHUNK = Buffer.from('0\\r\\n');\n\tlet socket;\n\n\trequest.on('socket', s => {\n\t\tsocket = s;\n\t});\n\n\trequest.on('response', response => {\n\t\tconst {headers} = response;\n\t\tif (headers['transfer-encoding'] === 'chunked' && !headers['content-length']) {\n\t\t\tlet properLastChunkReceived = false;\n\n\t\t\tsocket.on('data', buf => {\n\t\t\t\tproperLastChunkReceived = Buffer.compare(buf.slice(-3), LAST_CHUNK) === 0;\n\t\t\t});\n\n\t\t\tsocket.prependListener('close', () => {\n\t\t\t\tif (!properLastChunkReceived) {\n\t\t\t\t\tconst err = new Error('Premature close');\n\t\t\t\t\terr.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\t\terrorCallback(err);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}\n\nObject.defineProperty(exports, 'Blob', {\n\tenumerable: true,\n\tget: function () {\n\t\treturn blob.Blob;\n\t}\n});\nexports.AbortError = AbortError;\nexports.FetchError = FetchError;\nexports.Headers = Headers;\nexports.ReadableStream = ReadableStream;\nexports.Request = Request;\nexports.Response = Response;\nexports.default = fetch;\nexports.isRedirect = isRedirect;\n//# sourceMappingURL=index.cjs.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar blob = require('@web-std/blob');\n\n// @ts-check\n\n/**\n * @implements {globalThis.File}\n */\nconst WebFile = class File extends blob.Blob {\n  /**\n   *\n   * @param {BlobPart[]} init\n   * @param {string} name - A USVString representing the file name or the path\n   * to the file.\n   * @param {FilePropertyBag} [options]\n   */\n  constructor(\n    init,\n    name = panic(new TypeError(\"File constructor requires name argument\")),\n    options = {}\n  ) {\n    super(init, options);\n    // Per File API spec https://w3c.github.io/FileAPI/#file-constructor\n    // Every \"/\" character of file name must be replaced with a \":\".\n    /** @private */\n    this._name = name;\n    // It appears that browser do not follow the spec here.\n    // String(name).replace(/\\//g, \":\")\n    /** @private */\n    this._lastModified = options.lastModified || Date.now();\n  }\n\n  /**\n   * The name of the file referenced by the File object.\n   * @type {string}\n   */\n  get name() {\n    return this._name\n  }\n\n  /**\n   * The path the URL of the File is relative to.\n   * @type {string}\n   */\n  get webkitRelativePath() {\n    return \"\"\n  }\n\n  /**\n   * Returns the last modified time of the file, in millisecond since the UNIX\n   * epoch (January 1st, 1970 at Midnight).\n   * @returns {number}\n   */\n  get lastModified() {\n    return this._lastModified\n  }\n\n  get [Symbol.toStringTag]() {\n    return \"File\"\n  }\n};\n\n/**\n * @param {*} error\n * @returns {never}\n */\nconst panic = error => {\n  throw error\n};\n\n// Marking export as a DOM File object instead of custom class.\n/** @type {typeof globalThis.File} */\nconst File = WebFile;\n\nObject.defineProperty(exports, 'Blob', {\n  enumerable: true,\n  get: function () {\n    return blob.Blob;\n  }\n});\nexports.File = File;\n//# sourceMappingURL=lib.node.cjs.map\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar streamingIterables = require('streaming-iterables');\nvar pRetry = require('p-retry');\nvar pack = require('ipfs-car/pack');\nvar unpack = require('ipfs-car/unpack');\nvar treewalk = require('carbites/treewalk');\nvar filesFromPath = require('files-from-path');\nvar fetch = require('@web-std/fetch');\nvar blob = require('@web-std/blob');\nvar file = require('@web-std/file');\nvar fs = require('ipfs-car/blockstore/fs');\n\nfunction _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\nvar pRetry__default = /*#__PURE__*/_interopDefaultLegacy(pRetry);\nvar fetch__default = /*#__PURE__*/_interopDefaultLegacy(fetch);\n\n/**\n * A client library for the https://web3.storage/ service. It provides a convenient\n * interface for working with the [Raw HTTP API](https://web3.storage/#api-docs)\n * from a web browser or [Node.js](https://nodejs.org/) and comes bundled with\n * TS for out-of-the box type inference and better IntelliSense.\n *\n * @example\n * ```js\n * import { Web3Storage, File } from 'web3.storage'\n * const client = new Web3Storage({ token: API_TOKEN })\n *\n * const cid = await client.put([new File(['hello world'], 'hello.txt', { type: 'text/plain' })])\n * ```\n * @module\n */\n\nconst MAX_PUT_RETRIES = 5;\nconst MAX_CONCURRENT_UPLOADS = 3;\nconst MAX_CHUNK_SIZE = 1024 * 1024 * 10; // chunk to ~10MB CARs\n\n/** @typedef { import('./lib/interface.js').API } API */\n/** @typedef { import('./lib/interface.js').Status} Status */\n/** @typedef { import('./lib/interface.js').Service } Service */\n/** @typedef { import('./lib/interface.js').Web3File} Web3File */\n/** @typedef { import('./lib/interface.js').Filelike } Filelike */\n/** @typedef { import('./lib/interface.js').CIDString} CIDString */\n/** @typedef { import('./lib/interface.js').PutOptions} PutOptions */\n/** @typedef { import('./lib/interface.js').UnixFSEntry} UnixFSEntry */\n/** @typedef { import('./lib/interface.js').Web3Response} Web3Response */\n\n/**\n * @implements Service\n */\nclass Web3Storage {\n  /**\n   * Constructs a client bound to the given `options.token` and\n   * `options.endpoint`.\n   *\n   * @example\n   * ```js\n   * import { Web3Storage } from 'web3.storage'\n   * const client = new Web3Storage({ token: API_TOKEN })\n   * ```\n   *\n   * @param {{token: string, endpoint?:URL}} options\n   */\n  constructor ({ token, endpoint = new URL('https://api.web3.storage') }) {\n    /**\n     * Authorization token.\n     *\n     * @readonly\n     */\n    this.token = token;\n    /**\n     * Service API endpoint `URL`.\n     * @readonly\n     */\n    this.endpoint = endpoint;\n  }\n\n  /**\n   * @hidden\n   * @param {string} token\n   */\n  static headers (token) {\n    if (!token) throw new Error('missing token')\n    return {\n      Authorization: `Bearer ${token}`,\n      'X-Client': 'web3.storage'\n    }\n  }\n\n  /**\n   * @param {Service} service\n   * @param {Iterable<Filelike>} files\n   * @param {PutOptions} [options]\n   * @returns {Promise<CIDString>}\n   */\n  static async put ({ endpoint, token }, files, {\n    onRootCidReady,\n    onStoredChunk,\n    maxRetries = MAX_PUT_RETRIES,\n    wrapWithDirectory = true,\n    name\n  } = {}) {\n    const url = new URL('/car', endpoint);\n    const targetSize = MAX_CHUNK_SIZE;\n    let headers = Web3Storage.headers(token);\n\n    if (name) {\n      headers = {\n        ...headers,\n        // @ts-ignore 'X-Name' does not exist in type inferred\n        'X-Name': name\n      };\n    }\n\n    let carRoot;\n    const blockstore = new fs.FsBlockStore();\n\n    try {\n      const { out, root } = await pack.pack({\n        input: Array.from(files).map((f) => ({\n          path: f.name,\n          content: f.stream()\n        })),\n        blockstore,\n        wrapWithDirectory\n      });\n      carRoot = root.toString();\n\n      onRootCidReady && onRootCidReady(carRoot);\n\n      const splitter = await treewalk.TreewalkCarSplitter.fromIterable(out, targetSize);\n\n      const upload = streamingIterables.transform(\n        MAX_CONCURRENT_UPLOADS,\n        async (/** @type {AsyncIterable<Uint8Array>} */ car) => {\n          const carParts = [];\n          for await (const part of car) {\n            carParts.push(part);\n          }\n\n          const carFile = new blob.Blob(carParts, {\n            type: 'application/car'\n          });\n\n          const res = await pRetry__default['default'](\n            async () => {\n              const request = await fetch__default['default'](url.toString(), {\n                method: 'POST',\n                headers,\n                body: carFile\n              });\n              const res = await request.json();\n\n              if (request.ok) {\n                return res.cid\n              } else {\n                throw new Error(res.message)\n              }\n            },\n            { retries: maxRetries }\n          );\n          onStoredChunk && onStoredChunk(carFile.size);\n          return res\n        }\n      );\n\n      for await (const _ of upload(splitter.cars())) {} // eslint-disable-line\n    } finally {\n      // Close Blockstore\n      await blockstore.close();\n    }\n\n    return carRoot\n  }\n\n  /**\n   * @param {Service} service\n   * @param {CIDString} cid\n   * @returns {Promise<Web3Response | null>}\n   */\n  static async get ({ endpoint, token }, cid) {\n    const url = new URL(`/car/${cid}`, endpoint);\n    const res = await fetch__default['default'](url.toString(), {\n      method: 'GET',\n      headers: Web3Storage.headers(token)\n    });\n    if (!res.ok) {\n      // TODO: I'm assuming that an error for \"CID isn't there (yet)\" would be unergonomic. Need to verify.\n      // I'm thinking null means, nope, not yet, no can has. Anything else is _AN ERROR_\n      if (res.status === 404) {\n        return null\n      } else {\n        throw new Error(`${res.status} ${res.statusText}`)\n      }\n    }\n    return toWeb3Response(res)\n  }\n\n  /**\n   * @param {Service} service\n   * @param {CIDString} cid\n   * @returns {Promise<CIDString>}\n   */\n  /* c8 ignore next 4 */\n  static async delete ({ endpoint, token }, cid) {\n    console.log('Not deleteing', cid, endpoint, token);\n    throw Error('.delete not implemented yet')\n  }\n\n  /**\n   * @param {Service} service\n   * @param {CIDString} cid\n   * @returns {Promise<Status | undefined>}\n   */\n  static async status ({ endpoint, token }, cid) {\n    const url = new URL(`/status/${cid}`, endpoint);\n    const res = await fetch__default['default'](url.toString(), {\n      method: 'GET',\n      headers: Web3Storage.headers(token)\n    });\n    if (res.status === 404) {\n      return undefined\n    }\n    if (!res.ok) {\n      throw new Error(res.statusText)\n    }\n    return res.json()\n  }\n\n  // Just a sugar so you don't have to pass around endpoint and token around.\n\n  /**\n   * Uploads files to web3.storage. Files are hashed in the client and uploaded as a single\n   * [Content Addressed Archive(CAR)](https://github.com/ipld/specs/blob/master/block-layer/content-addressable-archives.md).\n   * Takes a [Blob](https://developer.mozilla.org/en-US/docs/Web/API/Blob/Blob)\n   *\n   * Returns the corresponding Content Identifier (CID).\n   *\n   * @example\n   * ```js\n   * const file = new File(['hello world'], 'hello.txt', { type: 'text/plain' })\n   * const cid = await client.put([file])\n   * ```\n   * @param {Iterable<Filelike>} files\n   * @param {PutOptions} [options]\n   */\n  put (files, options) {\n    return Web3Storage.put(this, files, options)\n  }\n\n  /**\n   * Fetch the Content Addressed Archive by it's root CID.\n   * @param {CIDString} cid\n   */\n  get (cid) {\n    return Web3Storage.get(this, cid)\n  }\n\n  /**\n   * @param {CIDString} cid\n   */\n  /* c8 ignore next 3 */\n  delete (cid) {\n    return Web3Storage.delete(this, cid)\n  }\n\n  /**\n   * Fetch info on Filecoin deals and IPFS pins that a given CID is replicated in.\n   * @param {CIDString} cid\n   */\n  status (cid) {\n    return Web3Storage.status(this, cid)\n  }\n}\n\n/**\n * Map a UnixFSEntry to a File with a cid property\n * @param {UnixFSEntry} entry\n * @returns {Promise<Web3File>}\n */\nasync function toWeb3File ({ content, path, cid }) {\n  const chunks = [];\n  for await (const chunk of content()) {\n    chunks.push(chunk);\n  }\n  const file$1 = new file.File(chunks, toFilenameWithPath(path));\n  return Object.assign(file$1, { cid: cid.toString() })\n}\n\n/**\n * Trim the root cid from the path if there is anyting after it.\n * bafy...ic2q/path/to/pinpie.jpg => path/to/pinpie.jpg\n *         bafy...ic2q/pinpie.jpg => pinpie.jpg\n *                    bafk...52zy => bafk...52zy\n * @param {string} unixFsPath\n * @returns {string}\n */\nfunction toFilenameWithPath (unixFsPath) {\n  const slashIndex = unixFsPath.indexOf('/');\n  return slashIndex === -1 ? unixFsPath : unixFsPath.substring(slashIndex + 1)\n}\n\n/**\n * Add car unpacking smarts to the response object,\n * @param {Response} res\n * @returns {Web3Response}\n */\nfunction toWeb3Response (res) {\n  const response = Object.assign(res, {\n    unixFsIterator: async function * () {\n      /* c8 ignore next 3 */\n      if (!res.body) {\n        throw new Error('No body on response')\n      }\n      const blockstore = new fs.FsBlockStore();\n      try {\n        for await (const entry of unpack.unpackStream(res.body, { blockstore })) {\n          yield entry;\n        }\n      } finally {\n        await blockstore.close();\n      }\n    },\n    files: async () => {\n      const files = [];\n      // @ts-ignore we're using the enriched response here\n      for await (const entry of response.unixFsIterator()) {\n        if (entry.type === 'directory') {\n          continue\n        }\n        const file = await toWeb3File(entry);\n        files.push(file);\n      }\n      return files\n    }\n  });\n  return response\n}\n\nObject.defineProperty(exports, 'filesFromPath', {\n  enumerable: true,\n  get: function () {\n    return filesFromPath.filesFromPath;\n  }\n});\nObject.defineProperty(exports, 'getFilesFromPath', {\n  enumerable: true,\n  get: function () {\n    return filesFromPath.getFilesFromPath;\n  }\n});\nObject.defineProperty(exports, 'Blob', {\n  enumerable: true,\n  get: function () {\n    return blob.Blob;\n  }\n});\nObject.defineProperty(exports, 'File', {\n  enumerable: true,\n  get: function () {\n    return file.File;\n  }\n});\nexports.Web3Storage = Web3Storage;\n//# sourceMappingURL=lib.cjs.map\n","module.exports = require(\"buffer\");","module.exports = require(\"crypto\");","module.exports = require(\"fs\");","module.exports = require(\"http\");","module.exports = require(\"https\");","module.exports = require(\"os\");","module.exports = require(\"path\");","module.exports = require(\"stream\");","module.exports = require(\"url\");","module.exports = require(\"util\");","module.exports = require(\"zlib\");","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = __dirname + \"/\";","const core = require('@actions/core')\nconst { addToWeb3, pickName } = require('./web3')\n\nasync function run () {\n  try {\n    const name = pickName({\n      repo: process.env.GITHUB_REPOSITORY,\n      run: process.env.GITHUB_RUN_NUMBER,\n      sha: process.env.GITHUB_SHA\n    })\n    const endpoint = new URL(core.getInput('web3_api'))\n    const pathToAdd = core.getInput('path_to_add')\n    const token = core.getInput('web3_token')\n    const wrapWithDirectory = core.getBooleanInput('wrap_with_directory')\n    core.info(`Adding ${pathToAdd} to ${endpoint.origin}`)\n    const { cid, url } = await addToWeb3({ endpoint, token, name, pathToAdd, wrapWithDirectory })\n    core.info(url)\n    core.setOutput('cid', cid)\n    core.setOutput('url', url)\n  } catch (error) {\n    core.setFailed(error.message)\n  }\n}\n\nrun()\n"],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;AC3FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACrSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1XA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/sBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACh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xCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC3YA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/sBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACt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tMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/sBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC1KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC15BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACtKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACv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aAqBA;AACA;;;A;;;;;;ACpkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpFA;AACA;AACA;AACA;;;A;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACvMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACpFA;;;;;;;;;AASA;;;;;A;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;ACxDA;;A;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACjKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;A;;;;;ACz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x0BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC7BA;AACA;AACA;AACA;AACA;;;A;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;ACNA;AACA;AACA;AACA;AACA;AACA,KACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACh6HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC9SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC1uDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;A;;;;;;AC/WA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;;;ACAA;;A;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC7BA;AACA;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;A","sourceRoot":""}